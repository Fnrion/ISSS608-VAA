[
  {
    "objectID": "In-class_Ex/In-class_Ex08/shp/Oceanus Geography.html",
    "href": "In-class_Ex/In-class_Ex08/shp/Oceanus Geography.html",
    "title": "",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n       GEOGCRS[“WGS 84”,ENSEMBLE[“World Geodetic System 1984 ensemble”,MEMBER[“World Geodetic System 1984 (Transit)”],MEMBER[“World Geodetic System 1984 (G730)”],MEMBER[“World Geodetic System 1984 (G873)”],MEMBER[“World Geodetic System 1984 (G1150)”],MEMBER[“World Geodetic System 1984 (G1674)”],MEMBER[“World Geodetic System 1984 (G1762)”],MEMBER[“World Geodetic System 1984 (G2139)”],ELLIPSOID[“WGS 84”,6378137,298.257223563,LENGTHUNIT[“metre”,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[“Greenwich”,0,ANGLEUNIT[“degree”,0.0174532925199433]],CS[ellipsoidal,2],AXIS[“geodetic latitude (Lat)”,north,ORDER[1],ANGLEUNIT[“degree”,0.0174532925199433]],AXIS[“geodetic longitude (Lon)”,east,ORDER[2],ANGLEUNIT[“degree”,0.0174532925199433]],USAGE[SCOPE[“Horizontal component of 3D system.”],AREA[“World.”],BBOX[-90,-180,90,180]],ID[“EPSG”,4326]] +proj=longlat +datum=WGS84 +no_defs 3452 4326 EPSG:4326 WGS 84 longlat EPSG:7030 true"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html",
    "title": "In-class Ex01",
    "section": "",
    "text": "In the code chunk below, ‘p_load()’ of pacman package is used to load tidyverse family of package\n\npacman::p_load(tidyverse)\n\n\nrealis &lt;-read.csv(\"data/realis2019.csv\")\nhead(realis, 10)\n\n               Project.Name                        Address No..of.Units\n1               PEIRCE VIEW 557 Upper Thomson Road  #02-12            1\n2              FLORIDA PARK               54 Sunrise Drive            1\n3              BULLION PARK        164 Lentor Loop  #03-02            1\n4              CASTLE GREEN  483 Yio Chu Kang Road  #07-03            1\n5              HAPPY ESTATE             36 Thomson Heights            1\n6  TEACHER'S HOUSING ESTATE              148 Tagore Avenue            1\n7              THE PANORAMA 20 Ang Mo Kio Avenue 2  #05-40            1\n8              THE PANORAMA 16 Ang Mo Kio Avenue 2  #12-20            1\n9          CHIP THYE GARDEN         8 Yio Chu Kang Gardens            1\n10 TEACHER'S HOUSING ESTATE             16 Kalidasa Avenue            1\n   Area..sqm. Type.of.Area Transacted.Price.... Nett.Price...\n1         113       Strata               840000             -\n2         312         Land              3040000             -\n3          75       Strata               860000             -\n4         107       Strata              1000000             -\n5         687         Land              7000000             -\n6         228         Land              2880000             -\n7          94       Strata              1510000             -\n8          42       Strata               710000             -\n9         207         Land              2800000             -\n10        232         Land              2300000             -\n   Unit.Price....psm. Unit.Price....psf. Sale.Date       Property.Type\n1                7434                691 10-Jan-19         Condominium\n2                9737                905 10-Jan-19 Semi-Detached House\n3               11467               1065  8-Jan-19         Condominium\n4                9346                868  3-Jan-19         Condominium\n5               10183                946  2-Jan-19 Semi-Detached House\n6               12659               1176 11-Feb-19       Terrace House\n7               16064               1492  8-Feb-19         Condominium\n8               16905               1570  8-Feb-19         Condominium\n9               13500               1254  8-Feb-19       Terrace House\n10               9935                923  8-Feb-19       Terrace House\n                    Tenure Completion.Date Type.of.Sale\n1                 Freehold            1996       Resale\n2                 Freehold            1989       Resale\n3                 Freehold            1993       Resale\n4   99 Yrs From 01/12/1993            1997       Resale\n5                 Freehold            1984       Resale\n6  999 Yrs From 02/12/1885         Unknown       Resale\n7   99 Yrs From 08/04/2013            2017       Resale\n8   99 Yrs From 08/04/2013            2017       Resale\n9                 Freehold            1981       Resale\n10 999 Yrs From 02/12/1885         Unknown       Resale\n   Purchaser.Address.Indicator Postal.District Postal.Sector Postal.Code\n1                      Private              20            57      574418\n2                      Private              28            80      806557\n3                      Private              26            78      789096\n4                      Private              26            78      787057\n5                      Private              20            57      574861\n6                      Private              26            78      787738\n7                          HDB              20            56      567701\n8                      Private              20            56      567699\n9                          HDB              20            56      568058\n10                     Private              26            78      789395\n     Planning.Region Planning.Area\n1  North East Region    Ang Mo Kio\n2  North East Region    Ang Mo Kio\n3  North East Region    Ang Mo Kio\n4  North East Region    Ang Mo Kio\n5  North East Region    Ang Mo Kio\n6  North East Region    Ang Mo Kio\n7  North East Region    Ang Mo Kio\n8  North East Region    Ang Mo Kio\n9  North East Region    Ang Mo Kio\n10 North East Region    Ang Mo Kio\n\n\n\nrealis &lt;-read_csv(\"data/realis2019.csv\")\n\n\nggplot(data = realis,\n       aes(x = 'Unit price($ psm)'))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#loading-r-package",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#loading-r-package",
    "title": "In-class Ex01",
    "section": "",
    "text": "In the code chunk below, ‘p_load()’ of pacman package is used to load tidyverse family of package\n\npacman::p_load(tidyverse)\n\n\nrealis &lt;-read.csv(\"data/realis2019.csv\")\nhead(realis, 10)\n\n               Project.Name                        Address No..of.Units\n1               PEIRCE VIEW 557 Upper Thomson Road  #02-12            1\n2              FLORIDA PARK               54 Sunrise Drive            1\n3              BULLION PARK        164 Lentor Loop  #03-02            1\n4              CASTLE GREEN  483 Yio Chu Kang Road  #07-03            1\n5              HAPPY ESTATE             36 Thomson Heights            1\n6  TEACHER'S HOUSING ESTATE              148 Tagore Avenue            1\n7              THE PANORAMA 20 Ang Mo Kio Avenue 2  #05-40            1\n8              THE PANORAMA 16 Ang Mo Kio Avenue 2  #12-20            1\n9          CHIP THYE GARDEN         8 Yio Chu Kang Gardens            1\n10 TEACHER'S HOUSING ESTATE             16 Kalidasa Avenue            1\n   Area..sqm. Type.of.Area Transacted.Price.... Nett.Price...\n1         113       Strata               840000             -\n2         312         Land              3040000             -\n3          75       Strata               860000             -\n4         107       Strata              1000000             -\n5         687         Land              7000000             -\n6         228         Land              2880000             -\n7          94       Strata              1510000             -\n8          42       Strata               710000             -\n9         207         Land              2800000             -\n10        232         Land              2300000             -\n   Unit.Price....psm. Unit.Price....psf. Sale.Date       Property.Type\n1                7434                691 10-Jan-19         Condominium\n2                9737                905 10-Jan-19 Semi-Detached House\n3               11467               1065  8-Jan-19         Condominium\n4                9346                868  3-Jan-19         Condominium\n5               10183                946  2-Jan-19 Semi-Detached House\n6               12659               1176 11-Feb-19       Terrace House\n7               16064               1492  8-Feb-19         Condominium\n8               16905               1570  8-Feb-19         Condominium\n9               13500               1254  8-Feb-19       Terrace House\n10               9935                923  8-Feb-19       Terrace House\n                    Tenure Completion.Date Type.of.Sale\n1                 Freehold            1996       Resale\n2                 Freehold            1989       Resale\n3                 Freehold            1993       Resale\n4   99 Yrs From 01/12/1993            1997       Resale\n5                 Freehold            1984       Resale\n6  999 Yrs From 02/12/1885         Unknown       Resale\n7   99 Yrs From 08/04/2013            2017       Resale\n8   99 Yrs From 08/04/2013            2017       Resale\n9                 Freehold            1981       Resale\n10 999 Yrs From 02/12/1885         Unknown       Resale\n   Purchaser.Address.Indicator Postal.District Postal.Sector Postal.Code\n1                      Private              20            57      574418\n2                      Private              28            80      806557\n3                      Private              26            78      789096\n4                      Private              26            78      787057\n5                      Private              20            57      574861\n6                      Private              26            78      787738\n7                          HDB              20            56      567701\n8                      Private              20            56      567699\n9                          HDB              20            56      568058\n10                     Private              26            78      789395\n     Planning.Region Planning.Area\n1  North East Region    Ang Mo Kio\n2  North East Region    Ang Mo Kio\n3  North East Region    Ang Mo Kio\n4  North East Region    Ang Mo Kio\n5  North East Region    Ang Mo Kio\n6  North East Region    Ang Mo Kio\n7  North East Region    Ang Mo Kio\n8  North East Region    Ang Mo Kio\n9  North East Region    Ang Mo Kio\n10 North East Region    Ang Mo Kio\n\n\n\nrealis &lt;-read_csv(\"data/realis2019.csv\")\n\n\nggplot(data = realis,\n       aes(x = 'Unit price($ psm)'))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "title": "In-class_Ex02 Demo",
    "section": "",
    "text": "Click to view code\npacman::p_load(ggrepel, patchwork, ggthemes,\n               hrbrthemes, tidyverse, ggplot2)\n\n\n\n\n\n\n\nClick to view code\nexam_df &lt;- read.csv(\"data/Exam_data.csv\")\n\n\n\n\n\n\n\n\n\nClick to view code\nggplot(data = exam_df,\n       aes(x = ENGLISH)) +\n  geom_histogram()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nClick to view code\nggplot(data = exam_df,\n       aes(x = ENGLISH,\n           color = CLASS)) +\n  geom_density(color = \"#1696d2\",\n  adjust = .65,\n  alpha = .6)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nClick to view code\nmedian_eng &lt;- median(exam_df$ENGLISH)\nmean_eng &lt;- mean(exam_df$ENGLISH)\nstd_eng &lt;- sd(exam_df$ENGLISH)\n\nggplot(exam_df, aes(x=ENGLISH)) +\n  geom_density(color = \"#1696d2\",\n               adjust = 0.65,\n               alpha = 0.6,) +\n  stat_function(\n    fun=dnorm,\n    args = list(mean=mean_eng, sd = std_eng),\n    col = \"grey30\",\n    size = 0.8)+\n    geom_vline(aes(xintercept=mean_eng), color = \"#4d5887\", linewidth = 0.6, linetype = \"dashed\")+\n  annotate(geom = \"text\",\n           x = mean_eng - 10,\n           y = 0.04,\n           label = paste0(\"Mean ENGLISH:\", round(mean_eng), 2),\n           color = \"#4d5887\") +\n  geom_vline(aes(xintercept=median_eng), color = \"#4d5887\", linewidth = 0.6) +\n  annotate(geom = \"text\",\n           x = median_eng + 10,\n           y = 0.04,\n           label = paste0(\"Median ENGLISH:\", round(median_eng), 2),\n           color = \"#4d5887\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#load-package",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#load-package",
    "title": "In-class_Ex02 Demo",
    "section": "",
    "text": "Click to view code\npacman::p_load(ggrepel, patchwork, ggthemes,\n               hrbrthemes, tidyverse, ggplot2)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#import-data",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#import-data",
    "title": "In-class_Ex02 Demo",
    "section": "",
    "text": "Click to view code\nexam_df &lt;- read.csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#draw",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#draw",
    "title": "In-class_Ex02 Demo",
    "section": "",
    "text": "Click to view code\nggplot(data = exam_df,\n       aes(x = ENGLISH)) +\n  geom_histogram()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nClick to view code\nggplot(data = exam_df,\n       aes(x = ENGLISH,\n           color = CLASS)) +\n  geom_density(color = \"#1696d2\",\n  adjust = .65,\n  alpha = .6)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nClick to view code\nmedian_eng &lt;- median(exam_df$ENGLISH)\nmean_eng &lt;- mean(exam_df$ENGLISH)\nstd_eng &lt;- sd(exam_df$ENGLISH)\n\nggplot(exam_df, aes(x=ENGLISH)) +\n  geom_density(color = \"#1696d2\",\n               adjust = 0.65,\n               alpha = 0.6,) +\n  stat_function(\n    fun=dnorm,\n    args = list(mean=mean_eng, sd = std_eng),\n    col = \"grey30\",\n    size = 0.8)+\n    geom_vline(aes(xintercept=mean_eng), color = \"#4d5887\", linewidth = 0.6, linetype = \"dashed\")+\n  annotate(geom = \"text\",\n           x = mean_eng - 10,\n           y = 0.04,\n           label = paste0(\"Mean ENGLISH:\", round(mean_eng), 2),\n           color = \"#4d5887\") +\n  geom_vline(aes(xintercept=median_eng), color = \"#4d5887\", linewidth = 0.6) +\n  annotate(geom = \"text\",\n           x = median_eng + 10,\n           y = 0.04,\n           label = paste0(\"Median ENGLISH:\", round(median_eng), 2),\n           color = \"#4d5887\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#plotting-ridgeline-graph-ggridges-method",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#plotting-ridgeline-graph-ggridges-method",
    "title": "In-class_Ex02 Demo",
    "section": "4.1 Plotting ridgeline graph: ggridges method",
    "text": "4.1 Plotting ridgeline graph: ggridges method\nggridges package provides two main geom to plot gridgeline plots, they are: geom_ridgeline()and geom_density_ridges().\ngeom_ridgeline() plots the graph using the height values from the data directly. It is useful when the height values refer to a column directly.\nFor this particular dataset, it is more appropriate to use geom_density_ridges() as we need to plot the distribution of students’ English score. If we had tallied and aggregated the number of students who scores within score ranges, geom_ridgeline() might be appropriate but it isn’t the case.\n\n\nClick to view code\n# ggplot(exam_df, \n#        aes(x = ENGLISH, \n#            y = CLASS)) +\n#   geom_density_ridges(\n#     scale = 3,\n#     rel_min_height = 0.01,\n#     bandwidth = 3.4,\n#     fill = lighten(\"#7097BB\", .3),\n#     color = \"white\"\n#   ) +\n#   scale_x_continuous(\n#     name = \"English grades\",\n#     expand = c(0, 0)\n#     ) +\n#   scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n#   theme_ridges()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "title": "In-class_Exercise 4",
    "section": "",
    "text": "pacman::p_load(tidyverse, ggstatsplot)\n\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")\n\n\nset.seed(1234)\n\ngghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"np\",\n  #type = \"parametric\",\n  test.value = 60,\n  bin.args = list(color = \"black\",\n                  fill = \"grey50\",\n                  alpha = 0.7),\n  normal.curve = FALSE,\n  normal.curve.args = list(linewidth = 2),\n  xlab = \"English scores\"\n)\n\n\n\n\n\n\n\n\n\nset.seed(1234)\n\np &lt;- gghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"np\",\n  #type = \"parametric\",\n  #type = \"robust\",\n  #type = \"bayes\",\n  test.value = 60,\n  bin.args = list(color = \"black\",\n                  fill = \"grey50\",\n                  alpha = 0.7),\n  normal.curve = FALSE,\n  #normal.curve = TRUE, #(show the normal distribution)\n  normal.curve.args = list(linewidth = 2),\n  xlab = \"English scores\"\n)\n\n\nextract_stats(p)\n\n$subtitle_data\n# A tibble: 1 × 12\n  statistic  p.value method                    alternative effectsize       \n      &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;                     &lt;chr&gt;       &lt;chr&gt;            \n1     38743 3.43e-16 Wilcoxon signed rank test two.sided   r (rank biserial)\n  estimate conf.level conf.low conf.high conf.method n.obs expression\n     &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;       &lt;int&gt; &lt;list&gt;    \n1    0.528       0.95    0.430     0.613 normal        322 &lt;language&gt;\n\n$caption_data\nNULL\n\n$pairwise_comparisons_data\nNULL\n\n$descriptive_data\nNULL\n\n$one_sample_data\nNULL\n\n$tidy_data\nNULL\n\n$glance_data\nNULL\n\n\n\nggdotplotstats(\n  data = exam,\n  x = ENGLISH,\n  y = CLASS,\n  title = \"\",\n  xlab = \"\"\n)\n\n\n\n\n\n\n\n\n\nexam_long &lt;- exam %&gt;%\n  pivot_longer(\n    cols = ENGLISH:SCIENCE,\n    names_to = \"SUBJECT\",\n    values_to = \"SCORES\") %&gt;%\n filter(CLASS == \"3A\")\n\n\nggwithinstats(data = filter(exam_long,\n                            SUBJECT %in% c(\"ENGLISH\", \"SCIENCE\")),\n              x = \"SUBJECT\",\n              y = \"SCORES\",\n              type = \"p\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "title": "Take-home_Exercise2",
    "section": "",
    "text": "This project is a continuation from Take-take Exercise 1. The objective is to analyse the charts by applying the data visualisation design principles and best practices, and to improve on one of the submissions prepared by a fellow classmate. ZHANG CHENBIN in Take-home Exercise 1 submission will be selected to have some comments and try to improve it.\n\n\n\n\n\n\nI’m going to Judge you!"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#first-analysis---quarterly-housing-prices-by-area-category",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#first-analysis---quarterly-housing-prices-by-area-category",
    "title": "Take-home_Exercise2",
    "section": "2.1 First Analysis - Quarterly Housing Prices by Area Category",
    "text": "2.1 First Analysis - Quarterly Housing Prices by Area Category\n\nOriginal PlotImproved Plot\n\n\nThe original plot handled average price before utilizing 4 plots to show different Area range’s average Unit Price, and used three plots to present Q1 2024 situation.\n\n\n\n\n\n\n\n\n\nRows: 26,806\nColumns: 21\n$ `Project Name`                &lt;chr&gt; \"THE REEF AT KING'S DOCK\", \"URBAN TREASU…\n$ `Transacted Price ($)`        &lt;dbl&gt; 2317000, 1823500, 1421112, 1258112, 1280…\n$ `Area (SQFT)`                 &lt;dbl&gt; 882.65, 882.65, 1076.40, 1033.34, 871.88…\n$ `Unit Price ($ PSF)`          &lt;dbl&gt; 2625, 2066, 1320, 1218, 1468, 1767, 1095…\n$ `Sale Date`                   &lt;chr&gt; \"01 Jan 2023\", \"02 Jan 2023\", \"02 Jan 20…\n$ Address                       &lt;chr&gt; \"12 HARBOURFRONT AVENUE #05-32\", \"205 JA…\n$ `Type of Sale`                &lt;chr&gt; \"New Sale\", \"New Sale\", \"New Sale\", \"New…\n$ `Type of Area`                &lt;chr&gt; \"Strata\", \"Strata\", \"Strata\", \"Strata\", …\n$ `Area (SQM)`                  &lt;dbl&gt; 82.0, 82.0, 100.0, 96.0, 81.0, 308.7, 42…\n$ `Unit Price ($ PSM)`          &lt;dbl&gt; 28256, 22238, 14211, 13105, 15802, 19015…\n$ `Nett Price($)`               &lt;chr&gt; \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", …\n$ `Property Type`               &lt;chr&gt; \"Condominium\", \"Condominium\", \"Executive…\n$ `Number of Units`             &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ Tenure                        &lt;chr&gt; \"99 yrs from 12/01/2021\", \"Freehold\", \"9…\n$ `Completion Date`             &lt;chr&gt; \"Uncompleted\", \"Uncompleted\", \"Uncomplet…\n$ `Purchaser Address Indicator` &lt;chr&gt; \"HDB\", \"Private\", \"HDB\", \"HDB\", \"HDB\", \"…\n$ `Postal Code`                 &lt;chr&gt; \"097996\", \"419535\", \"269343\", \"269294\", …\n$ `Postal District`             &lt;chr&gt; \"04\", \"14\", \"27\", \"27\", \"28\", \"19\", \"10\"…\n$ `Postal Sector`               &lt;chr&gt; \"09\", \"41\", \"26\", \"26\", \"79\", \"54\", \"27\"…\n$ `Planning Region`             &lt;chr&gt; \"Central Region\", \"East Region\", \"North …\n$ `Planning Area`               &lt;chr&gt; \"Bukit Merah\", \"Bedok\", \"Yishun\", \"Yishu…\n\n\n\n\nInstead of relying on average unit price, utilizing the frequency of distributed area (in square meters) can better illustrate purchasing power and market potential, particularly when the total number of transactions is unknown. Additionally, for a clearer understanding of specific Q1 2024 sales data, opting for a density plot can effectively visualize the distribution of unit prices."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#comparative-analysis-of-transaction-volumes-and-pricing-across-real-estate-projects",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#comparative-analysis-of-transaction-volumes-and-pricing-across-real-estate-projects",
    "title": "Take-home_Exercise2",
    "section": "2.2.Comparative Analysis of Transaction Volumes and Pricing Across Real Estate Projects",
    "text": "2.2.Comparative Analysis of Transaction Volumes and Pricing Across Real Estate Projects\n\nOriginal PlotImproved Plot\n\n\nChenbin employed two plots: one depicting the frequency of various projects and the other illustrating the purchase situation across different projects.\n\n\n\n\n\n\n\n\n\n\n\nTo broaden the scope and facilitate comparison between project categories, we can utilize a flip in plot orientation. Additionally, incorporating mean statistics can effectively convey Chenbin’s intended presentation in the aforementioned plots."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "There are two major residential property market in Singapore, namely public and private housing. Public housing aims to meet the basic need of the general public with monthly household income less than or equal to S$14,000. For families with monthly household income more than S$14,000, they need to turn to the private residential market.\nWe will go to prepare minimum two and maximum three data visualisation to reveal the private residential market and sub-markets of Singapore for the 1st quarter of 2024.\n\n\n\n\n\n\n\n\n\n\n\nClick to view code\npacman::p_load(dplyr, purrr, readr, ggiraph,\n               ggplot2, lubridate, ggrepel,\n               patchwork, ggthemes, hrbrthemes, tidyverse)\ndata_dir &lt;- \"data-2\"\nfile_paths &lt;- file.path(data_dir,\n                        c(\"2023Q1.csv\",\n                          \"2023Q2.csv\",\n                          \"2023Q3.csv\",\n                          \"2023Q4.csv\",\n                          \"2024Q1.csv\"))\ncombined_data &lt;- purrr::map_df(file_paths, readr::read_csv)\nglimpse(combined_data)\n\n\nRows: 26,806\nColumns: 21\n$ `Project Name`                &lt;chr&gt; \"THE REEF AT KING'S DOCK\", \"URBAN TREASU…\n$ `Transacted Price ($)`        &lt;dbl&gt; 2317000, 1823500, 1421112, 1258112, 1280…\n$ `Area (SQFT)`                 &lt;dbl&gt; 882.65, 882.65, 1076.40, 1033.34, 871.88…\n$ `Unit Price ($ PSF)`          &lt;dbl&gt; 2625, 2066, 1320, 1218, 1468, 1767, 1095…\n$ `Sale Date`                   &lt;chr&gt; \"01 Jan 2023\", \"02 Jan 2023\", \"02 Jan 20…\n$ Address                       &lt;chr&gt; \"12 HARBOURFRONT AVENUE #05-32\", \"205 JA…\n$ `Type of Sale`                &lt;chr&gt; \"New Sale\", \"New Sale\", \"New Sale\", \"New…\n$ `Type of Area`                &lt;chr&gt; \"Strata\", \"Strata\", \"Strata\", \"Strata\", …\n$ `Area (SQM)`                  &lt;dbl&gt; 82.0, 82.0, 100.0, 96.0, 81.0, 308.7, 42…\n$ `Unit Price ($ PSM)`          &lt;dbl&gt; 28256, 22238, 14211, 13105, 15802, 19015…\n$ `Nett Price($)`               &lt;chr&gt; \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", …\n$ `Property Type`               &lt;chr&gt; \"Condominium\", \"Condominium\", \"Executive…\n$ `Number of Units`             &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ Tenure                        &lt;chr&gt; \"99 yrs from 12/01/2021\", \"Freehold\", \"9…\n$ `Completion Date`             &lt;chr&gt; \"Uncompleted\", \"Uncompleted\", \"Uncomplet…\n$ `Purchaser Address Indicator` &lt;chr&gt; \"HDB\", \"Private\", \"HDB\", \"HDB\", \"HDB\", \"…\n$ `Postal Code`                 &lt;chr&gt; \"097996\", \"419535\", \"269343\", \"269294\", …\n$ `Postal District`             &lt;chr&gt; \"04\", \"14\", \"27\", \"27\", \"28\", \"19\", \"10\"…\n$ `Postal Sector`               &lt;chr&gt; \"09\", \"41\", \"26\", \"26\", \"79\", \"54\", \"27\"…\n$ `Planning Region`             &lt;chr&gt; \"Central Region\", \"East Region\", \"North …\n$ `Planning Area`               &lt;chr&gt; \"Bukit Merah\", \"Bedok\", \"Yishun\", \"Yishu…\n\n\nClick to view code\nreadr::write_csv(combined_data,\n                 file.path(data_dir,\"merged_transaction_data.csv\"))\n\n\n\n\n\n\nAccording to the combined_data, there are 26,806 observation of 21 variables before we make a data cleaning.\n\nNow we need to check the duplicate.\n\n\nClick to view code\nduplicate &lt;- combined_data %&gt;% \n  group_by_all() %&gt;% \n  filter(n()&gt;1) %&gt;% \n  ungroup()\n  \nduplicate\n\n\n# A tibble: 0 × 21\n# ℹ 21 variables: Project Name &lt;chr&gt;, Transacted Price ($) &lt;dbl&gt;,\n#   Area (SQFT) &lt;dbl&gt;, Unit Price ($ PSF) &lt;dbl&gt;, Sale Date &lt;chr&gt;,\n#   Address &lt;chr&gt;, Type of Sale &lt;chr&gt;, Type of Area &lt;chr&gt;, Area (SQM) &lt;dbl&gt;,\n#   Unit Price ($ PSM) &lt;dbl&gt;, Nett Price($) &lt;chr&gt;, Property Type &lt;chr&gt;,\n#   Number of Units &lt;dbl&gt;, Tenure &lt;chr&gt;, Completion Date &lt;chr&gt;,\n#   Purchaser Address Indicator &lt;chr&gt;, Postal Code &lt;chr&gt;,\n#   Postal District &lt;chr&gt;, Postal Sector &lt;chr&gt;, Planning Region &lt;chr&gt;, …\n\n\nCongratulation, there is no duplicate according to our find!\n\n\n\n\n\n\n\n\n\n\n\n\nCategory\nSample Description\nType\nChoose or not\n\n\n\n\nProject.Name\n“THE REEF AT KING’S DOCK”\nchr\nNot Choose\n\n\nTransacted Price ($)\n“2317000”\nnum\nChoose\n\n\nArea (SQFT)\n“883”\nnum\nChoose\n\n\nUnit Price ($ PSF)\n“2625 = 2317000/883”\nnum\nChoose\n\n\nSale Data\n“01 Jan 2023”\nchr\nChoose\n\n\nAddress\n“12 HARBOURFRONT AVENUE #05-32”\nchr\nNot Choose\n\n\nType of sale\n“New Sale”\nchr\nChoose\n\n\nArea (SQM)\n“Strata”\nnum\nNot Choose\n\n\nUnit Price ($ PSM)\n“82”\nnum\nNot Choose\n\n\nNett Price ($)\n“-”\nchr\nNot Choose\n\n\nProperty Type\n“Condominium”\nchr\nChoose\n\n\nNumber of Units\n“1”\nnum\nChoose Choose\n\n\nTenure\n“99 yrs from 12/01/2021”\nchr\nNot Choose\n\n\nCompletion Data\n“Uncompleted”\nchr\nNot Choose\n\n\nPurchaser Address Indicator\n“HDB”\nchr\nChoose\n\n\nPostal Code\n“097996”\nchr\nNot Choose\n\n\nPostal District\n“04”\nchr\nNot Choose\n\n\nPostal Sector\n“09”\nchr\nNot Choose\n\n\nPlanning Region\n“Central Region”\nchr\nChoose\n\n\nPlanning Area\n“Bukit Merah”\nchr\nNot Choose\n\n\n\n\n\n\n\n\n\n\n\n\nTransacted Price ($)Area (SQFT)Unit Price ($ PSF)Sale DataType of saleProperty TypePurchaser Address IndicatorPlanning Region\n\n\n\n\nClick to view code\nsum(is.na(combined_data$`Transacted Price ($)`))\n\n\n[1] 0\n\n\n\n\n\n\nClick to view code\nsum(is.na(combined_data$`Area (SQFT)`))\n\n\n[1] 0\n\n\n\n\n\n\nClick to view code\nsum(is.na(combined_data$`Unit Price ($ PSF)`))\n\n\n[1] 0\n\n\n\n\n\n\nClick to view code\nsum(is.na(combined_data$`Sale Date`))\n\n\n[1] 0\n\n\n\n\n\n\nClick to view code\nsum(is.na(combined_data$`Type of Sale`))\n\n\n[1] 0\n\n\n\n\n\n\nClick to view code\nsum(is.na(combined_data$`Property Type`))\n\n\n[1] 0\n\n\n\n\n\n\nClick to view code\nsum(is.na(combined_data$`Purchaser Address Indicator`))\n\n\n[1] 0\n\n\n\n\n\n\nClick to view code\nsum(is.na(combined_data$`Planning Region`))\n\n\n[1] 0\n\n\n\n\n\nCongratulation, there is no missing data according to our find!"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#background",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#background",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "There are two major residential property market in Singapore, namely public and private housing. Public housing aims to meet the basic need of the general public with monthly household income less than or equal to S$14,000. For families with monthly household income more than S$14,000, they need to turn to the private residential market.\nWe will go to prepare minimum two and maximum three data visualisation to reveal the private residential market and sub-markets of Singapore for the 1st quarter of 2024."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-import",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-import",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "Click to view code\npacman::p_load(dplyr, purrr, readr, ggiraph,\n               ggplot2, lubridate, ggrepel,\n               patchwork, ggthemes, hrbrthemes, tidyverse)\ndata_dir &lt;- \"data-2\"\nfile_paths &lt;- file.path(data_dir,\n                        c(\"2023Q1.csv\",\n                          \"2023Q2.csv\",\n                          \"2023Q3.csv\",\n                          \"2023Q4.csv\",\n                          \"2024Q1.csv\"))\ncombined_data &lt;- purrr::map_df(file_paths, readr::read_csv)\nglimpse(combined_data)\n\n\nRows: 26,806\nColumns: 21\n$ `Project Name`                &lt;chr&gt; \"THE REEF AT KING'S DOCK\", \"URBAN TREASU…\n$ `Transacted Price ($)`        &lt;dbl&gt; 2317000, 1823500, 1421112, 1258112, 1280…\n$ `Area (SQFT)`                 &lt;dbl&gt; 882.65, 882.65, 1076.40, 1033.34, 871.88…\n$ `Unit Price ($ PSF)`          &lt;dbl&gt; 2625, 2066, 1320, 1218, 1468, 1767, 1095…\n$ `Sale Date`                   &lt;chr&gt; \"01 Jan 2023\", \"02 Jan 2023\", \"02 Jan 20…\n$ Address                       &lt;chr&gt; \"12 HARBOURFRONT AVENUE #05-32\", \"205 JA…\n$ `Type of Sale`                &lt;chr&gt; \"New Sale\", \"New Sale\", \"New Sale\", \"New…\n$ `Type of Area`                &lt;chr&gt; \"Strata\", \"Strata\", \"Strata\", \"Strata\", …\n$ `Area (SQM)`                  &lt;dbl&gt; 82.0, 82.0, 100.0, 96.0, 81.0, 308.7, 42…\n$ `Unit Price ($ PSM)`          &lt;dbl&gt; 28256, 22238, 14211, 13105, 15802, 19015…\n$ `Nett Price($)`               &lt;chr&gt; \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", …\n$ `Property Type`               &lt;chr&gt; \"Condominium\", \"Condominium\", \"Executive…\n$ `Number of Units`             &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ Tenure                        &lt;chr&gt; \"99 yrs from 12/01/2021\", \"Freehold\", \"9…\n$ `Completion Date`             &lt;chr&gt; \"Uncompleted\", \"Uncompleted\", \"Uncomplet…\n$ `Purchaser Address Indicator` &lt;chr&gt; \"HDB\", \"Private\", \"HDB\", \"HDB\", \"HDB\", \"…\n$ `Postal Code`                 &lt;chr&gt; \"097996\", \"419535\", \"269343\", \"269294\", …\n$ `Postal District`             &lt;chr&gt; \"04\", \"14\", \"27\", \"27\", \"28\", \"19\", \"10\"…\n$ `Postal Sector`               &lt;chr&gt; \"09\", \"41\", \"26\", \"26\", \"79\", \"54\", \"27\"…\n$ `Planning Region`             &lt;chr&gt; \"Central Region\", \"East Region\", \"North …\n$ `Planning Area`               &lt;chr&gt; \"Bukit Merah\", \"Bedok\", \"Yishun\", \"Yishu…\n\n\nClick to view code\nreadr::write_csv(combined_data,\n                 file.path(data_dir,\"merged_transaction_data.csv\"))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-check",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-check",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "According to the combined_data, there are 26,806 observation of 21 variables before we make a data cleaning.\n\nNow we need to check the duplicate.\n\n\nClick to view code\nduplicate &lt;- combined_data %&gt;% \n  group_by_all() %&gt;% \n  filter(n()&gt;1) %&gt;% \n  ungroup()\n  \nduplicate\n\n\n# A tibble: 0 × 21\n# ℹ 21 variables: Project Name &lt;chr&gt;, Transacted Price ($) &lt;dbl&gt;,\n#   Area (SQFT) &lt;dbl&gt;, Unit Price ($ PSF) &lt;dbl&gt;, Sale Date &lt;chr&gt;,\n#   Address &lt;chr&gt;, Type of Sale &lt;chr&gt;, Type of Area &lt;chr&gt;, Area (SQM) &lt;dbl&gt;,\n#   Unit Price ($ PSM) &lt;dbl&gt;, Nett Price($) &lt;chr&gt;, Property Type &lt;chr&gt;,\n#   Number of Units &lt;dbl&gt;, Tenure &lt;chr&gt;, Completion Date &lt;chr&gt;,\n#   Purchaser Address Indicator &lt;chr&gt;, Postal Code &lt;chr&gt;,\n#   Postal District &lt;chr&gt;, Postal Sector &lt;chr&gt;, Planning Region &lt;chr&gt;, …\n\n\nCongratulation, there is no duplicate according to our find!"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#variable-selection",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#variable-selection",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "Category\nSample Description\nType\nChoose or not\n\n\n\n\nProject.Name\n“THE REEF AT KING’S DOCK”\nchr\nNot Choose\n\n\nTransacted Price ($)\n“2317000”\nnum\nChoose\n\n\nArea (SQFT)\n“883”\nnum\nChoose\n\n\nUnit Price ($ PSF)\n“2625 = 2317000/883”\nnum\nChoose\n\n\nSale Data\n“01 Jan 2023”\nchr\nChoose\n\n\nAddress\n“12 HARBOURFRONT AVENUE #05-32”\nchr\nNot Choose\n\n\nType of sale\n“New Sale”\nchr\nChoose\n\n\nArea (SQM)\n“Strata”\nnum\nNot Choose\n\n\nUnit Price ($ PSM)\n“82”\nnum\nNot Choose\n\n\nNett Price ($)\n“-”\nchr\nNot Choose\n\n\nProperty Type\n“Condominium”\nchr\nChoose\n\n\nNumber of Units\n“1”\nnum\nChoose Choose\n\n\nTenure\n“99 yrs from 12/01/2021”\nchr\nNot Choose\n\n\nCompletion Data\n“Uncompleted”\nchr\nNot Choose\n\n\nPurchaser Address Indicator\n“HDB”\nchr\nChoose\n\n\nPostal Code\n“097996”\nchr\nNot Choose\n\n\nPostal District\n“04”\nchr\nNot Choose\n\n\nPostal Sector\n“09”\nchr\nNot Choose\n\n\nPlanning Region\n“Central Region”\nchr\nChoose\n\n\nPlanning Area\n“Bukit Merah”\nchr\nNot Choose"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#missing-values",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#missing-values",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "Transacted Price ($)Area (SQFT)Unit Price ($ PSF)Sale DataType of saleProperty TypePurchaser Address IndicatorPlanning Region\n\n\n\n\nClick to view code\nsum(is.na(combined_data$`Transacted Price ($)`))\n\n\n[1] 0\n\n\n\n\n\n\nClick to view code\nsum(is.na(combined_data$`Area (SQFT)`))\n\n\n[1] 0\n\n\n\n\n\n\nClick to view code\nsum(is.na(combined_data$`Unit Price ($ PSF)`))\n\n\n[1] 0\n\n\n\n\n\n\nClick to view code\nsum(is.na(combined_data$`Sale Date`))\n\n\n[1] 0\n\n\n\n\n\n\nClick to view code\nsum(is.na(combined_data$`Type of Sale`))\n\n\n[1] 0\n\n\n\n\n\n\nClick to view code\nsum(is.na(combined_data$`Property Type`))\n\n\n[1] 0\n\n\n\n\n\n\nClick to view code\nsum(is.na(combined_data$`Purchaser Address Indicator`))\n\n\n[1] 0\n\n\n\n\n\n\nClick to view code\nsum(is.na(combined_data$`Planning Region`))\n\n\n[1] 0\n\n\n\n\n\nCongratulation, there is no missing data according to our find!"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#property-type-planning-region",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#property-type-planning-region",
    "title": "Take-home Exercise 1",
    "section": "2.1 Property Type & Planning Region",
    "text": "2.1 Property Type & Planning Region\nFirst, we want to know which property type is popular in private residential market and sub-markets of Singapore, and how the resident located in Singapore.\n\n\nClick to view code\nF1 &lt;- ggplot(combined_data, aes(x = `Property Type`)) + \n    geom_bar_interactive(aes(fill = `Planning Region`), position = \"dodge\") +  \n    labs(x = \"Property Type\", y = \"Frequency\",\n         title = \"Frequency of Property Types by Planning Region\") +\n    facet_wrap(~ `Planning Region`, scales = \"free\") +\n    theme_stata(base_size = 2.5)\n    theme(axis.text.x = element_text(angle = 45, hjust = 1)) \n\n\nList of 1\n $ axis.text.x:List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : num 1\n  ..$ vjust        : NULL\n  ..$ angle        : num 45\n  ..$ lineheight   : NULL\n  ..$ margin       : NULL\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi FALSE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n - attr(*, \"class\")= chr [1:2] \"theme\" \"gg\"\n - attr(*, \"complete\")= logi FALSE\n - attr(*, \"validate\")= logi TRUE\n\n\nClick to view code\nF1\n\n\n\n\n\n\n\n\n\n\nWe have now acquired transaction data pertaining to six distinct property types: Apartment, Condominium, Terrace House, Executive Condominium, Detached House, and Semi-Detached House. These properties are situated across five planning regions: Central Region, East Region, North East Region, North Region, and West Region.\nUpon analysis, it is evident that the market for detached houses, semi-detached houses, and terrace houses is considerably limited, with minimal activity observed.\nFurthermore, our findings reveal noteworthy trends across different regions. In the North Region, Executive Condominiums emerge as the most sought-after property type, boasting the highest number of transactions compared to other regions. Similarly, in the West Region, Executive Condominiums exhibit robust trading activity.\nAcross most regions, Apartments and Condominiums consistently dominate the market as preferred sale properties, with the exception of the North Region, where unique market dynamics are observed."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#quarterly-boxplot-of-transacted-price-area",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#quarterly-boxplot-of-transacted-price-area",
    "title": "Take-home Exercise 1",
    "section": "2.2 Quarterly Boxplot of Transacted Price & Area",
    "text": "2.2 Quarterly Boxplot of Transacted Price & Area\n\nTransacted PriceArea\n\n\n\n\nClick to view code\nP1 &lt;- Boxplot_Q_TP + coord_cartesian(ylim = c(0, 3000000)) +  \n  scale_y_continuous(labels = scales::comma_format(scale = 1e-3))\nP1\n\n\n\n\n\n\n\n\n\n\n\n\n\nClick to view code\nP2 &lt;- Boxplot_Q_A + coord_cartesian(ylim = c(0, 2000))\nP2"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#scatter-plot-of-transacted-price-vs.-area",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#scatter-plot-of-transacted-price-vs.-area",
    "title": "Take-home Exercise 1",
    "section": "2.3 Scatter Plot of Transacted Price vs. Area",
    "text": "2.3 Scatter Plot of Transacted Price vs. Area\n\n\nClick to view code\nsampled_data &lt;- combined_data[sample(nrow(combined_data), 500), ]\nsampled_data$`Transacted Price ($)` &lt;- sampled_data$`Transacted Price ($)` / 1000\nP3 &lt;- ggplot(data = sampled_data, aes(x = `Area (SQFT)`, y = `Transacted Price ($)`)) +\n  geom_point_interactive() +\n  geom_smooth() +\n  scale_x_continuous(limits = c(0, 3000)) + \n  scale_y_continuous(limits = c(0, 10000)) +\n  labs(x = \"Area (SQFT)\", y = \"Transacted Price ($ thousands)\",\n       title = \"Scatter Plot of Transacted Price vs. Area\")\nP3\n\n\n\n\n\n\n\n\n\n\nAfter thorough analysis, it becomes apparent that each quarter exhibits a comparable range of transacted prices, with Q1 2024 demonstrating a notably higher transacted price compared to Q1 2023.\nMoreover, the distribution of transacted prices and areas across all transactions reveals that 99% of deals fall within the range of 300 to 1,500 square feet, with corresponding prices ranging from 1,100 to 3,750 thousand SGD. This distribution underscores the prevailing market trends and preferences within the real estate landscape."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#unit-price-analysis",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#unit-price-analysis",
    "title": "Take-home Exercise 1",
    "section": "2.4 Unit Price Analysis",
    "text": "2.4 Unit Price Analysis\nAs we mentioned about the individual market is focus on the apartment and condominium above, and we know the distribution of total preoperty, what about the first quarter unit price of these two popular goods?\n\nJan-Mar 2024Jan-Mar 2023\n\n\n\n\nClick to view code\nfiltered_data &lt;- combined_data %&gt;%\n  mutate(Sale_Date = dmy(`Sale Date`)) %&gt;%\n  filter((year(Sale_Date) == 2023 & \n          month(Sale_Date) %in% 1:12) |\n         (year(Sale_Date) == 2024 & \n          month(Sale_Date) %in% 1:3)) %&gt;%\n  mutate(Quarter_Sale_Data = case_when(\n    between(Sale_Date, as.Date(\"2023-01-01\"), as.Date(\"2023-03-31\")) ~ \"Q1_2023\",\n    between(Sale_Date, as.Date(\"2023-04-01\"), as.Date(\"2023-06-30\")) ~ \"Q2_2023\",\n    between(Sale_Date, as.Date(\"2023-07-01\"), as.Date(\"2023-09-30\")) ~ \"Q3_2023\",\n    between(Sale_Date, as.Date(\"2023-10-01\"), as.Date(\"2023-12-31\")) ~ \"Q4_2023\",\n    between(Sale_Date, as.Date(\"2024-01-01\"), as.Date(\"2024-03-31\")) ~ \"Q1_2024\",\n    TRUE ~ NA_character_\n  )) %&gt;%\n  filter(!is.na(Quarter_Sale_Data)) %&gt;%\n  mutate(Month_Sale_Data = paste0(year(Sale_Date), \"-\", month(Sale_Date)))\n\nfiltered_data &lt;- filtered_data %&gt;%\n  filter(`Property Type` %in% c(\"Apartment\", \"Condominium\"))\n\nggplot(filtered_data, aes(x = Month_Sale_Data, y = `Unit Price ($ PSF)`, color = `Property Type`)) +\n  geom_violin() +\n  geom_point(position = \"jitter\",\n             size = 0.1) +\n  labs(title = \"Unit Price per Square Foot for Apartments and Condominiums\",\n       x = \"Month\",\n       y = \"Unit Price ($ PSF)\") +\n  theme_light(base_size = 6) +\n  xlim(c(\"2024-1\",\"2024-2\",\"2024-3\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\nClick to view code\nggplot(filtered_data, aes(x = Month_Sale_Data, y = `Unit Price ($ PSF)`, color = `Property Type`)) +\n  geom_violin() +\n  geom_point(position = \"jitter\",\n             size = 0.1) +\n  labs(title = \"Unit Price per Square Foot for Apartments and Condominiums\",\n       x = \"Month\",\n       y = \"Unit Price ($ PSF)\") +\n  theme_light(base_size = 6) +\n  xlim(c(\"2023-1\",\"2023-2\",\"2023-3\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\nUpon examination of the violin plots, a clear disparity emerges between the average unit prices of condominiums and apartments, standing at approximately $1,500 and $2,000, respectively, for the period spanning January to March. Noteworthy is the discernible uptick in both unit price and transaction volume from January to March 2024. Despite an overall reduction in total transactions vis-a-vis the preceding year, there is an unmistakable trend towards growth within specific sub-markets, suggesting an increasing inclination towards higher-value properties"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS608-VAA",
    "section": "",
    "text": "Welcome to ISSS608 Visual Analytics and Applications homepage. In this website, you will find my coursework prepared for this course.\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 1: A Layered Grammar of Graphics: ggplot2 methods\n\n\n\nZou Jiaxun\n\n\nApr 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 2: Beyond ggplot2 Fundamentals\n\n\n\nZou Jiaxun\n\n\nApr 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 3(a): Programming Interactive Data Visualisation with R\n\n\n\nZou Jiaxun\n\n\nApr 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 3(b): Programming Animated Statistical Graphics with R\n\n\n\nZou Jiaxun\n\n\nApr 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 4(a): Visual Statistical Analysis\n\n\n\nZou Jiaxun\n\n\nApr 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 4(b): Visualising Uncertainty\n\n\n\nZou Jiaxun\n\n\nApr 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 4(c): Funnel Plots for Fair Comparisons\n\n\n\nZou Jiaxun\n\n\nApr 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 6: Modelling, Visualising and Analysing Network Data with R\n\n\n\nZou Jiaxun\n\n\nApr 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on_Ex07\n\n\n\nZou Jiaxun\n\n\nMay 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on_Ex08(a)\n\n\n\nZou Jiaxun\n\n\nJun 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on_Ex08(b)\n\n\n\nZou Jiaxun\n\n\nJun 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on_Ex08(c)\n\n\n\n\n\n\nJun 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on_Ex09(a)\n\n\n\n\n\n\nJun 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on_Ex09(b)\n\n\n\n\n\n\nJun 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on_Ex09(c)\n\n\n\n\n\n\nJun 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on_Ex09(d)\n\n\n\n\n\n\nJun 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on_Ex09(e)\n\n\n\n\n\n\nJun 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on_Ex10\n\n\n\n\n\n\nJun 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on_Exercise 5: Visualising and Analysing Text Data with R: tidytext methods\n\n\n\nZou Jiaxun\n\n\nMay 9, 2024\n\n\n\n\n\n\n\n\nNo matching items\n\n\n  \n\n\n\n\n\n\n\n\n\nIn-class Ex01\n\n\n\nZou Jiaxun\n\n\nApr 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn-class_Ex02 Demo\n\n\n\nZou Jiaxun\n\n\nApr 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn-class_Ex05\n\n\n\nZou Jiaxun\n\n\nMay 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn-class_Ex06\n\n\n\nZou Jiaxun\n\n\nMay 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn-class_Ex09\n\n\n\n\n\n\nJun 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn-class_Exercise 4\n\n\n\nZou Jiaxun\n\n\nMay 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nMy Second Quarto Dashboard\n\n\n\n\n\n\nJun 22, 2024\n\n\n\n\n\n\n\n\nNo matching items\n\n\n\n\n\n\n\n\n\nTake-home Exercise 1\n\n\n\nZou Jiaxun\n\n\nApr 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nTake-home_Ex03\n\n\n\nZou Jiaxun\n\n\nJun 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nTake-home_Exercise2\n\n\n\nZou Jiaxun\n\n\nMay 2, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04(b)/Hands-on_Ex04(b).html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex04(b)/Hands-on_Ex04(b).html#learning-outcome",
    "title": "Hands-on Exercise 4(b): Visualising Uncertainty",
    "section": "1 Learning Outcome",
    "text": "1 Learning Outcome\nVisualising uncertainty is relatively new in statistical graphics. In this chapter, you will gain hands-on experience on creating statistical graphics for visualising uncertainty. By the end of this chapter you will be able:\n\nto plot statistics error bars by using ggplot2,\nto plot interactive error bars by combining ggplot2, plotly and DT,\nto create advanced by using ggdist, and\nto create hypothetical outcome plots (HOPs) by using ungeviz package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04(b)/Hands-on_Ex04(b).html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex04(b)/Hands-on_Ex04(b).html#getting-started",
    "title": "Hands-on Exercise 4(b): Visualising Uncertainty",
    "section": "2 Getting Started",
    "text": "2 Getting Started\n\n2.1 Installing and loading the packages\nFor the purpose of this exercise, the following R packages will be used, they are:\n\ntidyverse, a family of R packages for data science process,\nplotly for creating interactive plot,\ngganimate for creating animation plot,\nDT for displaying interactive html table,\ncrosstalk for for implementing cross-widget interactions (currently, linked brushing and filtering), and\nggdist for visualising distribution and uncertainty.\n\n\n\nClick to view code\ndevtools::install_github(\"wilkelab/ungeviz\")\n\n\n\n\nClick to view code\npacman::p_load(ungeviz, plotly, crosstalk,\n               DT, ggdist, ggridges,\n               colorspace, gganimate, tidyverse)\n\n\n\n\n2.2 Data import\nFor the purpose of this exercise, Exam_data.csv will be used.\n\n\nClick to view code\nexam &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04(b)/Hands-on_Ex04(b).html#visualizing-the-uncertainty-of-point-estimates-ggplot2-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04(b)/Hands-on_Ex04(b).html#visualizing-the-uncertainty-of-point-estimates-ggplot2-methods",
    "title": "Hands-on Exercise 4(b): Visualising Uncertainty",
    "section": "3 Visualizing the uncertainty of point estimates: ggplot2 methods",
    "text": "3 Visualizing the uncertainty of point estimates: ggplot2 methods\nA point estimate is a single number, such as a mean. Uncertainty, on the other hand, is expressed as standard error, confidence interval, or credible interval.\n\n\n\n\n\n\nImportant\n\n\n\n\nDon’t confuse the uncertainty of a point estimate with the variation in the sample\n\n\n\nIn this section, you will learn how to plot error bars of maths scores by race by using data provided in exam tibble data frame.\nFirstly, code chunk below will be used to derive the necessary summary statistics.\n\n\nClick to view code\nmy_sum &lt;- exam %&gt;%\n  group_by(RACE) %&gt;%\n  summarise(\n    n = n(),\n    mean = mean(MATHS),\n    sd = sd(MATHS)\n  ) %&gt;%\n  mutate(se = sd/sqrt(n-1))\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\ngroup_by() of dplyr package is used to group the observation by RACE,\nsummarise() is used to compute the count of observations, mean, standard deviation\nmutate() is used to derive standard error of Maths by RACE, and\nthe output is save as a tibble data table called my_sum.\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nFor the mathematical explanation, please refer to Slide 20 of Lesson 4.\n\n\nNext, the code chunk below will be used to display my_sum tibble data frame in an html table format.\n\nThe code chunkThe table\n\n\n\n\nClick to view code\nknitr::kable(head(my_sum), format = 'html')\n\n\n\n\n\n\n\n\n\nRACE\nn\nmean\nsd\nse\n\n\n\n\nChinese\n193\n76.50777\n15.69040\n1.132357\n\n\nIndian\n12\n60.66667\n23.35237\n7.041005\n\n\nMalay\n108\n57.44444\n21.13478\n2.043177\n\n\nOthers\n9\n69.66667\n10.72381\n3.791438\n\n\n\n\n\n\n\n\n\n\n\n3.1 Plotting standard error bars of point estimates\nNow we are ready to plot the standard error bars of mean maths score by race as shown below.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nClick to view code\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=RACE, \n        ymin=mean-se, \n        ymax=mean+se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    size=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  ggtitle(\"Standard error of mean maths score by rac\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.2 Plotting confidence interval of point estimates\nInstead of plotting the standard error bar of point estimates, we can also plot the confidence intervals of mean maths score by race.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nClick to view code\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=reorder(RACE, -mean), \n        ymin=mean-1.96*se, \n        ymax=mean+1.96*se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    size=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  labs(x = \"Maths score\",\n       title = \"95% confidence interval of mean maths score by race\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nThe confidence intervals are computed by using the formula mean+/-1.96*se.\nThe error bars is sorted by using the average maths scores.\nlabs() argument of ggplot2 is used to change the x-axis label.\n\n\n\n\n\n3.3 Visualizing the uncertainty of point estimates with interactive error bars\nIn this section, you will learn how to plot interactive error bars for the 99% confidence interval of mean maths score by race as shown in the figure below.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nClick to view code\nshared_df = SharedData$new(my_sum)\n\nbscols(widths = c(4,8),\n       ggplotly((ggplot(shared_df) +\n                   geom_errorbar(aes(\n                     x=reorder(RACE, -mean),\n                     ymin=mean-2.58*se, \n                     ymax=mean+2.58*se), \n                     width=0.2, \n                     colour=\"black\", \n                     alpha=0.9, \n                     size=0.5) +\n                   geom_point(aes(\n                     x=RACE, \n                     y=mean, \n                     text = paste(\"Race:\", `RACE`, \n                                  \"&lt;br&gt;N:\", `n`,\n                                  \"&lt;br&gt;Avg. Scores:\", round(mean, digits = 2),\n                                  \"&lt;br&gt;95% CI:[\", \n                                  round((mean-2.58*se), digits = 2), \",\",\n                                  round((mean+2.58*se), digits = 2),\"]\")),\n                     stat=\"identity\", \n                     color=\"red\", \n                     size = 1.5, \n                     alpha=1) + \n                   xlab(\"Race\") + \n                   ylab(\"Average Scores\") + \n                   theme_minimal() + \n                   theme(axis.text.x = element_text(\n                     angle = 45, vjust = 0.5, hjust=1)) +\n                   ggtitle(\"99% Confidence interval of average /&lt;br&gt;maths scores by race\")), \n                tooltip = \"text\"), \n       DT::datatable(shared_df, \n                     rownames = FALSE, \n                     class=\"compact\", \n                     width=\"100%\", \n                     options = list(pageLength = 10,\n                                    scrollX=T), \n                     colnames = c(\"No. of pupils\", \n                                  \"Avg Scores\",\n                                  \"Std Dev\",\n                                  \"Std Error\")) %&gt;%\n         formatRound(columns=c('mean', 'sd', 'se'),\n                     digits=2))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04(b)/Hands-on_Ex04(b).html#visualising-uncertainty-ggdist-package",
    "href": "Hands-on_Ex/Hands-on_Ex04(b)/Hands-on_Ex04(b).html#visualising-uncertainty-ggdist-package",
    "title": "Hands-on Exercise 4(b): Visualising Uncertainty",
    "section": "4 Visualising Uncertainty: ggdist package",
    "text": "4 Visualising Uncertainty: ggdist package\n\nggdist is an R package that provides a flexible set of ggplot2 geoms and stats designed especially for visualising distributions and uncertainty.\nIt is designed for both frequentist and Bayesian uncertainty visualization, taking the view that uncertainty visualization can be unified through the perspective of distribution visualization:\n\nfor frequentist models, one visualises confidence distributions or bootstrap distributions (see vignette(“freq-uncertainty-vis”));\nfor Bayesian models, one visualises probability distributions (see the tidybayes package, which builds on top of ggdist).\n\n\n\n\n4.1 Visualizing the uncertainty of point estimates: ggdist methods\nIn the code chunk below, stat_pointinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\n\nClick to view code\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval() +\n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThis function comes with many arguments, students are advised to read the syntax reference for more detail.\n\n\nFor example, in the code chunk below the following arguments are used:\n\n.width = 0.95\n.point = median\n.interval = qi\n\n\n\nClick to view code\nexam %&gt;%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(.width = 0.95,\n  .point = median,\n  .interval = qi) +\n  labs(\n    title = \"Visualising confidence intervals of median math score\",\n    subtitle = \"Median Point + Multiple-interval plot\")\n\n\n\n\n\n\n\n\n\n\n\n4.2 Visualizing the uncertainty of point estimates: ggdist methods\n\n\n\n\n\n\nYour turn\n\n\n\nMakeover the plot on previous slide by showing 95% and 99% confidence intervals.\n\n\n\n\nClick to view code\nexam %&gt;%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(.width = 0.99,\n  .point = median,\n  .interval = qi,\n  color = 'red') +\n    stat_pointinterval(.width = 0.95,\n  .point = median,\n  .interval = qi,\n  color = 'blue') +\n  labs(\n    title = \"Visualising confidence intervals of median math score\",\n    subtitle = \"Median Point + Multiple-interval plot\")\n\n\n\n\n\n\n\n\n\n\n\n4.3 Visualizing the uncertainty of point estimates: ggdist methods\nIn the code chunk below, stat_gradientinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\n\nClick to view code\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_gradientinterval(   \n    fill = \"skyblue\",      \n    show.legend = TRUE     \n  ) +                        \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Gradient + interval plot\")\n\n\n\n\n\n\n\n\n\nGentle advice: This function comes with many arguments, students are advised to read the syntax reference for more detail."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04(b)/Hands-on_Ex04(b).html#visualising-uncertainty-with-hypothetical-outcome-plots-hops",
    "href": "Hands-on_Ex/Hands-on_Ex04(b)/Hands-on_Ex04(b).html#visualising-uncertainty-with-hypothetical-outcome-plots-hops",
    "title": "Hands-on Exercise 4(b): Visualising Uncertainty",
    "section": "5 Visualising Uncertainty with Hypothetical Outcome Plots (HOPs)",
    "text": "5 Visualising Uncertainty with Hypothetical Outcome Plots (HOPs)\nStep 1: Installing ungeviz package\n\n\nClick to view code\ndevtools::install_github(\"wilkelab/ungeviz\")\n\n\nNote: You only need to perform this step once.\nStep 2: Launch the application in R\n\n\nClick to view code\nlibrary(ungeviz)\n\n\n\n\nClick to view code\nggplot(data = exam, \n       (aes(x = factor(RACE), y = MATHS))) +\n  geom_point(position = position_jitter(\n    height = 0.3, width = 0.05), \n    size = 0.4, color = \"#0072B2\", alpha = 1/2) +\n  geom_hpline(data = sampler(25, group = RACE), height = 0.6, color = \"#D55E00\") +\n  theme_bw() + \n  # `.draw` is a generated column indicating the sample draw\n  transition_states(.draw, 1, 3)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04(b)/Hands-on_Ex04(b).html#visualising-uncertainty-with-hypothetical-outcome-plots-hops-1",
    "href": "Hands-on_Ex/Hands-on_Ex04(b)/Hands-on_Ex04(b).html#visualising-uncertainty-with-hypothetical-outcome-plots-hops-1",
    "title": "Hands-on Exercise 4(b): Visualising Uncertainty",
    "section": "6 Visualising Uncertainty with Hypothetical Outcome Plots (HOPs)",
    "text": "6 Visualising Uncertainty with Hypothetical Outcome Plots (HOPs)\n\n\nClick to view code\nggplot(data = exam, \n       (aes(x = factor(RACE), \n            y = MATHS))) +\n  geom_point(position = position_jitter(\n    height = 0.3, \n    width = 0.05), \n    size = 0.4, \n    color = \"#0072B2\", \n    alpha = 1/2) +\n  geom_hpline(data = sampler(25, \n                             group = RACE), \n              height = 0.6, \n              color = \"#D55E00\") +\n  theme_bw() + \n  transition_states(.draw, 1, 3)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "title": "Hands-on Exercise 6: Modelling, Visualising and Analysing Network Data with R",
    "section": "",
    "text": "In this hands-on exercise, you will learn how to model, analyse and visualise network data using R.\nBy the end of this hands-on exercise, you will be able to:\n\ncreate graph object data frames, manipulate them using appropriate functions of dplyr, lubridate, and tidygraph,\nbuild network graph visualisation using appropriate functions of ggraph,\ncompute network geometrics using tidygraph,\nbuild advanced graph visualisation by incorporating the network geometrics, and\nbuild interactive network visualisation using visNetwork package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#overview",
    "title": "Hands-on Exercise 6: Modelling, Visualising and Analysing Network Data with R",
    "section": "",
    "text": "In this hands-on exercise, you will learn how to model, analyse and visualise network data using R.\nBy the end of this hands-on exercise, you will be able to:\n\ncreate graph object data frames, manipulate them using appropriate functions of dplyr, lubridate, and tidygraph,\nbuild network graph visualisation using appropriate functions of ggraph,\ncompute network geometrics using tidygraph,\nbuild advanced graph visualisation by incorporating the network geometrics, and\nbuild interactive network visualisation using visNetwork package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#getting-started",
    "title": "Hands-on Exercise 6: Modelling, Visualising and Analysing Network Data with R",
    "section": "2 Getting Started",
    "text": "2 Getting Started\n\n2.1 Installing and launching R packages\nIn this hands-on exercise, four network data modelling and visualisation packages will be installed and launched. They are igraph, tidygraph, ggraph and visNetwork. Beside these four packages, tidyverse and lubridate, an R package specially designed to handle and wrangling time data will be installed and launched too.\nThe code chunk:\n\n\nClick to view code\npacman::p_load(igraph, tidygraph, ggraph, visNetwork,\n               lubridate, clock, tidyverse, graphlayouts)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#the-data",
    "title": "Hands-on Exercise 6: Modelling, Visualising and Analysing Network Data with R",
    "section": "3 The Data",
    "text": "3 The Data\nThe data sets used in this hands-on exercise is from an oil exploration and extraction company. There are two data sets. One contains the nodes data and the other contains the edges (also know as link) data.\n\n3.1 The edges data\n\nGAStech-email_edges.csv which consists of two weeks of 9063 emails correspondances between 55 employees.\n\n\n\n\n3.2 The nodes data\n\nGAStech_email_nodes.csv which consist of the names, department and title of the 55 employees.\n\n\n\n\n3.3 Importing network data from files\nIn this step, you will import GAStech_email_node.csv and GAStech_email_edges-v2.csv into RStudio environment by using read_csv() of readr package.\n\n\nClick to view code\nGAStech_nodes &lt;- read_csv(\"data/GAStech_email_node.csv\")\nGAStech_edges &lt;- read_csv(\"data/GAStech_email_edge-v2.csv\")\n\n\n\n\n3.4 Reviewing the imported data\nNext, we will examine the structure of the data frame using glimpse() of dplyr. ·\n\n\nClick to view code\nglimpse(GAStech_edges)\n\n\nRows: 9,063\nColumns: 8\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThe output report of GAStech_edges above reveals that the SentDate is treated as “Character” data type instead of data type. This is an error! Before we continue, it is important for us to change the data type of SentDate field back to “Date”” data type.\n\n\n\n\n3.5 Wrangling time\nThe code chunk below will be used to perform the changes.\n\n\nClick to view code\nGAStech_edges &lt;- GAStech_edges %&gt;%\n  mutate(SendDate = dmy(SentDate)) %&gt;%\n  mutate(Weekday = wday(SentDate,\n                        label = TRUE,\n                        abbr = FALSE))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#creating-network-objects-using-tidygraph",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#creating-network-objects-using-tidygraph",
    "title": "Hands-on Exercise 6: Modelling, Visualising and Analysing Network Data with R",
    "section": "4 Creating network objects using tidygraph",
    "text": "4 Creating network objects using tidygraph\nIn this section, you will learn how to create a graph data model by using tidygraph package. It provides a tidy API for graph/network manipulation. While network data itself is not tidy, it can be envisioned as two tidy tables, one for node data and one for edge data. tidygraph provides a way to switch between the two tables and provides dplyr verbs for manipulating them. Furthermore it provides access to a lot of graph algorithms with return values that facilitate their use in a tidy workflow.\nBefore getting started, you are advised to read these two articles:\n\nIntroducing tidygraph\ntidygraph 1.1 - A tidy hope\n\n\n4.1 The tbl_graph object\nTwo functions of tidygraph package can be used to create network objects, they are:\n\ntbl_graph() creates a tbl_graph network object from nodes and edges data.\nas_tbl_graph() converts network data and objects to a tbl_graphnetwork. Below are network data and objects supported by as_tbl_graph()\n\na node data.frame and an edge data.frame,\ndata.frame, list, matrix from base,\nigraph from igraph,\nnetwork from network,\ndendrogram and hclust from stats,\nNode from data.tree,\nphylo and evonet from ape, and\ngraphNEL, graphAM, graphBAM from graph (in Bioconductor).\n\n\n\n\n4.2 The dplyr verbs in tidygraph\n\nactivate() verb from tidygraph serves as a switch between tibbles for nodes and edges. All dplyr verbs applied to tbl_graph object are applied to the active tibble.\n\n\n\nIn the above the .N() function is used to gain access to the node data while manipulating the edge data. Similarly .E() will give you the edge data and .G() will give you the tbl_graph object itself.\n\n\n\n4.3 Using tbl_graph() to build tidygraph data model.\nIn this section, you will use tbl_graph() of tinygraph package to build an tidygraph’s network graph data.frame.\nBefore typing the codes, you are recommended to review to reference guide of tbl_graph()\n\n\nClick to view code\nGAStech_graph &lt;- tbl_graph(nodes = GAStech_nodes,\n                           edges = GAStech_edges_aggregated, \n                           directed = TRUE)\n\n\n\n\n4.4 Reviewing the output tidygraph’s graph object\n\n\nClick to view code\nGAStech_graph\n\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# Node Data: 54 × 4 (active)\n      id label               Department     Title                               \n   &lt;dbl&gt; &lt;chr&gt;               &lt;chr&gt;          &lt;chr&gt;                               \n 1     1 Mat.Bramar          Administration Assistant to CEO                    \n 2     2 Anda.Ribera         Administration Assistant to CFO                    \n 3     3 Rachel.Pantanal     Administration Assistant to CIO                    \n 4     4 Linda.Lagos         Administration Assistant to COO                    \n 5     5 Ruscella.Mies.Haber Administration Assistant to Engineering Group Mana…\n 6     6 Carla.Forluniau     Administration Assistant to IT Group Manager       \n 7     7 Cornelia.Lais       Administration Assistant to Security Group Manager \n 8    44 Kanon.Herrero       Security       Badging Office                      \n 9    45 Varja.Lagos         Security       Badging Office                      \n10    46 Stenig.Fusil        Security       Building Control                    \n# ℹ 44 more rows\n#\n# Edge Data: 1,372 × 4\n   from    to Weekday Weight\n  &lt;int&gt; &lt;int&gt; &lt;ord&gt;    &lt;int&gt;\n1     1     2 Sunday       5\n2     1     2 Monday       2\n3     1     2 Tuesday      3\n# ℹ 1,369 more rows\n\n\n\n\n4.5 Reviewing the output tidygraph’s graph object\n\nThe output above reveals that GAStech_graph is a tbl_graph object with 54 nodes and 4541 edges.\nThe command also prints the first six rows of “Node Data” and the first three of “Edge Data”.\nIt states that the Node Data is active. The notion of an active tibble within a tbl_graph object makes it possible to manipulate the data in one tibble at a time.\n\n\n\n4.6 Changing the active object\nThe nodes tibble data frame is activated by default, but you can change which tibble data frame is active with the activate() function. Thus, if we wanted to rearrange the rows in the edges tibble to list those with the highest “weight” first, we could use activate() and then arrange().\nFor example,\nGAStech_graph %&gt;%\n  activate(edges) %&gt;%\n  arrange(desc(Weight))\nVisit the reference guide of activate() to find out more about the function."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-static-network-graphs-with-ggraph-package",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-static-network-graphs-with-ggraph-package",
    "title": "Hands-on Exercise 6: Modelling, Visualising and Analysing Network Data with R",
    "section": "5 Plotting Static Network Graphs with ggraph package",
    "text": "5 Plotting Static Network Graphs with ggraph package\nggraph is an extension of ggplot2, making it easier to carry over basic ggplot skills to the design of network graphs.\nAs in all network graph, there are three main aspects to a ggraph’s network graph, they are:\n\nnodes,\nedges and\nlayouts.\n\nFor a comprehensive discussion of each of this aspect of graph, please refer to their respective vignettes provided.\n\n5.1 Plotting a basic network graph\nThe code chunk below uses ggraph(), geom-edge_link() and geom_node_point() to plot a network graph by using GAStech_graph. Before your get started, it is advisable to read their respective reference guide at least once.\n\n\nClick to view code\nggraph(GAStech_graph) +\n  geom_edge_link() +\n  geom_node_point()\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\nThe basic plotting function is ggraph(), which takes the data to be used for the graph and the type of layout desired. Both of the arguments for ggraph()are built around igraph. Therefore, ggraph() can use either an igraph object or a tbl_graph object.\n\n\n\n\n5.2 Changing the default network graph theme\nIn this section, you will use theme_graph() to remove the x and y axes. Before your get started, it is advisable to read it’s reference guide at least once.\n\n\nClick to view code\ng &lt;- ggraph(GAStech_graph) + \n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\nggraph introduces a special ggplot theme that provides better defaults for network graphs than the normal ggplot defaults. theme_graph(), besides removing axes, grids, and border, changes the font to Arial Narrow (this can be overridden).\nThe ggraph theme can be set for a series of plots with the set_graph_style() command run before the graphs are plotted or by using theme_graph() in the individual plots.\n\n\n\n\n5.3 Changing the coloring of the plot\nFurthermore, theme_graph() makes it easy to change the coloring of the plot.\n\n\nClick to view code\ng &lt;- ggraph(GAStech_graph) + \n  geom_edge_link(aes(colour = 'grey50')) +\n  geom_node_point(aes(colour = 'grey40'))\n\ng + theme_graph(background = 'grey10',\n                text_colour = 'white')\n\n\n\n\n\n\n\n\n\n\n\n5.4 Working with ggraph’s layouts\nggraph support many layout for standard used, they are: star, circle, nicely (default), dh, gem, graphopt, grid, mds, spahere, randomly, fr, kk, drl and lgl. Figures below and on the right show layouts supported by ggraph().\n\n\n\n\n5.5 Fruchterman and Reingold layout\nThe code chunks below will be used to plot the network graph using Fruchterman and Reingold layout.\n\n\nClick to view code\ng &lt;- ggraph(GAStech_graph, \n            layout = \"fr\") +\n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\nThing to learn from the code chunk above:\n\nlayout argument is used to define the layout to be used.\n\n\n\n5.6 Modifying network nodes\nIn this section, you will colour each node by referring to their respective departments.\n\n\nClick to view code\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes()) +\n  geom_node_point(aes(colour = Department, \n                      size = 3))\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunks above:\n\ngeom_node_point is equivalent in functionality to geo_point of ggplot2. It allows for simple plotting of nodes in different shapes, colours and sizes. In the codes chnuks above colour and size are used.\n\n\n\n5.7 Modifying edges\nIn the code chunk below, the thickness of the edges will be mapped with the Weight variable.\n\n\nClick to view code\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") +\n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 3)\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunks above:\n\ngeom_edge_link draws edges in the simplest way - as straight lines between the start and end nodes. But, it can do more that that. In the example above, argument width is used to map the width of the line in proportional to the Weight attribute and argument alpha is used to introduce opacity on the line."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#creating-facet-graphs",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#creating-facet-graphs",
    "title": "Hands-on Exercise 6: Modelling, Visualising and Analysing Network Data with R",
    "section": "6 Creating facet graphs",
    "text": "6 Creating facet graphs\nAnother very useful feature of ggraph is faceting. In visualising network data, this technique can be used to reduce edge over-plotting in a very meaning way by spreading nodes and edges out based on their attributes. In this section, you will learn how to use faceting technique to visualise network data.\nThere are three functions in ggraph to implement faceting, they are:\n\nfacet_nodes() whereby edges are only draw in a panel if both terminal nodes are present here,\nfacet_edges() whereby nodes are always drawn in al panels even if the node data contains an attribute named the same as the one used for the edge facetting, and\nfacet_graph() faceting on two variables simultaneously.\n\n\n6.1 Working with facet_edges()\nIn the code chunk below, facet_edges() is used. Before getting started, it is advisable for you to read it’s reference guide at least once.\nAnother very useful feature of ggraph is faceting. In visualising network data, this technique can be used to reduce edge over-plotting in a very meaning way by spreading nodes and edges out based on their attributes. In this section, you will learn how to use faceting technique to visualise network data.\nThere are three functions in ggraph to implement faceting, they are:\n\nfacet_nodes() whereby edges are only draw in a panel if both terminal nodes are present here,\nfacet_edges() whereby nodes are always drawn in al panels even if the node data contains an attribute named the same as the one used for the edge facetting, and\nfacet_graph() faceting on two variables simultaneously.\n\n\n\n6.1 Working with facet_edges()\nIn the code chunk below, facet_edges() is used. Before getting started, it is advisable for you to read it’s reference guide at least once.\n\n\nClick to view code\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n\ng + facet_edges(~Weekday)\n\n\n\n\n\n\n\n\n\n\n\n6.2 Working with facet_edges()\nThe code chunk below uses theme() to change the position of the legend.\n\n\nClick to view code\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2) +\n  theme(legend.position = 'bottom')\n  \ng + facet_edges(~Weekday)\n\n\n\n\n\n\n\n\n\n\n\n6.3 A framed facet graph\nThe code chunk below adds frame to each graph.\n\n\nClick to view code\nset_graph_style() \n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_edges(~Weekday) +\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')\n\n\n\n\n\n\n\n\n\n6.4 Working with facet_nodes() In the code chunkc below, facet_nodes() is used. Before getting started, it is advisable for you to read it’s reference guide at least once.\n\n\nClick to view code\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_nodes(~Department)+\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#network-metrics-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#network-metrics-analysis",
    "title": "Hands-on Exercise 6: Modelling, Visualising and Analysing Network Data with R",
    "section": "7 Network Metrics Analysis",
    "text": "7 Network Metrics Analysis\n\n7.1 Computing centrality indices\nCentrality measures are a collection of statistical indices use to describe the relative important of the actors are to a network. There are four well-known centrality measures, namely: degree, betweenness, closeness and eigenvector. It is beyond the scope of this hands-on exercise to cover the principles and mathematics of these measure here. Students are encouraged to refer to Chapter 7: Actor Prominence of A User’s Guide to Network Analysis in R to gain better understanding of theses network measures.\n\n\nClick to view code\ng &lt;- GAStech_graph %&gt;%\n  mutate(betweenness_centrality = centrality_betweenness()) %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department,\n            size=betweenness_centrality))\ng + theme_graph()\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\nmutate() of dplyr is used to perform the computation.\nthe algorithm used, on the other hand, is the centrality_betweenness() of tidygraph.\n\n\n\n7.2 Visualising network metrics\nIt is important to note that from ggraph v2.0 onward tidygraph algorithms such as centrality measures can be accessed directly in ggraph calls. This means that it is no longer necessary to precompute and store derived node and edge centrality measures on the graph in order to use them in a plot.\n\n\nClick to view code\ng &lt;- GAStech_graph %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department, \n                      size = centrality_betweenness()))\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\n7.3 Visualising Community\ntidygraph package inherits many of the community detection algorithms imbedded into igraph and makes them available to us, including Edge-betweenness (group_edge_betweenness), Leading eigenvector (group_leading_eigen), Fast-greedy (group_fast_greedy), Louvain (group_louvain), Walktrap (group_walktrap), Label propagation (group_label_prop), InfoMAP (group_infomap), Spinglass (group_spinglass), and Optimal (group_optimal). Some community algorithms are designed to take into account direction or weight, while others ignore it. Use this link to find out more about community detection functions provided by tidygraph,\nIn the code chunk below group_edge_betweenness() is used.\n\n\nClick to view code\ng &lt;- GAStech_graph %&gt;%\n  mutate(community = as.factor(group_edge_betweenness(weights = Weight, directed = TRUE))) %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = community))  \n\ng + theme_graph()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#building-interactive-network-graph-with-visnetwork",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#building-interactive-network-graph-with-visnetwork",
    "title": "Hands-on Exercise 6: Modelling, Visualising and Analysing Network Data with R",
    "section": "8 Building Interactive Network Graph with visNetwork",
    "text": "8 Building Interactive Network Graph with visNetwork\n\nvisNetwork() is a R package for network visualization, using vis.jsjavascript library.\nvisNetwork() function uses a nodes list and edges list to create an interactive graph.\n\nThe nodes list must include an “id” column, and the edge list must have “from” and “to” columns.\nThe function also plots the labels for the nodes, using the names of the actors from the “label” column in the node list.\n\nThe resulting graph is fun to play around with.\n\nYou can move the nodes and the graph will use an algorithm to keep the nodes properly spaced.\nYou can also zoom in and out on the plot and move it around to re-center it.\n\n\n\n8.1 Data preparation\nBefore we can plot the interactive network graph, we need to prepare the data model by using the code chunk below.\n\n\nClick to view code\nGAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  left_join(GAStech_nodes, by = c(\"sourceLabel\" = \"label\")) %&gt;%\n  rename(from = id) %&gt;%\n  left_join(GAStech_nodes, by = c(\"targetLabel\" = \"label\")) %&gt;%\n  rename(to = id) %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(from, to) %&gt;%\n    summarise(weight = n()) %&gt;%\n  filter(from!=to) %&gt;%\n  filter(weight &gt; 1) %&gt;%\n  ungroup()\n\n\n\n\n8.2 Plotting the first interactive network graph\nThe code chunk below will be used to plot an interactive network graph by using the data prepared.8.3 Working with layout\nIn the code chunk below, Fruchterman and Reingold layout is used.\n\n\nClick to view code\nvisNetwork(GAStech_nodes, \n           GAStech_edges_aggregated)\n\n\n\n\n\n\n\n\n8.3 Working with layout\nIn the code chunk below, Fruchterman and Reingold layout is used.\n\n\nClick to view code\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") \n\n\n\n\n\n\nVisit Igraph to find out more about visIgraphLayout’s argument.\n\n\n8.4 Working with visual attributes - Nodes\nvisNetwork() looks for a field called “group” in the nodes object and colour the nodes according to the values of the group field.\nThe code chunk below rename Department field to group.\n\n\nClick to view code\nGAStech_nodes &lt;- GAStech_nodes %&gt;%\n  rename(group = Department) \n\n\nWhen we rerun the code chunk below, visNetwork shades the nodes by assigning unique colour to each category in the group field.\n\n\nClick to view code\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\n\n\n8.5 Working with visual attributes - Edges\nIn the code run below visEdges() is used to symbolise the edges.\n- The argument arrows is used to define where to place the arrow.\n- The smooth argument is used to plot the edges using a smooth curve.\n\n\nClick to view code\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visEdges(arrows = \"to\", \n           smooth = list(enabled = TRUE, \n                         type = \"curvedCW\")) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\nVisit Option to find out more about visEdges’s argument.\n\n\n8.6 Interactivity\nIn the code chunk below, visOptions() is used to incorporate interactivity features in the data visualisation.\n\nThe argument highlightNearest highlights nearest when clicking a node.\nThe argument nodesIdSelection adds an id node selection creating an HTML select element.\n\n\n\nClick to view code\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visOptions(highlightNearest = TRUE,\n             nodesIdSelection = TRUE) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\nVisit Option to find out more about visOption’s argument."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#reference",
    "title": "Hands-on Exercise 6: Modelling, Visualising and Analysing Network Data with R",
    "section": "9 Reference",
    "text": "9 Reference"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html",
    "title": "Hands-on_Ex07",
    "section": "",
    "text": "By the end of this hands-on exercise you will be able create the followings data visualisation by using R packages:\n\nplotting a calender heatmap by using ggplot2 functions,\nplotting a cycle plot by using ggplot2 function,\nplotting a slopegraph\nplotting a horizon chart"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#learning-outcome",
    "title": "Hands-on_Ex07",
    "section": "",
    "text": "By the end of this hands-on exercise you will be able create the followings data visualisation by using R packages:\n\nplotting a calender heatmap by using ggplot2 functions,\nplotting a cycle plot by using ggplot2 function,\nplotting a slopegraph\nplotting a horizon chart"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#getting-started",
    "title": "Hands-on_Ex07",
    "section": "2 Getting Started",
    "text": "2 Getting Started"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#do-it-yourself",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#do-it-yourself",
    "title": "Hands-on_Ex07",
    "section": "3 Do It Yourself",
    "text": "3 Do It Yourself\nWrite a code chunk to check, install and launch the following R packages: scales, viridis, lubridate, ggthemes, gridExtra, readxl, knitr, data.table and tidyverse.\n\npacman::p_load(scales, viridis, lubridate, ggthemes, gridExtra, readxl, knitr, data.table, CGPfunctions, ggHoriPlot, tidyverse)\n\n4 Plotting Calendar Heatmap\nIn this section, you will learn how to plot a calender heatmap programmatically by using ggplot2 package.\n\nBy the end of this section, you will be able to:\n\nplot a calender heatmap by using ggplot2 functions and extension,\nto write function using R programming,\nto derive specific date and time related field by using base R and lubridate packages\nto perform data preparation task by using tidyr and dplyr packages.\n\n\n4.1 The Data\nFor the purpose of this hands-on exercise, eventlog.csv file will be used. This data file consists of 199,999 rows of time-series cyber attack records by country.\n\n\n4.2 Importing the data\nFirst, you will use the code chunk below to import eventlog.csv file into R environment and called the data frame as attacks.\n\nattacks &lt;- read_csv(\"data/eventlog.csv\")\n\n\n\n4.3 Examining the data structure\nIt is always a good practice to examine the imported data frame before further analysis is performed.\nFor example, kable() can be used to review the structure of the imported data frame.\n\nkable(head(attacks))\n\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai\n\n\n\n\n\nThere are three columns, namely timestamp, source_country and tz.\n\ntimestamp field stores date-time values in POSIXct format.\nsource_country field stores the source of the attack. It is in ISO 3166-1 alpha-2country code.\ntz field stores time zone of the source IP address.\n\n\n\n4.4 Data Preparation\nStep 1: Deriving weekday and hour of day fields\nBefore we can plot the calender heatmap, two new fields namely wkday and hourneed to be derived. In this step, we will write a function to perform the task.\n\nmake_hr_wkday &lt;- function(ts, sc, tz) {\n  real_times &lt;- ymd_hms(ts, \n                        tz = tz[1], \n                        quiet = TRUE)\n  dt &lt;- data.table(source_country = sc,\n                   wkday = weekdays(real_times),\n                   hour = hour(real_times))\n  return(dt)\n  }\n\n\n\n\n\n\n\nNote\n\n\n\nNote\n\nymd_hms() and hour() are from lubridate package, and\nweekdays() is a base R function.\n\n\n\nStep 2: Deriving the attacks tibble data frame\n\nwkday_levels &lt;- c('Saturday', 'Friday', \n                  'Thursday', 'Wednesday', \n                  'Tuesday', 'Monday', \n                  'Sunday')\n\nattacks &lt;- attacks %&gt;%\n  group_by(tz) %&gt;%\n  do(make_hr_wkday(.$timestamp, \n                   .$source_country, \n                   .$tz)) %&gt;% \n  ungroup() %&gt;% \n  mutate(wkday = factor(\n    wkday, levels = wkday_levels),\n    hour  = factor(\n      hour, levels = 0:23))\n\n\n\n\n\n\n\nNote\n\n\n\nNote\nBeside extracting the necessary data into attacks data frame, mutate() of dplyr package is used to convert wkday and hour fields into factor so they’ll be ordered when plotting\n\nymd_hms() and hour() are from lubridate package, and\nweekdays() is a base R function.\n\n\n\nTable below shows the tidy tibble table after processing.\n\nkable(head(attacks))\n\n\n\n\ntz\nsource_country\nwkday\nhour\n\n\n\n\nAfrica/Cairo\nBG\nSaturday\n20\n\n\nAfrica/Cairo\nTW\nSunday\n6\n\n\nAfrica/Cairo\nTW\nSunday\n8\n\n\nAfrica/Cairo\nCN\nSunday\n11\n\n\nAfrica/Cairo\nUS\nSunday\n15\n\n\nAfrica/Cairo\nCA\nMonday\n11\n\n\n\n\n\n\n\n4.5 Building the Calendar Heatmaps\n\ngrouped &lt;- attacks %&gt;% \n  count(wkday, hour) %&gt;% \n  ungroup() %&gt;%\n  na.omit()\n\nggplot(grouped, \n       aes(hour, \n           wkday, \n           fill = n)) + \ngeom_tile(color = \"white\", \n          size = 0.1) + \ntheme_tufte(base_family = \"Helvetica\") + \ncoord_equal() +\nscale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\nlabs(x = NULL, \n     y = NULL, \n     title = \"Attacks by weekday and time of day\") +\ntheme(axis.ticks = element_blank(),\n      plot.title = element_text(hjust = 0.5),\n      legend.title = element_text(size = 8),\n      legend.text = element_text(size = 6) )\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk\n\na tibble data table called grouped is derived by aggregating the attack by wkday and hour fields.\na new field called n is derived by using group_by() and count() functions.\nna.omit() is used to exclude missing value.\ngeom_tile() is used to plot tiles (grids) at each x and y position. color and sizearguments are used to specify the border color and line size of the tiles.\ntheme_tufte() of ggthemes package is used to remove unnecessary chart junk. To learn which visual components of default ggplot2 have been excluded, you are encouraged to comment out this line to examine the default plot.\ncoord_equal() is used to ensure the plot will have an aspect ratio of 1:1.\nscale_fill_gradient() function is used to creates a two colour gradient (low-high).\n\n\nThen we can simply group the count by hour and wkday and plot it, since we know that we have values for every combination there’s no need to further preprocess the data.\n\n\n4.6 Building Multiple Calendar Heatmaps\nChallenge: Building multiple heatmaps for the top four countries with the highest number of attacks.\n\n\n\n4.7 Plotting Multiple Calendar Heatmaps\nStep 1: Deriving attack by country object\nIn order to identify the top 4 countries with the highest number of attacks, you are required to do the followings:\n\ncount the number of attacks by country,\ncalculate the percent of attackes by country, and\nsave the results in a tibble data frame.\n\n\nattacks_by_country &lt;- count(\n  attacks, source_country) %&gt;%\n  mutate(percent = percent(n/sum(n))) %&gt;%\n  arrange(desc(n))\n\nStep 2: Preparing the tidy data frame\nIn this step, you are required to extract the attack records of the top 4 countries from attacks data frame and save the data in a new tibble data frame (i.e. top4_attacks).\n\ntop4 &lt;- attacks_by_country$source_country[1:4]\ntop4_attacks &lt;- attacks %&gt;%\n  filter(source_country %in% top4) %&gt;%\n  count(source_country, wkday, hour) %&gt;%\n  ungroup() %&gt;%\n  mutate(source_country = factor(\n    source_country, levels = top4)) %&gt;%\n  na.omit()\n\n\n\n4.8 Plotting Multiple Calendar Heatmaps\nStep 3: Plotting the Multiple Calender Heatmap by using ggplot2 package.\n\nggplot(top4_attacks, \n       aes(hour, \n           wkday, \n           fill = n)) + \n  geom_tile(color = \"white\", \n          size = 0.1) + \n  theme_tufte(base_family = \"Helvetica\") + \n  coord_equal() +\n  scale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\n  facet_wrap(~source_country, ncol = 2) +\n  labs(x = NULL, y = NULL, \n     title = \"Attacks on top 4 countries by weekday and time of day\") +\n  theme(axis.ticks = element_blank(),\n        axis.text.x = element_text(size = 7),\n        plot.title = element_text(hjust = 0.5),\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 6) )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#plotting-cycle-plot",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#plotting-cycle-plot",
    "title": "Hands-on_Ex07",
    "section": "5 Plotting Cycle Plot",
    "text": "5 Plotting Cycle Plot\nIn this section, you will learn how to plot a cycle plot showing the time-series patterns and trend of visitor arrivals from Vietnam programmatically by using ggplot2 functions.\n\n\n5.1 Step 1: Data Import\nFor the purpose of this hands-on exercise, arrivals_by_air.xlsx will be used.\nThe code chunk below imports arrivals_by_air.xlsx by using read_excel() of readxl package and save it as a tibble data frame called air.\n\nair &lt;- read_excel(\"data/arrivals_by_air.xlsx\")\n\n\n\n5.2 Step 2: Deriving month and year fields\nNext, two new fields called month and year are derived from Month-Year field.\n\nair$month &lt;- factor(month(air$`Month-Year`), \n                    levels=1:12, \n                    labels=month.abb, \n                    ordered=TRUE) \nair$year &lt;- year(ymd(air$`Month-Year`))\n\n\n\n5.3 Step 4: Extracting the target country\nNext, the code chunk below is use to extract data for the target country (i.e. Vietnam)\n\nVietnam &lt;- air %&gt;% \n  select(`Vietnam`, \n         month, \n         year) %&gt;%\n  filter(year &gt;= 2010)\n\n\n\n5.4 Step 5: Computing year average arrivals by month\nThe code chunk below uses group_by() and summarise() of dplyr to compute year average arrivals by month.\n\nhline.data &lt;- Vietnam %&gt;% \n  group_by(month) %&gt;%\n  summarise(avgvalue = mean(`Vietnam`))\n\n\n\n5.5 Srep 6: Plotting the cycle plot\nThe code chunk below is used to plot the cycle plot as shown in Slide 12/23.\n\nggplot() + \n  geom_line(data=Vietnam,\n            aes(x=year, \n                y=`Vietnam`, \n                group=month), \n            colour=\"black\") +\n  geom_hline(aes(yintercept=avgvalue), \n             data=hline.data, \n             linetype=6, \n             colour=\"red\", \n             size=0.5) + \n  facet_grid(~month) +\n  labs(axis.text.x = element_blank(),\n       title = \"Visitor arrivals from Vietnam by air, Jan 2010-Dec 2019\") +\n  xlab(\"\") +\n  ylab(\"No. of Visitors\") +\n  theme_tufte(base_family = \"Helvetica\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#plotting-slopegraph",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#plotting-slopegraph",
    "title": "Hands-on_Ex07",
    "section": "6 Plotting Slopegraph",
    "text": "6 Plotting Slopegraph\nIn this section you will learn how to plot a slopegraph by using R.\nBefore getting start, make sure that CGPfunctions has been installed and loaded onto R environment. Then, refer to Using newggslopegraph to learn more about the function. Lastly, read more about newggslopegraph() and its arguments by referring to this link.\n\n6.1 Step 1: Data Import\nImport the rice data set into R environment by using the code chunk below.\n\nrice &lt;- read_csv(\"data/rice.csv\")\n\n\n\n6.2 Step 2: Plotting the slopegraph\nNext, code chunk below will be used to plot a basic slopegraph as shown below.\n\nrice %&gt;% \n  mutate(Year = factor(Year)) %&gt;%\n  filter(Year %in% c(1961, 1980)) %&gt;%\n  newggslopegraph(Year, Yield, Country,\n                Title = \"Rice Yield of Top 11 Asian Counties\",\n                SubTitle = \"1961-1980\",\n                Caption = \"Prepared by: Dr. Kam Tin Seong\")\n\n\n\n\n\n\n\n\n\n\nThing to learn from the code chunk above\nFor effective data visualisation design, factor() is used convert the value type of Yearfield from numeric to factor."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08(c)/Hands-on_Ex08(c).html",
    "href": "Hands-on_Ex/Hands-on_Ex08(c)/Hands-on_Ex08(c).html",
    "title": "Hands-on_Ex08(c)",
    "section": "",
    "text": "In this in-class exercise, you will gain hands-on experience on using appropriate R methods to plot analytical maps.\n\n\n\nBy the end of this in-class exercise, you will be able to use appropriate functions of tmap and tidyverse to perform the following tasks:\n\nImporting geospatial data in rds format into R environment.\nCreating cartographic quality choropleth maps by using appropriate tmap functions.\nCreating rate map\nCreating percentile map\nCreating boxmap"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08(c)/Hands-on_Ex08(c).html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex08(c)/Hands-on_Ex08(c).html#overview",
    "title": "Hands-on_Ex08(c)",
    "section": "",
    "text": "In this in-class exercise, you will gain hands-on experience on using appropriate R methods to plot analytical maps.\n\n\n\nBy the end of this in-class exercise, you will be able to use appropriate functions of tmap and tidyverse to perform the following tasks:\n\nImporting geospatial data in rds format into R environment.\nCreating cartographic quality choropleth maps by using appropriate tmap functions.\nCreating rate map\nCreating percentile map\nCreating boxmap"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08(c)/Hands-on_Ex08(c).html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex08(c)/Hands-on_Ex08(c).html#getting-started",
    "title": "Hands-on_Ex08(c)",
    "section": "2 Getting Started",
    "text": "2 Getting Started\n\n2.1 Installing and loading packages\n\npacman::p_load(tmap, tidyverse, sf)\n\n\n\n2.2 Importing data\nFor the purpose of this hands-on exercise, a prepared data set called NGA_wp.rds will be used. The data set is a polygon feature data.frame providing information on water point of Nigeria at the LGA level. You can find the data set in the rds sub-direct of the hands-on data folder.\n\nNGA_wp &lt;- read_rds(\"data/rds/NGA_wp.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08(c)/Hands-on_Ex08(c).html#basic-choropleth-mapping",
    "href": "Hands-on_Ex/Hands-on_Ex08(c)/Hands-on_Ex08(c).html#basic-choropleth-mapping",
    "title": "Hands-on_Ex08(c)",
    "section": "3 Basic Choropleth Mapping",
    "text": "3 Basic Choropleth Mapping\n\n3.1 Visualising distribution of non-functional water point\n\np1 &lt;- tm_shape(NGA_wp) +\n  tm_fill(\"wp_functional\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\") +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Distribution of functional water point by LGAs\",\n            legend.outside = FALSE)\n\n\np2 &lt;- tm_shape(NGA_wp) +\n  tm_fill(\"total_wp\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\") +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Distribution of total  water point by LGAs\",\n            legend.outside = FALSE)\n\n\ntmap_arrange(p2, p1, nrow = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08(c)/Hands-on_Ex08(c).html#choropleth-map-for-rates",
    "href": "Hands-on_Ex/Hands-on_Ex08(c)/Hands-on_Ex08(c).html#choropleth-map-for-rates",
    "title": "Hands-on_Ex08(c)",
    "section": "4 Choropleth Map for Rates",
    "text": "4 Choropleth Map for Rates\nIn much of our readings we have now seen the importance to map rates rather than counts of things, and that is for the simple reason that water points are not equally distributed in space. That means that if we do not account for how many water points are somewhere, we end up mapping total water point size rather than our topic of interest.\n\n4.1 Deriving Proportion of Functional Water Points and Non-Functional Water Points\nWe will tabulate the proportion of functional water points and the proportion of non-functional water points in each LGA. In the following code chunk, mutate() from dplyr package is used to derive two fields, namely pct_functional and pct_nonfunctional.\n\nNGA_wp &lt;- NGA_wp %&gt;%\n  mutate(pct_functional = wp_functional/total_wp) %&gt;%\n  mutate(pct_nonfunctional = wp_nonfunctional/total_wp)\n\n\n\n4.2 Plotting map of rate\n\ntm_shape(NGA_wp) +\n  tm_fill(\"pct_functional\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\",\n          legend.hist = TRUE) +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Rate map of functional water point by LGAs\",\n            legend.outside = TRUE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08(c)/Hands-on_Ex08(c).html#extreme-value-maps",
    "href": "Hands-on_Ex/Hands-on_Ex08(c)/Hands-on_Ex08(c).html#extreme-value-maps",
    "title": "Hands-on_Ex08(c)",
    "section": "5 Extreme Value Maps",
    "text": "5 Extreme Value Maps\nExtreme value maps are variations of common choropleth maps where the classification is designed to highlight extreme values at the lower and upper end of the scale, with the goal of identifying outliers. These maps were developed in the spirit of spatializing EDA, i.e., adding spatial features to commonly used approaches in non-spatial EDA (Anselin 1994).\n\n5.1 Percentile Map\nThe percentile map is a special type of quantile map with six specific categories: 0-1%,1-10%, 10-50%,50-90%,90-99%, and 99-100%. The corresponding breakpoints can be derived by means of the base R quantile command, passing an explicit vector of cumulative probabilities as c(0,.01,.1,.5,.9,.99,1). Note that the begin and endpoint need to be included.\n\n5.1.1 Data Preparation\nStep 1: Exclude records with NA by using the code chunk below.\n\nNGA_wp &lt;- NGA_wp %&gt;%\n  drop_na()\n\nStep 2: Creating customised classification and extracting values\n\npercent &lt;- c(0,.01,.1,.5,.9,.99,1)\nvar &lt;- NGA_wp[\"pct_functional\"] %&gt;%\n  st_set_geometry(NULL)\nquantile(var[,1], percent)\n\n       0%        1%       10%       50%       90%       99%      100% \n0.0000000 0.0000000 0.2169811 0.4791667 0.8611111 1.0000000 1.0000000 \n\n\n\n\n5.1.2 Why writing functions?\nWriting a function has three big advantages over using copy-and-paste:\n\nYou can give a function an evocative name that makes your code easier to understand.\nAs requirements change, you only need to update code in one place, instead of many.\nYou eliminate the chance of making incidental mistakes when you copy and paste (i.e. updating a variable name in one place, but not in another).\n\nSource: Chapter 19: Functions of R for Data Science.\n\n\n5.1.3 Creating the get.var function\nFirstly, we will write an R function as shown below to extract a variable (i.e. wp_nonfunctional) as a vector out of an sf data.frame.\n\narguments:\n\nvname: variable name (as character, in quotes)\ndf: name of sf data frame\n\nreturns:\n\nv: vector with values (without a column name)\n\n\n\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% \n    st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\n\n\n5.1.4 A percentile mapping function\nNext, we will write a percentile mapping function by using the code chunk below.\n\npercentmap &lt;- function(vnam, df, legtitle=NA, mtitle=\"Percentile Map\"){\n  percent &lt;- c(0,.01,.1,.5,.9,.99,1)\n  var &lt;- get.var(vnam, df)\n  bperc &lt;- quantile(var, percent)\n  tm_shape(df) +\n  tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,\n             title=legtitle,\n             breaks=bperc,\n             palette=\"Blues\",\n          labels=c(\"&lt; 1%\", \"1% - 10%\", \"10% - 50%\", \"50% - 90%\", \"90% - 99%\", \"&gt; 99%\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"right\",\"bottom\"))\n}\n\n\n\n5.1.5 Test drive the percentile mapping function\nTo run the function, type the code chunk as shown below.\n\npercentmap(\"total_wp\", NGA_wp)\n\n\n\n\n\n\n\n\nNote that this is just a bare bones implementation. Additional arguments such as the title, legend positioning just to name a few of them, could be passed to customise various features of the map.\n\n\n\n5.2 Box map\nIn essence, a box map is an augmented quartile map, with an additional lower and upper category. When there are lower outliers, then the starting point for the breaks is the minimum value, and the second break is the lower fence. In contrast, when there are no lower outliers, then the starting point for the breaks will be the lower fence, and the second break is the minimum value (there will be no observations that fall in the interval between the lower fence and the minimum value).\n\nggplot(data = NGA_wp,\n       aes(x = \"\",\n           y = wp_nonfunctional)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\nDisplaying summary statistics on a choropleth map by using the basic principles of boxplot.\nTo create a box map, a custom breaks specification will be used. However, there is a complication. The break points for the box map vary depending on whether lower or upper outliers are present.\n\n\n5.2.1 Creating the boxbreaks function\nThe code chunk below is an R function that creating break points for a box map.\n\narguments:\n\nv: vector with observations\nmult: multiplier for IQR (default 1.5)\n\nreturns:\n\nbb: vector with 7 break points compute quartile and fences\n\n\n\nboxbreaks &lt;- function(v,mult=1.5) {\n  qv &lt;- unname(quantile(v))\n  iqr &lt;- qv[4] - qv[2]\n  upfence &lt;- qv[4] + mult * iqr\n  lofence &lt;- qv[2] - mult * iqr\n  # initialize break points vector\n  bb &lt;- vector(mode=\"numeric\",length=7)\n  # logic for lower and upper fences\n  if (lofence &lt; qv[1]) {  # no lower outliers\n    bb[1] &lt;- lofence\n    bb[2] &lt;- floor(qv[1])\n  } else {\n    bb[2] &lt;- lofence\n    bb[1] &lt;- qv[1]\n  }\n  if (upfence &gt; qv[5]) { # no upper outliers\n    bb[7] &lt;- upfence\n    bb[6] &lt;- ceiling(qv[5])\n  } else {\n    bb[6] &lt;- upfence\n    bb[7] &lt;- qv[5]\n  }\n  bb[3:5] &lt;- qv[2:4]\n  return(bb)\n}\n\n\n\n5.2.2 Creating the get.var function\nThe code chunk below is an R function to extract a variable as a vector out of an sf data frame.\n\narguments:\n\nvname: variable name (as character, in quotes)\ndf: name of sf data frame\n\nreturns:\n\nv: vector with values (without a column name)\n\n\n\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\n\n\n5.2.3 Test drive the newly created function\nLet’s test the newly created function\n\nvar &lt;- get.var(\"wp_nonfunctional\", NGA_wp) \nboxbreaks(var)\n\n[1] -56.5   0.0  14.0  34.0  61.0 131.5 278.0\n\n\n\n\n5.2.4 Boxmap function\nThe code chunk below is an R function to create a box map. - arguments: - vnam: variable name (as character, in quotes) - df: simple features polygon layer - legtitle: legend title - mtitle: map title - mult: multiplier for IQR - returns: - a tmap-element (plots a map)\n\nboxmap &lt;- function(vnam, df, \n                   legtitle=NA,\n                   mtitle=\"Box Map\",\n                   mult=1.5){\n  var &lt;- get.var(vnam,df)\n  bb &lt;- boxbreaks(var)\n  tm_shape(df) +\n    tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,title=legtitle,\n             breaks=bb,\n             palette=\"Blues\",\n          labels = c(\"lower outlier\", \n                     \"&lt; 25%\", \n                     \"25% - 50%\", \n                     \"50% - 75%\",\n                     \"&gt; 75%\", \n                     \"upper outlier\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"left\",\n                               \"top\"))\n}\ntmap_mode(\"plot\")\nboxmap(\"wp_nonfunctional\", NGA_wp)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08(b)/Hands-on_Ex08(b).html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex08(b)/Hands-on_Ex08(b).html#learning-outcome",
    "title": "Hands-on_Ex08(b)",
    "section": "1.1.1 Learning outcome",
    "text": "1.1.1 Learning outcome\nBy the end of this hands-on exercise, you will acquire the following skills by using appropriate R packages:\n\nTo import an aspatial data file into R.\nTo convert it into simple point feature data frame and at the same time, to assign an appropriate projection reference to the newly create simple point feature data frame.\nTo plot interactive proportional symbol maps."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08(b)/Hands-on_Ex08(b).html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex08(b)/Hands-on_Ex08(b).html#the-data",
    "title": "Hands-on_Ex08(b)",
    "section": "2.1 The data",
    "text": "2.1 The data\nThe data set use for this hands-on exercise is called SGPools_svy21. The data is in csv file format.\nFigure below shows the first 15 records of SGPools_svy21.csv. It consists of seven columns. The XCOORD and YCOORD columns are the x-coordinates and y-coordinates of SingPools outlets and branches. They are in Singapore SVY21 Projected Coordinates System."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08(b)/Hands-on_Ex08(b).html#data-import-and-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex08(b)/Hands-on_Ex08(b).html#data-import-and-preparation",
    "title": "Hands-on_Ex08(b)",
    "section": "2.2 Data Import and Preparation",
    "text": "2.2 Data Import and Preparation\nThe code chunk below uses read_csv() function of readr package to import SGPools_svy21.csv into R as a tibble data frame called sgpools.\n\nsgpools &lt;- read_csv(\"data/aspatial/SGPools_svy21.csv\")\n\nAfter importing the data file into R, it is important for us to examine if the data file has been imported correctly.\nThe code chunk below shows list() is used to do the job.\n\nlist(sgpools)\n\n[[1]]\n# A tibble: 306 × 7\n   NAME           ADDRESS POSTCODE XCOORD YCOORD `OUTLET TYPE` `Gp1Gp2 Winnings`\n   &lt;chr&gt;          &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                     &lt;dbl&gt;\n 1 Livewire (Mar… 2 Bayf…    18972 30842. 29599. Branch                        5\n 2 Livewire (Res… 26 Sen…    98138 26704. 26526. Branch                       11\n 3 SportsBuzz (K… Lotus …   738078 20118. 44888. Branch                        0\n 4 SportsBuzz (P… 1 Sele…   188306 29777. 31382. Branch                       44\n 5 Prime Serango… Blk 54…   552542 32239. 39519. Branch                        0\n 6 Singapore Poo… 1A Woo…   731001 21012. 46987. Branch                        3\n 7 Singapore Poo… Blk 64…   370064 33990. 34356. Branch                       17\n 8 Singapore Poo… Blk 88…   370088 33847. 33976. Branch                       16\n 9 Singapore Poo… Blk 30…   540308 33910. 41275. Branch                       21\n10 Singapore Poo… Blk 20…   560202 29246. 38943. Branch                       25\n# ℹ 296 more rows\n\n\nNotice that the sgpools data in tibble data frame and not the common R data frame."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08(b)/Hands-on_Ex08(b).html#creating-a-sf-data-frame-from-an-aspatial-data-frame",
    "href": "Hands-on_Ex/Hands-on_Ex08(b)/Hands-on_Ex08(b).html#creating-a-sf-data-frame-from-an-aspatial-data-frame",
    "title": "Hands-on_Ex08(b)",
    "section": "2.3 Creating a sf data frame from an aspatial data frame",
    "text": "2.3 Creating a sf data frame from an aspatial data frame\nThe code chunk below converts sgpools data frame into a simple feature data frame by using st_as_sf() of sf packages\n\nsgpools_sf &lt;- st_as_sf(sgpools, \n                       coords = c(\"XCOORD\", \"YCOORD\"),\n                       crs= 3414)\n\nThings to learn from the arguments above:\n\nThe coords argument requires you to provide the column name of the x-coordinates first then followed by the column name of the y-coordinates.\nThe crs argument required you to provide the coordinates system in epsg format. EPSG: 3414 is Singapore SVY21 Projected Coordinate System. You can search for other country’s epsg code by refering to epsg.io.\n\nFigure below shows the data table of sgpools_sf. Notice that a new column called geometry has been added into the data frame.\n\nYou can display the basic information of the newly created sgpools_sf by using the code chunk below.\n\nlist(sgpools_sf)\n\n[[1]]\nSimple feature collection with 306 features and 5 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 7844.194 ymin: 26525.7 xmax: 45176.57 ymax: 47987.13\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 306 × 6\n   NAME                         ADDRESS POSTCODE `OUTLET TYPE` `Gp1Gp2 Winnings`\n * &lt;chr&gt;                        &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;                     &lt;dbl&gt;\n 1 Livewire (Marina Bay Sands)  2 Bayf…    18972 Branch                        5\n 2 Livewire (Resorts World Sen… 26 Sen…    98138 Branch                       11\n 3 SportsBuzz (Kranji)          Lotus …   738078 Branch                        0\n 4 SportsBuzz (PoMo)            1 Sele…   188306 Branch                       44\n 5 Prime Serangoon North        Blk 54…   552542 Branch                        0\n 6 Singapore Pools Woodlands C… 1A Woo…   731001 Branch                        3\n 7 Singapore Pools 64 Circuit … Blk 64…   370064 Branch                       17\n 8 Singapore Pools 88 Circuit … Blk 88…   370088 Branch                       16\n 9 Singapore Pools Anchorvale … Blk 30…   540308 Branch                       21\n10 Singapore Pools Ang Mo Kio … Blk 20…   560202 Branch                       25\n# ℹ 296 more rows\n# ℹ 1 more variable: geometry &lt;POINT [m]&gt;\n\n\nThe output shows that sgppols_sf is in point feature class. It’s epsg ID is 3414. The bbox provides information of the extend of the geospatial data."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08(b)/Hands-on_Ex08(b).html#it-all-started-with-an-interactive-point-symbol-map",
    "href": "Hands-on_Ex/Hands-on_Ex08(b)/Hands-on_Ex08(b).html#it-all-started-with-an-interactive-point-symbol-map",
    "title": "Hands-on_Ex08(b)",
    "section": "3.1 It all started with an interactive point symbol map",
    "text": "3.1 It all started with an interactive point symbol map\nThe code chunks below are used to create an interactive point symbol map.\n\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"red\",\n           size = 1,\n           border.col = \"black\",\n           border.lwd = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08(b)/Hands-on_Ex08(b).html#lets-make-it-proportional",
    "href": "Hands-on_Ex/Hands-on_Ex08(b)/Hands-on_Ex08(b).html#lets-make-it-proportional",
    "title": "Hands-on_Ex08(b)",
    "section": "3.2 Lets make it proportional",
    "text": "3.2 Lets make it proportional\nTo draw a proportional symbol map, we need to assign a numerical variable to the size visual attribute. The code chunks below show that the variable Gp1Gp2Winningsis assigned to size visual attribute.\n\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"red\",\n           size = \"Gp1Gp2 Winnings\",\n           border.col = \"black\",\n           border.lwd = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08(b)/Hands-on_Ex08(b).html#lets-give-it-a-different-colour",
    "href": "Hands-on_Ex/Hands-on_Ex08(b)/Hands-on_Ex08(b).html#lets-give-it-a-different-colour",
    "title": "Hands-on_Ex08(b)",
    "section": "3.3 Lets give it a different colour",
    "text": "3.3 Lets give it a different colour\nThe proportional symbol map can be further improved by using the colour visual attribute. In the code chunks below, OUTLET_TYPE variable is used as the colour attribute variable.\n\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"OUTLET TYPE\", \n          size = \"Gp1Gp2 Winnings\",\n          border.col = \"black\",\n          border.lwd = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08(b)/Hands-on_Ex08(b).html#i-have-a-twin-brothers",
    "href": "Hands-on_Ex/Hands-on_Ex08(b)/Hands-on_Ex08(b).html#i-have-a-twin-brothers",
    "title": "Hands-on_Ex08(b)",
    "section": "3.4 I have a twin brothers :)",
    "text": "3.4 I have a twin brothers :)\nAn impressive and little-know feature of tmap’s view mode is that it also works with faceted plots. The argument sync in tm_facets() can be used in this case to produce multiple maps with synchronised zoom and pan settings.\n\ntm_shape(sgpools_sf) +\n  tm_bubbles(col = \"OUTLET TYPE\", \n          size = \"Gp1Gp2 Winnings\",\n          border.col = \"black\",\n          border.lwd = 1) +\n  tm_facets(by= \"OUTLET TYPE\",\n            nrow = 1,\n            sync = TRUE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09(b)/Hands-on_Ex09(b).html",
    "href": "Hands-on_Ex/Hands-on_Ex09(b)/Hands-on_Ex09(b).html",
    "title": "Hands-on_Ex09(b)",
    "section": "",
    "text": "Heatmaps visualise data through variations in colouring. When applied to a tabular format, heatmaps are useful for cross-examining multivariate data, through placing variables in the columns and observation (or records) in rowa and colouring the cells within the table. Heatmaps are good for showing variance across multiple variables, revealing any patterns, displaying whether any variables are similar to each other, and for detecting if any correlations exist in-between them.\nIn this hands-on exercise, you will gain hands-on experience on using R to plot static and interactive heatmap for visualising and analysing multivariate data.\n\n\n\nBefore you get started, you are required to open a new Quarto document. Keep the default html as the authoring format.\nNext, you will use the code chunk below to install and launch seriation, heatmaply, dendextend and tidyverse in RStudio.\n\npacman::p_load(seriation, dendextend, heatmaply, tidyverse)\n\n\n\n\nIn this hands-on exercise, the data of World Happines 2018 report will be used. The data set is downloaded from here. The original data set is in Microsoft Excel format. It has been extracted and saved in csv file called WHData-2018.csv.\n\n\nIn the code chunk below, read_csv() of readr is used to import WHData-2018.csv into R and parsed it into tibble R data frame format.\n\nwh &lt;- read_csv(\"data/WHData-2018.csv\")\nglimpse(head(wh))\n\nRows: 6\nColumns: 12\n$ Country                        &lt;chr&gt; \"Albania\", \"Bosnia and Herzegovina\", \"B…\n$ Region                         &lt;chr&gt; \"Central and Eastern Europe\", \"Central …\n$ `Happiness score`              &lt;dbl&gt; 4.586, 5.129, 4.933, 5.321, 6.711, 5.739\n$ `Whisker-high`                 &lt;dbl&gt; 4.695, 5.224, 5.022, 5.398, 6.783, 5.815\n$ `Whisker-low`                  &lt;dbl&gt; 4.477, 5.035, 4.844, 5.244, 6.639, 5.663\n$ Dystopia                       &lt;dbl&gt; 1.462, 1.883, 1.219, 1.769, 2.494, 1.457\n$ `GDP per capita`               &lt;dbl&gt; 0.916, 0.915, 1.054, 1.115, 1.233, 1.200\n$ `Social support`               &lt;dbl&gt; 0.817, 1.078, 1.515, 1.161, 1.489, 1.532\n$ `Healthy life expectancy`      &lt;dbl&gt; 0.790, 0.758, 0.712, 0.737, 0.854, 0.737\n$ `Freedom to make life choices` &lt;dbl&gt; 0.419, 0.280, 0.359, 0.380, 0.543, 0.553\n$ Generosity                     &lt;dbl&gt; 0.149, 0.216, 0.064, 0.120, 0.064, 0.086\n$ `Perceptions of corruption`    &lt;dbl&gt; 0.032, 0.000, 0.009, 0.039, 0.034, 0.174\n\n\nThe output tibbled data frame is called wh.\n\n\n\nNext, we need to change the rows by country name instead of row number by using the code chunk below\n\nrow.names(wh) &lt;- wh$Country\n\nNotice that the row number has been replaced into the country name.\n\n\n\nThe data was loaded into a data frame, but it has to be a data matrix to make your heatmap.\nThe code chunk below will be used to transform wh data frame into a data matrix.\n\nwh1 &lt;- dplyr::select(wh, c(3, 7:12))\nwh_matrix &lt;- data.matrix(wh)\n\nNotice that wh_matrix is in R matrix format.\n\n\n\n\nThere are many R packages and functions can be used to drawing static heatmaps, they are:\n\nheatmap()of R stats package. It draws a simple heatmap.\nheatmap.2() of gplots R package. It draws an enhanced heatmap compared to the R base function.\npheatmap() of pheatmap R package. pheatmap package also known as Pretty Heatmap. The package provides functions to draws pretty heatmaps and provides more control to change the appearance of heatmaps.\nComplexHeatmap package of R/Bioconductor package. The package draws, annotates and arranges complex heatmaps (very useful for genomic data analysis). The full reference guide of the package is available here.\nsuperheat package: A Graphical Tool for Exploring Complex Datasets Using Heatmaps. A system for generating extendable and customizable heatmaps for exploring complex datasets, including big data and data with multiple data types. The full reference guide of the package is available here.\n\nIn this section, you will learn how to plot static heatmaps by using heatmap() of R Stats package.\n\n\nIn this sub-section, we will plot a heatmap by using heatmap() of Base Stats. The code chunk is given below.\n\nwh_heatmap &lt;- heatmap(wh_matrix,\n                      Rowv=NA, Colv=NA)\n\n\n\n\n\n\n\n\nNote:\n\nBy default, heatmap() plots a cluster heatmap. The arguments Rowv=NA and Colv=NA are used to switch off the option of plotting the row and column dendrograms.\n\nTo plot a cluster heatmap, we just have to use the default as shown in the code chunk below.\n\nwh_heatmap &lt;- heatmap(wh_matrix)\n\n\n\n\n\n\n\n\nNote:\n\nThe order of both rows and columns is different compare to the native wh_matrix. This is because heatmap do a reordering using clusterisation: it calculates the distance between each pair of rows and columns and try to order them by similarity. Moreover, the corresponding dendrogram are provided beside the heatmap.\n\nHere, red cells denotes small values, and red small ones. This heatmap is not really informative. Indeed, the Happiness Score variable have relatively higher values, what makes that the other variables with small values all look the same. Thus, we need to normalize this matrix. This is done using the scale argument. It can be applied to rows or to columns following your needs.\nThe code chunk below normalises the matrix column-wise.\n\nwh_heatmap &lt;- heatmap(wh_matrix,\n                      scale=\"column\",\n                      cexRow = 0.6, \n                      cexCol = 0.8,\n                      margins = c(10, 4))\n\n\n\n\n\n\n\n\nNotice that the values are scaled now. Also note that margins argument is used to ensure that the entire x-axis labels are displayed completely and, cexRow and cexCol arguments are used to define the font size used for y-axis and x-axis labels respectively.\n\n\n\n\nheatmaply is an R package for building interactive cluster heatmap that can be shared online as a stand-alone HTML file. It is designed and maintained by Tal Galili.\nBefore we get started, you should review the Introduction to Heatmaply to have an overall understanding of the features and functions of Heatmaply package. You are also required to have the user manualof the package handy with you for reference purposes.\nIn this section, you will gain hands-on experience on using heatmaply to design an interactive cluster heatmap. We will still use the wh_matrix as the input data.\n\n\n\nheatmaply(mtcars)\n\n\n\n\n\nThe code chunk below shows the basic syntax needed to create n interactive heatmap by using heatmaply package.\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)])\n\n\n\n\n\nNote that:\n\nDifferent from heatmap(), for heatmaply() the default horizontal dendrogram is placed on the left hand side of the heatmap.\nThe text label of each raw, on the other hand, is placed on the right hand side of the heat map.\nWhen the x-axis marker labels are too long, they will be rotated by 135 degree from the north.\n\n\n\n\nWhen analysing multivariate data set, it is very common that the variables in the data sets includes values that reflect different types of measurement. In general, these variables’ values have their own range. In order to ensure that all the variables have comparable values, data transformation are commonly used before clustering.\nThree main data transformation methods are supported by heatmaply(), namely: scale, normalise and percentilse.\n\n\n\nWhen all variables are came from or assumed to come from some normal distribution, then scaling (i.e.: subtract the mean and divide by the standard deviation) would bring them all close to the standard normal distribution.\nIn such a case, each value would reflect the distance from the mean in units of standard deviation.\nThe scale argument in heatmaply() supports column and row scaling.\n\nThe code chunk below is used to scale variable values columewise.\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)],\n          scale = \"column\")\n\n\n\n\n\n\n\n\n\nWhen variables in the data comes from possibly different (and non-normal) distributions, the normalize function can be used to bring data to the 0 to 1 scale by subtracting the minimum and dividing by the maximum of all observations.\nThis preserves the shape of each variable’s distribution while making them easily comparable on the same “scale”.\n\nDifferent from Scaling, the normalise method is performed on the input data set i.e. wh_matrix as shown in the code chunk below.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\n\n\n\n\nThis is similar to ranking the variables, but instead of keeping the rank values, divide them by the maximal rank.\nThis is done by using the ecdf of the variables on their own values, bringing each value to its empirical percentile.\nThe benefit of the percentize function is that each value has a relatively clear interpretation, it is the percent of observations that got that value or below it.\n\nSimilar to Normalize method, the Percentize method is also performed on the input data set i.e. wh_matrix as shown in the code chunk below.\n\nheatmaply(percentize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\n\n\n\n\nheatmaply supports a variety of hierarchical clustering algorithm. The main arguments provided are:\n\ndistfun: function used to compute the distance (dissimilarity) between both rows and columns. Defaults to dist. The options “pearson”, “spearman” and “kendall” can be used to use correlation-based clustering, which uses as.dist(1 - cor(t(x))) as the distance metric (using the specified correlation method).\nhclustfun: function used to compute the hierarchical clustering when Rowv or Colv are not dendrograms. Defaults to hclust.\ndist_method default is NULL, which results in “euclidean” to be used. It can accept alternative character strings indicating the method to be passed to distfun. By default distfun is “dist”” hence this can be one of “euclidean”, “maximum”, “manhattan”, “canberra”, “binary” or “minkowski”.\nhclust_method default is NULL, which results in “complete” method to be used. It can accept alternative character strings indicating the method to be passed to hclustfun. By default hclustfun is hclust hence this can be one of “ward.D”, “ward.D2”, “single”, “complete”, “average” (= UPGMA), “mcquitty” (= WPGMA), “median” (= WPGMC) or “centroid” (= UPGMC).\n\nIn general, a clustering model can be calibrated either manually or statistically.\n\n\n\nIn the code chunk below, the heatmap is plotted by using hierachical clustering algorithm with “Euclidean distance” and “ward.D” method.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\")\n\n\n\n\n\n\n\n\nIn order to determine the best clustering method and number of cluster the dend_expend() and find_k()functions of dendextend package will be used.\nFirst, the dend_expend() will be used to determine the recommended clustering method to be used.\n\nwh_d &lt;- dist(normalize(wh_matrix[, -c(1, 2, 4, 5)]), method = \"euclidean\")\ndend_expend(wh_d)[[3]]\n\n  dist_methods hclust_methods     optim\n1      unknown         ward.D 0.6137851\n2      unknown        ward.D2 0.6289186\n3      unknown         single 0.4774362\n4      unknown       complete 0.6434009\n5      unknown        average 0.6701688\n6      unknown       mcquitty 0.5020102\n7      unknown         median 0.5901833\n8      unknown       centroid 0.6338734\n\n\nThe output table shows that “average” method should be used because it gave the high optimum value.\nNext, find_k() is used to determine the optimal number of cluster.\n\nwh_clust &lt;- hclust(wh_d, method = \"average\")\nnum_k &lt;- find_k(wh_clust)\nplot(num_k)\n\n\n\n\n\n\n\n\nFigure above shows that k=3 would be good.\nWith reference to the statistical analysis results, we can prepare the code chunk as shown below.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"average\",\n          k_row = 3)\n\n\n\n\n\n\n\n\nOne of the problems with hierarchical clustering is that it doesn’t actually place the rows in a definite order, it merely constrains the space of possible orderings. Take three items A, B and C. If you ignore reflections, there are three possible orderings: ABC, ACB, BAC. If clustering them gives you ((A+B)+C) as a tree, you know that C can’t end up between A and B, but it doesn’t tell you which way to flip the A+B cluster. It doesn’t tell you if the ABC ordering will lead to a clearer-looking heatmap than the BAC ordering.\nheatmaply uses the seriation package to find an optimal ordering of rows and columns. Optimal means to optimize the Hamiltonian path length that is restricted by the dendrogram structure. This, in other words, means to rotate the branches so that the sum of distances between each adjacent leaf (label) will be minimized. This is related to a restricted version of the travelling salesman problem.\nHere we meet our first seriation algorithm: Optimal Leaf Ordering (OLO). This algorithm starts with the output of an agglomerative clustering algorithm and produces a unique ordering, one that flips the various branches of the dendrogram around so as to minimize the sum of dissimilarities between adjacent leaves. Here is the result of applying Optimal Leaf Ordering to the same clustering result as the heatmap above.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"OLO\")\n\n\n\n\n\nThe default options is “OLO” (Optimal leaf ordering) which optimizes the above criterion (in O(n^4)). Another option is “GW” (Gruvaeus and Wainer) which aims for the same goal but uses a potentially faster heuristic.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"GW\")\n\n\n\n\n\nThe option “mean” gives the output we would get by default from heatmap functions in other packages such as gplots::heatmap.2.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"mean\")\n\n\n\n\n\nThe option “none” gives us the dendrograms without any rotation that is based on the data matrix.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"none\")\n\n\n\n\n\n\n\n\nThe default colour palette uses by heatmaply is viridis. heatmaply users, however, can use other colour palettes in order to improve the aestheticness and visual friendliness of the heatmap.\nIn the code chunk below, the Blues colour palette of rColorBrewer is used\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"none\",\n          colors = Blues)\n\n\n\n\n\n5.8 The finishing touch Beside providing a wide collection of arguments for meeting the statistical analysis needs, heatmaply also provides many plotting features to ensure cartographic quality heatmap can be produced.\nIn the code chunk below the following arguments are used:\nk_row is used to produce 5 groups. margins is used to change the top margin to 60 and row margin to 200. fontsizw_row and fontsize_col are used to change the font size for row and column labels to 4. main is used to write the main title of the plot. xlab and ylab are used to write the x-axis and y-axis labels respectively.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          Colv=NA,\n          seriate = \"none\",\n          colors = Blues,\n          k_row = 5,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"World Happiness Score and Variables by Country, 2018 \\nDataTransformation using Normalise Method\",\n          xlab = \"World Happiness Indicators\",\n          ylab = \"World Countries\"\n          )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09(b)/Hands-on_Ex09(b).html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex09(b)/Hands-on_Ex09(b).html#overview",
    "title": "Hands-on_Ex09(b)",
    "section": "",
    "text": "Heatmaps visualise data through variations in colouring. When applied to a tabular format, heatmaps are useful for cross-examining multivariate data, through placing variables in the columns and observation (or records) in rowa and colouring the cells within the table. Heatmaps are good for showing variance across multiple variables, revealing any patterns, displaying whether any variables are similar to each other, and for detecting if any correlations exist in-between them.\nIn this hands-on exercise, you will gain hands-on experience on using R to plot static and interactive heatmap for visualising and analysing multivariate data."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09(b)/Hands-on_Ex09(b).html#installing-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex09(b)/Hands-on_Ex09(b).html#installing-and-launching-r-packages",
    "title": "Hands-on_Ex09(b)",
    "section": "",
    "text": "Before you get started, you are required to open a new Quarto document. Keep the default html as the authoring format.\nNext, you will use the code chunk below to install and launch seriation, heatmaply, dendextend and tidyverse in RStudio.\n\npacman::p_load(seriation, dendextend, heatmaply, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09(b)/Hands-on_Ex09(b).html#importing-and-preparing-the-data-set",
    "href": "Hands-on_Ex/Hands-on_Ex09(b)/Hands-on_Ex09(b).html#importing-and-preparing-the-data-set",
    "title": "Hands-on_Ex09(b)",
    "section": "",
    "text": "In this hands-on exercise, the data of World Happines 2018 report will be used. The data set is downloaded from here. The original data set is in Microsoft Excel format. It has been extracted and saved in csv file called WHData-2018.csv.\n\n\nIn the code chunk below, read_csv() of readr is used to import WHData-2018.csv into R and parsed it into tibble R data frame format.\n\nwh &lt;- read_csv(\"data/WHData-2018.csv\")\nglimpse(head(wh))\n\nRows: 6\nColumns: 12\n$ Country                        &lt;chr&gt; \"Albania\", \"Bosnia and Herzegovina\", \"B…\n$ Region                         &lt;chr&gt; \"Central and Eastern Europe\", \"Central …\n$ `Happiness score`              &lt;dbl&gt; 4.586, 5.129, 4.933, 5.321, 6.711, 5.739\n$ `Whisker-high`                 &lt;dbl&gt; 4.695, 5.224, 5.022, 5.398, 6.783, 5.815\n$ `Whisker-low`                  &lt;dbl&gt; 4.477, 5.035, 4.844, 5.244, 6.639, 5.663\n$ Dystopia                       &lt;dbl&gt; 1.462, 1.883, 1.219, 1.769, 2.494, 1.457\n$ `GDP per capita`               &lt;dbl&gt; 0.916, 0.915, 1.054, 1.115, 1.233, 1.200\n$ `Social support`               &lt;dbl&gt; 0.817, 1.078, 1.515, 1.161, 1.489, 1.532\n$ `Healthy life expectancy`      &lt;dbl&gt; 0.790, 0.758, 0.712, 0.737, 0.854, 0.737\n$ `Freedom to make life choices` &lt;dbl&gt; 0.419, 0.280, 0.359, 0.380, 0.543, 0.553\n$ Generosity                     &lt;dbl&gt; 0.149, 0.216, 0.064, 0.120, 0.064, 0.086\n$ `Perceptions of corruption`    &lt;dbl&gt; 0.032, 0.000, 0.009, 0.039, 0.034, 0.174\n\n\nThe output tibbled data frame is called wh.\n\n\n\nNext, we need to change the rows by country name instead of row number by using the code chunk below\n\nrow.names(wh) &lt;- wh$Country\n\nNotice that the row number has been replaced into the country name.\n\n\n\nThe data was loaded into a data frame, but it has to be a data matrix to make your heatmap.\nThe code chunk below will be used to transform wh data frame into a data matrix.\n\nwh1 &lt;- dplyr::select(wh, c(3, 7:12))\nwh_matrix &lt;- data.matrix(wh)\n\nNotice that wh_matrix is in R matrix format."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09(b)/Hands-on_Ex09(b).html#static-heatmap",
    "href": "Hands-on_Ex/Hands-on_Ex09(b)/Hands-on_Ex09(b).html#static-heatmap",
    "title": "Hands-on_Ex09(b)",
    "section": "",
    "text": "There are many R packages and functions can be used to drawing static heatmaps, they are:\n\nheatmap()of R stats package. It draws a simple heatmap.\nheatmap.2() of gplots R package. It draws an enhanced heatmap compared to the R base function.\npheatmap() of pheatmap R package. pheatmap package also known as Pretty Heatmap. The package provides functions to draws pretty heatmaps and provides more control to change the appearance of heatmaps.\nComplexHeatmap package of R/Bioconductor package. The package draws, annotates and arranges complex heatmaps (very useful for genomic data analysis). The full reference guide of the package is available here.\nsuperheat package: A Graphical Tool for Exploring Complex Datasets Using Heatmaps. A system for generating extendable and customizable heatmaps for exploring complex datasets, including big data and data with multiple data types. The full reference guide of the package is available here.\n\nIn this section, you will learn how to plot static heatmaps by using heatmap() of R Stats package.\n\n\nIn this sub-section, we will plot a heatmap by using heatmap() of Base Stats. The code chunk is given below.\n\nwh_heatmap &lt;- heatmap(wh_matrix,\n                      Rowv=NA, Colv=NA)\n\n\n\n\n\n\n\n\nNote:\n\nBy default, heatmap() plots a cluster heatmap. The arguments Rowv=NA and Colv=NA are used to switch off the option of plotting the row and column dendrograms.\n\nTo plot a cluster heatmap, we just have to use the default as shown in the code chunk below.\n\nwh_heatmap &lt;- heatmap(wh_matrix)\n\n\n\n\n\n\n\n\nNote:\n\nThe order of both rows and columns is different compare to the native wh_matrix. This is because heatmap do a reordering using clusterisation: it calculates the distance between each pair of rows and columns and try to order them by similarity. Moreover, the corresponding dendrogram are provided beside the heatmap.\n\nHere, red cells denotes small values, and red small ones. This heatmap is not really informative. Indeed, the Happiness Score variable have relatively higher values, what makes that the other variables with small values all look the same. Thus, we need to normalize this matrix. This is done using the scale argument. It can be applied to rows or to columns following your needs.\nThe code chunk below normalises the matrix column-wise.\n\nwh_heatmap &lt;- heatmap(wh_matrix,\n                      scale=\"column\",\n                      cexRow = 0.6, \n                      cexCol = 0.8,\n                      margins = c(10, 4))\n\n\n\n\n\n\n\n\nNotice that the values are scaled now. Also note that margins argument is used to ensure that the entire x-axis labels are displayed completely and, cexRow and cexCol arguments are used to define the font size used for y-axis and x-axis labels respectively."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09(b)/Hands-on_Ex09(b).html#creating-interactive-heatmap",
    "href": "Hands-on_Ex/Hands-on_Ex09(b)/Hands-on_Ex09(b).html#creating-interactive-heatmap",
    "title": "Hands-on_Ex09(b)",
    "section": "",
    "text": "heatmaply is an R package for building interactive cluster heatmap that can be shared online as a stand-alone HTML file. It is designed and maintained by Tal Galili.\nBefore we get started, you should review the Introduction to Heatmaply to have an overall understanding of the features and functions of Heatmaply package. You are also required to have the user manualof the package handy with you for reference purposes.\nIn this section, you will gain hands-on experience on using heatmaply to design an interactive cluster heatmap. We will still use the wh_matrix as the input data.\n\n\n\nheatmaply(mtcars)\n\n\n\n\n\nThe code chunk below shows the basic syntax needed to create n interactive heatmap by using heatmaply package.\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)])\n\n\n\n\n\nNote that:\n\nDifferent from heatmap(), for heatmaply() the default horizontal dendrogram is placed on the left hand side of the heatmap.\nThe text label of each raw, on the other hand, is placed on the right hand side of the heat map.\nWhen the x-axis marker labels are too long, they will be rotated by 135 degree from the north.\n\n\n\n\nWhen analysing multivariate data set, it is very common that the variables in the data sets includes values that reflect different types of measurement. In general, these variables’ values have their own range. In order to ensure that all the variables have comparable values, data transformation are commonly used before clustering.\nThree main data transformation methods are supported by heatmaply(), namely: scale, normalise and percentilse.\n\n\n\nWhen all variables are came from or assumed to come from some normal distribution, then scaling (i.e.: subtract the mean and divide by the standard deviation) would bring them all close to the standard normal distribution.\nIn such a case, each value would reflect the distance from the mean in units of standard deviation.\nThe scale argument in heatmaply() supports column and row scaling.\n\nThe code chunk below is used to scale variable values columewise.\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)],\n          scale = \"column\")\n\n\n\n\n\n\n\n\n\nWhen variables in the data comes from possibly different (and non-normal) distributions, the normalize function can be used to bring data to the 0 to 1 scale by subtracting the minimum and dividing by the maximum of all observations.\nThis preserves the shape of each variable’s distribution while making them easily comparable on the same “scale”.\n\nDifferent from Scaling, the normalise method is performed on the input data set i.e. wh_matrix as shown in the code chunk below.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\n\n\n\n\nThis is similar to ranking the variables, but instead of keeping the rank values, divide them by the maximal rank.\nThis is done by using the ecdf of the variables on their own values, bringing each value to its empirical percentile.\nThe benefit of the percentize function is that each value has a relatively clear interpretation, it is the percent of observations that got that value or below it.\n\nSimilar to Normalize method, the Percentize method is also performed on the input data set i.e. wh_matrix as shown in the code chunk below.\n\nheatmaply(percentize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\n\n\n\n\nheatmaply supports a variety of hierarchical clustering algorithm. The main arguments provided are:\n\ndistfun: function used to compute the distance (dissimilarity) between both rows and columns. Defaults to dist. The options “pearson”, “spearman” and “kendall” can be used to use correlation-based clustering, which uses as.dist(1 - cor(t(x))) as the distance metric (using the specified correlation method).\nhclustfun: function used to compute the hierarchical clustering when Rowv or Colv are not dendrograms. Defaults to hclust.\ndist_method default is NULL, which results in “euclidean” to be used. It can accept alternative character strings indicating the method to be passed to distfun. By default distfun is “dist”” hence this can be one of “euclidean”, “maximum”, “manhattan”, “canberra”, “binary” or “minkowski”.\nhclust_method default is NULL, which results in “complete” method to be used. It can accept alternative character strings indicating the method to be passed to hclustfun. By default hclustfun is hclust hence this can be one of “ward.D”, “ward.D2”, “single”, “complete”, “average” (= UPGMA), “mcquitty” (= WPGMA), “median” (= WPGMC) or “centroid” (= UPGMC).\n\nIn general, a clustering model can be calibrated either manually or statistically.\n\n\n\nIn the code chunk below, the heatmap is plotted by using hierachical clustering algorithm with “Euclidean distance” and “ward.D” method.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\")\n\n\n\n\n\n\n\n\nIn order to determine the best clustering method and number of cluster the dend_expend() and find_k()functions of dendextend package will be used.\nFirst, the dend_expend() will be used to determine the recommended clustering method to be used.\n\nwh_d &lt;- dist(normalize(wh_matrix[, -c(1, 2, 4, 5)]), method = \"euclidean\")\ndend_expend(wh_d)[[3]]\n\n  dist_methods hclust_methods     optim\n1      unknown         ward.D 0.6137851\n2      unknown        ward.D2 0.6289186\n3      unknown         single 0.4774362\n4      unknown       complete 0.6434009\n5      unknown        average 0.6701688\n6      unknown       mcquitty 0.5020102\n7      unknown         median 0.5901833\n8      unknown       centroid 0.6338734\n\n\nThe output table shows that “average” method should be used because it gave the high optimum value.\nNext, find_k() is used to determine the optimal number of cluster.\n\nwh_clust &lt;- hclust(wh_d, method = \"average\")\nnum_k &lt;- find_k(wh_clust)\nplot(num_k)\n\n\n\n\n\n\n\n\nFigure above shows that k=3 would be good.\nWith reference to the statistical analysis results, we can prepare the code chunk as shown below.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"average\",\n          k_row = 3)\n\n\n\n\n\n\n\n\nOne of the problems with hierarchical clustering is that it doesn’t actually place the rows in a definite order, it merely constrains the space of possible orderings. Take three items A, B and C. If you ignore reflections, there are three possible orderings: ABC, ACB, BAC. If clustering them gives you ((A+B)+C) as a tree, you know that C can’t end up between A and B, but it doesn’t tell you which way to flip the A+B cluster. It doesn’t tell you if the ABC ordering will lead to a clearer-looking heatmap than the BAC ordering.\nheatmaply uses the seriation package to find an optimal ordering of rows and columns. Optimal means to optimize the Hamiltonian path length that is restricted by the dendrogram structure. This, in other words, means to rotate the branches so that the sum of distances between each adjacent leaf (label) will be minimized. This is related to a restricted version of the travelling salesman problem.\nHere we meet our first seriation algorithm: Optimal Leaf Ordering (OLO). This algorithm starts with the output of an agglomerative clustering algorithm and produces a unique ordering, one that flips the various branches of the dendrogram around so as to minimize the sum of dissimilarities between adjacent leaves. Here is the result of applying Optimal Leaf Ordering to the same clustering result as the heatmap above.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"OLO\")\n\n\n\n\n\nThe default options is “OLO” (Optimal leaf ordering) which optimizes the above criterion (in O(n^4)). Another option is “GW” (Gruvaeus and Wainer) which aims for the same goal but uses a potentially faster heuristic.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"GW\")\n\n\n\n\n\nThe option “mean” gives the output we would get by default from heatmap functions in other packages such as gplots::heatmap.2.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"mean\")\n\n\n\n\n\nThe option “none” gives us the dendrograms without any rotation that is based on the data matrix.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"none\")\n\n\n\n\n\n\n\n\nThe default colour palette uses by heatmaply is viridis. heatmaply users, however, can use other colour palettes in order to improve the aestheticness and visual friendliness of the heatmap.\nIn the code chunk below, the Blues colour palette of rColorBrewer is used\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"none\",\n          colors = Blues)\n\n\n\n\n\n5.8 The finishing touch Beside providing a wide collection of arguments for meeting the statistical analysis needs, heatmaply also provides many plotting features to ensure cartographic quality heatmap can be produced.\nIn the code chunk below the following arguments are used:\nk_row is used to produce 5 groups. margins is used to change the top margin to 60 and row margin to 200. fontsizw_row and fontsize_col are used to change the font size for row and column labels to 4. main is used to write the main title of the plot. xlab and ylab are used to write the x-axis and y-axis labels respectively.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          Colv=NA,\n          seriate = \"none\",\n          colors = Blues,\n          k_row = 5,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"World Happiness Score and Variables by Country, 2018 \\nDataTransformation using Normalise Method\",\n          xlab = \"World Happiness Indicators\",\n          ylab = \"World Countries\"\n          )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09(a)/Hands-on_Ex09(a).html",
    "href": "Hands-on_Ex/Hands-on_Ex09(a)/Hands-on_Ex09(a).html",
    "title": "Hands-on_Ex09(a)",
    "section": "",
    "text": "pacman::p_load(plotly, ggtern, tidyverse)\n\n\n\n\n\npop_data &lt;- read.csv(\"data/respopagsex2000to2018_tidy.csv\")\n\n\n\n\n\nagpop_mutated &lt;- pop_data %&gt;%\n  mutate('YEAR' = as.character(Year)) %&gt;%\n  spread(AG, Population) %&gt;%\n  mutate(across(4:22, as.numeric)) %&gt;%\n  mutate(YOUNG = rowSums(.[4:8])) %&gt;%\n  mutate(ACTIVE = rowSums(.[9:16])) %&gt;%\n  mutate(OLD = rowSums(.[17:21])) %&gt;%\n  mutate(TOTAL = rowSums(.[22:24])) %&gt;%\n  filter(Year == 2018) %&gt;%\n  filter(TOTAL &gt; 0)\n\n\n\n\n\n\n\n\nggtern(data = agpop_mutated, aes(x = YOUNG, y = ACTIVE, z = OLD)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\nggtern(data = agpop_mutated, aes(x = YOUNG, y = ACTIVE, z = OLD)) +\n  geom_point() +\n  labs(title = \"Population structure, 2015\") +\n  theme_rgbw()\n\n\n\n\n\n\n\n\n\n\n\n\nlabel &lt;- function(txt){\n  list(\n    text = txt,\n    x = 0.1, y = 1,\n    ax = 0, ay = 0,\n    xref = \"paper\", yref = \"paper\",\n    align = \"center\",\n    font = list(family = \"serif\", size = 15, color = \"white\"),\n    bgcolor =  \"#b3b3b3\", bordercolor = \"black\", borderwidth = 2\n  )\n}\n\n\naxis &lt;- function(txt){\n  list(\n    title = txt, tickformat = \".0%\", tickfont = list(size = 10)\n  )\n}\nternaryAxes &lt;- list(\n  aaxis = axis(\"Young\"),\n  baxis = axis(\"Active\"),\n  caxis = axis(\"Old\")\n)\n\n\nplot_ly(\n  agpop_mutated,\n  a = ~YOUNG,\n  b = ~ACTIVE,\n  c = ~OLD,\n  color = I(\"black\"),\n  type = \"scatterternary\"\n) %&gt;%\n  layout(\n    annotations = label(\"Ternary Markers\"),\n    ternary = ternaryAxes\n  )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09(a)/Hands-on_Ex09(a).html#data-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex09(a)/Hands-on_Ex09(a).html#data-preparation",
    "title": "Hands-on_Ex09(a)",
    "section": "",
    "text": "pacman::p_load(plotly, ggtern, tidyverse)\n\n\n\n\n\npop_data &lt;- read.csv(\"data/respopagsex2000to2018_tidy.csv\")\n\n\n\n\n\nagpop_mutated &lt;- pop_data %&gt;%\n  mutate('YEAR' = as.character(Year)) %&gt;%\n  spread(AG, Population) %&gt;%\n  mutate(across(4:22, as.numeric)) %&gt;%\n  mutate(YOUNG = rowSums(.[4:8])) %&gt;%\n  mutate(ACTIVE = rowSums(.[9:16])) %&gt;%\n  mutate(OLD = rowSums(.[17:21])) %&gt;%\n  mutate(TOTAL = rowSums(.[22:24])) %&gt;%\n  filter(Year == 2018) %&gt;%\n  filter(TOTAL &gt; 0)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09(a)/Hands-on_Ex09(a).html#plotting-ternary",
    "href": "Hands-on_Ex/Hands-on_Ex09(a)/Hands-on_Ex09(a).html#plotting-ternary",
    "title": "Hands-on_Ex09(a)",
    "section": "",
    "text": "ggtern(data = agpop_mutated, aes(x = YOUNG, y = ACTIVE, z = OLD)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\nggtern(data = agpop_mutated, aes(x = YOUNG, y = ACTIVE, z = OLD)) +\n  geom_point() +\n  labs(title = \"Population structure, 2015\") +\n  theme_rgbw()\n\n\n\n\n\n\n\n\n\n\n\n\nlabel &lt;- function(txt){\n  list(\n    text = txt,\n    x = 0.1, y = 1,\n    ax = 0, ay = 0,\n    xref = \"paper\", yref = \"paper\",\n    align = \"center\",\n    font = list(family = \"serif\", size = 15, color = \"white\"),\n    bgcolor =  \"#b3b3b3\", bordercolor = \"black\", borderwidth = 2\n  )\n}\n\n\naxis &lt;- function(txt){\n  list(\n    title = txt, tickformat = \".0%\", tickfont = list(size = 10)\n  )\n}\nternaryAxes &lt;- list(\n  aaxis = axis(\"Young\"),\n  baxis = axis(\"Active\"),\n  caxis = axis(\"Old\")\n)\n\n\nplot_ly(\n  agpop_mutated,\n  a = ~YOUNG,\n  b = ~ACTIVE,\n  c = ~OLD,\n  color = I(\"black\"),\n  type = \"scatterternary\"\n) %&gt;%\n  layout(\n    annotations = label(\"Ternary Markers\"),\n    ternary = ternaryAxes\n  )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html",
    "title": "Hands-on_Ex10",
    "section": "",
    "text": "By the end of this hands-on exercise, you will be able to:\n\ncreate bullet chart by using ggplot2,\ncreate sparklines by using ggplot2 ,\nbuild industry standard dashboard by using R Shiny.\n\n\n\n\nFor the purpose of this hands-on exercise, the following R packages will be used.\n\npacman::p_load(lubridate, ggthemes, reactable,\nreactablefmtr, gt, gtExtras, tidyverse)\n\n\ntidyverse provides a collection of functions for performing data science task such as importing, tidying, wrangling data and visualising data. It is not a single package but a collection of modern R packages including but not limited to readr, tidyr, dplyr, ggplot, tibble, stringr, forcats and purrr.\nlubridate provides functions to work with dates and times more efficiently.\nggthemes is an extension of ggplot2. It provides additional themes beyond the basic themes of ggplot2.\ngtExtras provides some additional helper functions to assist in creating beautiful tables with gt, an R package specially designed for anyone to make wonderful-looking tables using the R programming language.\nreactable provides functions to create interactive data tables for R, based on the React Table library and made with reactR.\nreactablefmtr provides various features to streamline and enhance the styling of interactive reactable tables with easy-to-use and highly-customizable functions and themes.\n\n\n\n\n\n\nFor the purpose of this study, a personal database in Microsoft Access mdb format called Coffee Chain will be used.\n\n\n\nIn the code chunk below, odbcConnectAccess() of RODBC package is used used to import a database query table into R.\n\n# library(RODBC)\n# con &lt;- odbcConnectAccess2007('data/Coffee Chain.mdb')\n# coffeechain &lt;- sqlFetch(con, 'CoffeeChain Query')\n# write_rds(coffeechain, \"data/CoffeeChain.rds\")\n# odbcClose(con)\n\nNote: Before running the code chunk, you need to change the R system to 32bit version. This is because the odbcConnectAccess() is based on 32bit and not 64bit\n\n\n\nThe code chunk below is used to import CoffeeChain.rds into R.\n\ncoffeechain &lt;- read_csv(\"data/CoffeeChain.csv\")\n\n# write.csv(coffeechain, \"CoffeeChain.csv\", row.names=FALSE)\n# first &lt;- read.csv(\"CoffeeChain.csv\")\n# first\n# \n# write.csv(coffeechain, \"CoffeeChain.csv\", fileEncoding = \"UTF-8\", row.names=FALSE)\n# second &lt;- read.csv(\"CoffeeChain.csv\")\n\nNote: This step is optional if coffeechain is already available in R.\nThe code chunk below is used to aggregate Sales and Budgeted Sales at the Product level.\n\nproduct &lt;- coffeechain %&gt;%\n  group_by(`Product`) %&gt;%\n  summarise(`target` = sum(`Budget Sales`),\n            `current` = sum(`Sales`)) %&gt;%\n  ungroup()\n\n\n\n\nThe code chunk below is used to plot the bullet charts using ggplot2 functions.\n\nggplot(product, aes(Product, current)) + \n  geom_col(aes(Product, max(target) * 1.01),\n           fill=\"grey85\", width=0.85) +\n  geom_col(aes(Product, target * 0.75),\n           fill=\"grey60\", width=0.85) +\n  geom_col(aes(Product, target * 0.5),\n           fill=\"grey50\", width=0.85) +\n  geom_col(aes(Product, current), \n           width=0.35,\n           fill = \"black\") + \n  geom_errorbar(aes(y = target,\n                    x = Product, \n                    ymin = target,\n                    ymax= target), \n                width = .4,\n                colour = \"red\",\n                size = 1) +\n  coord_flip()\n\n\n\n\n\n\n\n\n\n\n\n\nIn this section, you will learn how to plot sparklines by using ggplot2.\n\n\n\nsales_report &lt;- coffeechain %&gt;%\n  filter(Date &gt;= \"2013-01-01\") %&gt;%\n  mutate(Month = month(Date)) %&gt;%\n  group_by(Month, Product) %&gt;%\n  summarise(Sales = sum(Sales)) %&gt;%\n  ungroup() %&gt;%\n  select(Month, Product, Sales)\n\nThe code chunk below is used to compute the minimum, maximum and end othe the month sales.\n\nmins &lt;- group_by(sales_report, Product) %&gt;% \n  slice(which.min(Sales))\nmaxs &lt;- group_by(sales_report, Product) %&gt;% \n  slice(which.max(Sales))\nends &lt;- group_by(sales_report, Product) %&gt;% \n  filter(Month == max(Month))\n\nThe code chunk below is used to compute the 25 and 75 quantiles.\n\nquarts &lt;- sales_report %&gt;%\n  group_by(Product) %&gt;%\n  summarise(quart1 = quantile(Sales, \n                              0.25),\n            quart2 = quantile(Sales, \n                              0.75)) %&gt;%\n  right_join(sales_report)\n\n\n\n\nThe code chunk used.\n\nggplot(sales_report, aes(x=Month, y=Sales)) + \n  facet_grid(Product ~ ., scales = \"free_y\") + \n  geom_ribbon(data = quarts, aes(ymin = quart1, max = quart2), \n              fill = 'grey90') +\n  geom_line(size=0.3) +\n  geom_point(data = mins, col = 'red') +\n  geom_point(data = maxs, col = 'blue') +\n  geom_text(data = mins, aes(label = Sales), vjust = -1) +\n  geom_text(data = maxs, aes(label = Sales), vjust = 2.5) +\n  geom_text(data = ends, aes(label = Sales), hjust = 0, nudge_x = 0.5) +\n  geom_text(data = ends, aes(label = Product), hjust = 0, nudge_x = 1.0) +\n  expand_limits(x = max(sales_report$Month) + \n                  (0.25 * (max(sales_report$Month) - min(sales_report$Month)))) +\n  scale_x_continuous(breaks = seq(1, 12, 1)) +\n  scale_y_continuous(expand = c(0.1, 0)) +\n  theme_tufte(base_size = 3, base_family = \"Helvetica\") +\n  theme(axis.title=element_blank(), axis.text.y = element_blank(), \n        axis.ticks = element_blank(), strip.text = element_blank())\n\n\n\n\n\n\n\n\n\n\n\n\nIn this section, you will learn how to create static information dashboard by using gt and gtExtras packages. Before getting started, it is highly recommended for you to visit the webpage of these two packages and review all the materials provided on the webpages at least once. You done not have to understand and remember everything provided but at least have an overview of the purposes and functions provided by them.\n\n\nIn this section, you will learn how to prepare a bullet chart report by using functions of gt and gtExtras packages.\n\nproduct %&gt;%\n  gt::gt() %&gt;%\n  gt_plt_bullet(column = current, \n              target = target, \n              width = 60,\n              palette = c(\"lightblue\", \n                          \"black\")) %&gt;%\n  gt_theme_538()\n\n\n\n\n\n\n\n\n\n\n\nProduct\ncurrent\n\n\n\n\nAmaretto\n\n\n\n   \n\n\n\nCaffe Latte\n\n\n\n   \n\n\n\nCaffe Mocha\n\n\n\n   \n\n\n\nChamomile\n\n\n\n   \n\n\n\nColombian\n\n\n\n   \n\n\n\nDarjeeling\n\n\n\n   \n\n\n\nDecaf Espresso\n\n\n\n   \n\n\n\nDecaf Irish Cream\n\n\n\n   \n\n\n\nEarl Grey\n\n\n\n   \n\n\n\nGreen Tea\n\n\n\n   \n\n\n\nLemon\n\n\n\n   \n\n\n\nMint\n\n\n\n   \n\n\n\nRegular Espresso\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\nBefore we can prepare the sales report by product by using gtExtras functions, code chunk below will be used to prepare the data.\n\nreport &lt;- coffeechain %&gt;%\n  mutate(Year = year(Date)) %&gt;%\n  filter(Year == \"2013\") %&gt;%\n  mutate (Month = month(Date, \n                        label = TRUE, \n                        abbr = TRUE)) %&gt;%\n  group_by(Product, Month) %&gt;%\n  summarise(Sales = sum(Sales)) %&gt;%\n  ungroup()\n\nIt is important to note that one of the requirement of gtExtras functions is that almost exclusively they require you to pass data.frame with list columns. In view of this, code chunk below will be used to convert the report data.frame into list columns.\n\nreport %&gt;%\n  group_by(Product) %&gt;%\n  summarize('Monthly Sales' = list(Sales), \n            .groups = \"drop\")\n\n# A tibble: 13 × 2\n   Product           `Monthly Sales`\n   &lt;chr&gt;             &lt;list&gt;         \n 1 Amaretto          &lt;dbl [12]&gt;     \n 2 Caffe Latte       &lt;dbl [12]&gt;     \n 3 Caffe Mocha       &lt;dbl [12]&gt;     \n 4 Chamomile         &lt;dbl [12]&gt;     \n 5 Colombian         &lt;dbl [12]&gt;     \n 6 Darjeeling        &lt;dbl [12]&gt;     \n 7 Decaf Espresso    &lt;dbl [12]&gt;     \n 8 Decaf Irish Cream &lt;dbl [12]&gt;     \n 9 Earl Grey         &lt;dbl [12]&gt;     \n10 Green Tea         &lt;dbl [12]&gt;     \n11 Lemon             &lt;dbl [12]&gt;     \n12 Mint              &lt;dbl [12]&gt;     \n13 Regular Espresso  &lt;dbl [12]&gt;     \n\n\n\n\n\nreport %&gt;%\n  group_by(Product) %&gt;%\n  summarize('Monthly Sales' = list(Sales), \n            .groups = \"drop\") %&gt;%\n   gt() %&gt;%\n   gt_plt_sparkline('Monthly Sales',\n                    same_limit = FALSE)\n\n\n\n\n\n\n\n\n\n\n\nProduct\nMonthly Sales\n\n\n\n\nAmaretto\n\n\n\n   1.2K\n\n\n\nCaffe Latte\n\n\n\n   1.5K\n\n\n\nCaffe Mocha\n\n\n\n   3.7K\n\n\n\nChamomile\n\n\n\n   3.3K\n\n\n\nColombian\n\n\n\n   5.5K\n\n\n\nDarjeeling\n\n\n\n   3.0K\n\n\n\nDecaf Espresso\n\n\n\n   3.2K\n\n\n\nDecaf Irish Cream\n\n\n\n   2.7K\n\n\n\nEarl Grey\n\n\n\n   3.0K\n\n\n\nGreen Tea\n\n\n\n   1.5K\n\n\n\nLemon\n\n\n\n   4.4K\n\n\n\nMint\n\n\n\n   1.5K\n\n\n\nRegular Espresso\n\n\n\n   1.1K\n\n\n\n\n\n\n\n\n\n\n\nFirst, calculate summary statistics by using the code chunk below.\n\nreport %&gt;% \n  group_by(Product) %&gt;% \n  summarise(\"Min\" = min(Sales, na.rm = T),\n            \"Max\" = max(Sales, na.rm = T),\n            \"Average\" = mean(Sales, na.rm = T)\n            ) %&gt;%\n  gt() %&gt;%\n  fmt_number(columns = 4,\n    decimals = 2)\n\n\n\n\n\n\n\nProduct\nMin\nMax\nAverage\n\n\n\n\nAmaretto\n1016\n1210\n1,119.00\n\n\nCaffe Latte\n1398\n1653\n1,528.33\n\n\nCaffe Mocha\n3322\n3828\n3,613.92\n\n\nChamomile\n2967\n3395\n3,217.42\n\n\nColombian\n5132\n5961\n5,457.25\n\n\nDarjeeling\n2926\n3281\n3,112.67\n\n\nDecaf Espresso\n3181\n3493\n3,326.83\n\n\nDecaf Irish Cream\n2463\n2901\n2,648.25\n\n\nEarl Grey\n2730\n3005\n2,841.83\n\n\nGreen Tea\n1339\n1476\n1,398.75\n\n\nLemon\n3851\n4418\n4,080.83\n\n\nMint\n1388\n1669\n1,519.17\n\n\nRegular Espresso\n890\n1218\n1,023.42\n\n\n\n\n\n\n\n\n\n\nNext, use the code chunk below to add the statistics on the table.\n\nspark &lt;- report %&gt;%\n  group_by(Product) %&gt;%\n  summarize('Monthly Sales' = list(Sales), \n            .groups = \"drop\")\n\n\nsales &lt;- report %&gt;% \n  group_by(Product) %&gt;% \n  summarise(\"Min\" = min(Sales, na.rm = T),\n            \"Max\" = max(Sales, na.rm = T),\n            \"Average\" = mean(Sales, na.rm = T)\n            )\n\n\nsales_data = left_join(sales, spark)\n\n\n\n\n\nsales_data %&gt;%\n  gt() %&gt;%\n  gt_plt_sparkline('Monthly Sales',\n                   same_limit = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProduct\nMin\nMax\nAverage\nMonthly Sales\n\n\n\n\nAmaretto\n1016\n1210\n1119.000\n\n\n\n   1.2K\n\n\n\nCaffe Latte\n1398\n1653\n1528.333\n\n\n\n   1.5K\n\n\n\nCaffe Mocha\n3322\n3828\n3613.917\n\n\n\n   3.7K\n\n\n\nChamomile\n2967\n3395\n3217.417\n\n\n\n   3.3K\n\n\n\nColombian\n5132\n5961\n5457.250\n\n\n\n   5.5K\n\n\n\nDarjeeling\n2926\n3281\n3112.667\n\n\n\n   3.0K\n\n\n\nDecaf Espresso\n3181\n3493\n3326.833\n\n\n\n   3.2K\n\n\n\nDecaf Irish Cream\n2463\n2901\n2648.250\n\n\n\n   2.7K\n\n\n\nEarl Grey\n2730\n3005\n2841.833\n\n\n\n   3.0K\n\n\n\nGreen Tea\n1339\n1476\n1398.750\n\n\n\n   1.5K\n\n\n\nLemon\n3851\n4418\n4080.833\n\n\n\n   4.4K\n\n\n\nMint\n1388\n1669\n1519.167\n\n\n\n   1.5K\n\n\n\nRegular Espresso\n890\n1218\n1023.417\n\n\n\n   1.1K\n\n\n\n\n\n\n\n\n\n\n\nSimilarly, we can combining the bullet chart and sparklines using the steps below.\n\nbullet &lt;- coffeechain %&gt;%\n  filter(Date &gt;= \"2013-01-01\") %&gt;%\n  group_by(`Product`) %&gt;%\n  summarise(`Target` = sum(`Budget Sales`),\n            `Actual` = sum(`Sales`)) %&gt;%\n  ungroup() \n\n\nsales_data = sales_data %&gt;%\n  left_join(bullet)\n\n\nsales_data %&gt;%\n  gt() %&gt;%\n  gt_plt_sparkline('Monthly Sales') %&gt;%\n  gt_plt_bullet(column = Actual, \n                target = Target, \n                width = 28,\n                palette = c(\"lightblue\", \n                          \"black\")) %&gt;%\n  gt_theme_538()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProduct\nMin\nMax\nAverage\nMonthly Sales\nActual\n\n\n\n\nAmaretto\n1016\n1210\n1119.000\n\n\n\n   1.2K\n\n\n\n\n   \n\n\n\nCaffe Latte\n1398\n1653\n1528.333\n\n\n\n   1.5K\n\n\n\n\n   \n\n\n\nCaffe Mocha\n3322\n3828\n3613.917\n\n\n\n   3.7K\n\n\n\n\n   \n\n\n\nChamomile\n2967\n3395\n3217.417\n\n\n\n   3.3K\n\n\n\n\n   \n\n\n\nColombian\n5132\n5961\n5457.250\n\n\n\n   5.5K\n\n\n\n\n   \n\n\n\nDarjeeling\n2926\n3281\n3112.667\n\n\n\n   3.0K\n\n\n\n\n   \n\n\n\nDecaf Espresso\n3181\n3493\n3326.833\n\n\n\n   3.2K\n\n\n\n\n   \n\n\n\nDecaf Irish Cream\n2463\n2901\n2648.250\n\n\n\n   2.7K\n\n\n\n\n   \n\n\n\nEarl Grey\n2730\n3005\n2841.833\n\n\n\n   3.0K\n\n\n\n\n   \n\n\n\nGreen Tea\n1339\n1476\n1398.750\n\n\n\n   1.5K\n\n\n\n\n   \n\n\n\nLemon\n3851\n4418\n4080.833\n\n\n\n   4.4K\n\n\n\n\n   \n\n\n\nMint\n1388\n1669\n1519.167\n\n\n\n   1.5K\n\n\n\n\n   \n\n\n\nRegular Espresso\n890\n1218\n1023.417\n\n\n\n   1.1K\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\nIn this section, you will learn how to create interactive information dashboard by using reactable and reactablefmtr packages. Before getting started, it is highly recommended for you to visit the webpage of these two packages and review all the materials provided on the webpages at least once. You done not have to understand and remember everything provided but at least have an overview of the purposes and functions provided by them.\nIn order to build an interactive sparklines, we need to install dataui R package by using the code chunk below.\n\nremotes::install_github(\"timelyportfolio/dataui\")\n\nNext, you all need to load the package onto R environment by using the code chunk below.\n\nlibrary(dataui)\n\n\n\nSimilar to gtExtras, to plot an interactive sparklines by using reactablefmtr package we need to prepare the list field by using the code chunk below.\n\nreport &lt;- report %&gt;%\n  group_by(Product) %&gt;%\n  summarize(`Monthly Sales` = list(Sales))\n\nNext, react_sparkline will be to plot the sparklines as shown below.\n\nreactable(\n  report,\n  columns = list(\n    Product = colDef(maxWidth = 200),\n    `Monthly Sales` = colDef(\n      cell = react_sparkline(report)\n    )\n  )\n)\n\n\n\n\n\n\n\n\nBy default the pagesize is 10. In the code chunk below, arguments defaultPageSize is used to change the default setting.\n\nreactable(\n  report,\n  defaultPageSize = 13,\n  columns = list(\n    Product = colDef(maxWidth = 200),\n    `Monthly Sales` = colDef(\n      cell = react_sparkline(report)\n    )\n  )\n)\n\n\n\n\n\n\n\n\nIn the code chunk below highlight_points argument is used to show the minimum and maximum values points and label argument is used to label first and last values.\n\nreactable(\n  report,\n  defaultPageSize = 13,\n  columns = list(\n    Product = colDef(maxWidth = 200),\n    `Monthly Sales` = colDef(\n      cell = react_sparkline(\n        report,\n        highlight_points = highlight_points(\n          min = \"red\", max = \"blue\"),\n        labels = c(\"first\", \"last\")\n        )\n    )\n  )\n)\n\n\n\n\n\n\n\n\nIn the code chunk below statline argument is used to show the mean line.\n\nreactable(\n  report,\n  defaultPageSize = 13,\n  columns = list(\n    Product = colDef(maxWidth = 200),\n    `Monthly Sales` = colDef(\n      cell = react_sparkline(\n        report,\n        highlight_points = highlight_points(\n          min = \"red\", max = \"blue\"),\n        statline = \"mean\"\n        )\n    )\n  )\n)\n\n\n\n\n\n\n\n\nInstead adding reference line, bandline can be added by using the bandlineargument.\n\nreactable(\n  report,\n  defaultPageSize = 13,\n  columns = list(\n    Product = colDef(maxWidth = 200),\n    `Monthly Sales` = colDef(\n      cell = react_sparkline(\n        report,\n        highlight_points = highlight_points(\n          min = \"red\", max = \"blue\"),\n        line_width = 1,\n        bandline = \"innerquartiles\",\n        bandline_color = \"green\"\n        )\n    )\n  )\n)\n\n\n\n\n\n\n\n\nInstead of displaying the values as sparklines, we can display them as sparkbars as shiwn below.\n\nreactable(\n  report,\n  defaultPageSize = 13,\n  columns = list(\n    Product = colDef(maxWidth = 200),\n    `Monthly Sales` = colDef(\n      cell = react_sparkbar(\n        report,\n        highlight_bars = highlight_bars(\n          min = \"red\", max = \"blue\"),\n        bandline = \"innerquartiles\",\n        statline = \"mean\")\n    )\n  )\n)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#overview",
    "title": "Hands-on_Ex10",
    "section": "",
    "text": "By the end of this hands-on exercise, you will be able to:\n\ncreate bullet chart by using ggplot2,\ncreate sparklines by using ggplot2 ,\nbuild industry standard dashboard by using R Shiny."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#getting-started",
    "title": "Hands-on_Ex10",
    "section": "",
    "text": "For the purpose of this hands-on exercise, the following R packages will be used.\n\npacman::p_load(lubridate, ggthemes, reactable,\nreactablefmtr, gt, gtExtras, tidyverse)\n\n\ntidyverse provides a collection of functions for performing data science task such as importing, tidying, wrangling data and visualising data. It is not a single package but a collection of modern R packages including but not limited to readr, tidyr, dplyr, ggplot, tibble, stringr, forcats and purrr.\nlubridate provides functions to work with dates and times more efficiently.\nggthemes is an extension of ggplot2. It provides additional themes beyond the basic themes of ggplot2.\ngtExtras provides some additional helper functions to assist in creating beautiful tables with gt, an R package specially designed for anyone to make wonderful-looking tables using the R programming language.\nreactable provides functions to create interactive data tables for R, based on the React Table library and made with reactR.\nreactablefmtr provides various features to streamline and enhance the styling of interactive reactable tables with easy-to-use and highly-customizable functions and themes."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#importing-microsoft-access-database",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#importing-microsoft-access-database",
    "title": "Hands-on_Ex10",
    "section": "",
    "text": "For the purpose of this study, a personal database in Microsoft Access mdb format called Coffee Chain will be used.\n\n\n\nIn the code chunk below, odbcConnectAccess() of RODBC package is used used to import a database query table into R.\n\n# library(RODBC)\n# con &lt;- odbcConnectAccess2007('data/Coffee Chain.mdb')\n# coffeechain &lt;- sqlFetch(con, 'CoffeeChain Query')\n# write_rds(coffeechain, \"data/CoffeeChain.rds\")\n# odbcClose(con)\n\nNote: Before running the code chunk, you need to change the R system to 32bit version. This is because the odbcConnectAccess() is based on 32bit and not 64bit\n\n\n\nThe code chunk below is used to import CoffeeChain.rds into R.\n\ncoffeechain &lt;- read_csv(\"data/CoffeeChain.csv\")\n\n# write.csv(coffeechain, \"CoffeeChain.csv\", row.names=FALSE)\n# first &lt;- read.csv(\"CoffeeChain.csv\")\n# first\n# \n# write.csv(coffeechain, \"CoffeeChain.csv\", fileEncoding = \"UTF-8\", row.names=FALSE)\n# second &lt;- read.csv(\"CoffeeChain.csv\")\n\nNote: This step is optional if coffeechain is already available in R.\nThe code chunk below is used to aggregate Sales and Budgeted Sales at the Product level.\n\nproduct &lt;- coffeechain %&gt;%\n  group_by(`Product`) %&gt;%\n  summarise(`target` = sum(`Budget Sales`),\n            `current` = sum(`Sales`)) %&gt;%\n  ungroup()\n\n\n\n\nThe code chunk below is used to plot the bullet charts using ggplot2 functions.\n\nggplot(product, aes(Product, current)) + \n  geom_col(aes(Product, max(target) * 1.01),\n           fill=\"grey85\", width=0.85) +\n  geom_col(aes(Product, target * 0.75),\n           fill=\"grey60\", width=0.85) +\n  geom_col(aes(Product, target * 0.5),\n           fill=\"grey50\", width=0.85) +\n  geom_col(aes(Product, current), \n           width=0.35,\n           fill = \"black\") + \n  geom_errorbar(aes(y = target,\n                    x = Product, \n                    ymin = target,\n                    ymax= target), \n                width = .4,\n                colour = \"red\",\n                size = 1) +\n  coord_flip()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#plotting-sparklines-using-ggplot2",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#plotting-sparklines-using-ggplot2",
    "title": "Hands-on_Ex10",
    "section": "",
    "text": "In this section, you will learn how to plot sparklines by using ggplot2.\n\n\n\nsales_report &lt;- coffeechain %&gt;%\n  filter(Date &gt;= \"2013-01-01\") %&gt;%\n  mutate(Month = month(Date)) %&gt;%\n  group_by(Month, Product) %&gt;%\n  summarise(Sales = sum(Sales)) %&gt;%\n  ungroup() %&gt;%\n  select(Month, Product, Sales)\n\nThe code chunk below is used to compute the minimum, maximum and end othe the month sales.\n\nmins &lt;- group_by(sales_report, Product) %&gt;% \n  slice(which.min(Sales))\nmaxs &lt;- group_by(sales_report, Product) %&gt;% \n  slice(which.max(Sales))\nends &lt;- group_by(sales_report, Product) %&gt;% \n  filter(Month == max(Month))\n\nThe code chunk below is used to compute the 25 and 75 quantiles.\n\nquarts &lt;- sales_report %&gt;%\n  group_by(Product) %&gt;%\n  summarise(quart1 = quantile(Sales, \n                              0.25),\n            quart2 = quantile(Sales, \n                              0.75)) %&gt;%\n  right_join(sales_report)\n\n\n\n\nThe code chunk used.\n\nggplot(sales_report, aes(x=Month, y=Sales)) + \n  facet_grid(Product ~ ., scales = \"free_y\") + \n  geom_ribbon(data = quarts, aes(ymin = quart1, max = quart2), \n              fill = 'grey90') +\n  geom_line(size=0.3) +\n  geom_point(data = mins, col = 'red') +\n  geom_point(data = maxs, col = 'blue') +\n  geom_text(data = mins, aes(label = Sales), vjust = -1) +\n  geom_text(data = maxs, aes(label = Sales), vjust = 2.5) +\n  geom_text(data = ends, aes(label = Sales), hjust = 0, nudge_x = 0.5) +\n  geom_text(data = ends, aes(label = Product), hjust = 0, nudge_x = 1.0) +\n  expand_limits(x = max(sales_report$Month) + \n                  (0.25 * (max(sales_report$Month) - min(sales_report$Month)))) +\n  scale_x_continuous(breaks = seq(1, 12, 1)) +\n  scale_y_continuous(expand = c(0.1, 0)) +\n  theme_tufte(base_size = 3, base_family = \"Helvetica\") +\n  theme(axis.title=element_blank(), axis.text.y = element_blank(), \n        axis.ticks = element_blank(), strip.text = element_blank())"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#static-information-dashboard-design-gt-and-gtextras-methods",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#static-information-dashboard-design-gt-and-gtextras-methods",
    "title": "Hands-on_Ex10",
    "section": "",
    "text": "In this section, you will learn how to create static information dashboard by using gt and gtExtras packages. Before getting started, it is highly recommended for you to visit the webpage of these two packages and review all the materials provided on the webpages at least once. You done not have to understand and remember everything provided but at least have an overview of the purposes and functions provided by them.\n\n\nIn this section, you will learn how to prepare a bullet chart report by using functions of gt and gtExtras packages.\n\nproduct %&gt;%\n  gt::gt() %&gt;%\n  gt_plt_bullet(column = current, \n              target = target, \n              width = 60,\n              palette = c(\"lightblue\", \n                          \"black\")) %&gt;%\n  gt_theme_538()\n\n\n\n\n\n\n\n\n\n\n\nProduct\ncurrent\n\n\n\n\nAmaretto\n\n\n\n   \n\n\n\nCaffe Latte\n\n\n\n   \n\n\n\nCaffe Mocha\n\n\n\n   \n\n\n\nChamomile\n\n\n\n   \n\n\n\nColombian\n\n\n\n   \n\n\n\nDarjeeling\n\n\n\n   \n\n\n\nDecaf Espresso\n\n\n\n   \n\n\n\nDecaf Irish Cream\n\n\n\n   \n\n\n\nEarl Grey\n\n\n\n   \n\n\n\nGreen Tea\n\n\n\n   \n\n\n\nLemon\n\n\n\n   \n\n\n\nMint\n\n\n\n   \n\n\n\nRegular Espresso"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#sparklines-gtextras-method",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#sparklines-gtextras-method",
    "title": "Hands-on_Ex10",
    "section": "",
    "text": "Before we can prepare the sales report by product by using gtExtras functions, code chunk below will be used to prepare the data.\n\nreport &lt;- coffeechain %&gt;%\n  mutate(Year = year(Date)) %&gt;%\n  filter(Year == \"2013\") %&gt;%\n  mutate (Month = month(Date, \n                        label = TRUE, \n                        abbr = TRUE)) %&gt;%\n  group_by(Product, Month) %&gt;%\n  summarise(Sales = sum(Sales)) %&gt;%\n  ungroup()\n\nIt is important to note that one of the requirement of gtExtras functions is that almost exclusively they require you to pass data.frame with list columns. In view of this, code chunk below will be used to convert the report data.frame into list columns.\n\nreport %&gt;%\n  group_by(Product) %&gt;%\n  summarize('Monthly Sales' = list(Sales), \n            .groups = \"drop\")\n\n# A tibble: 13 × 2\n   Product           `Monthly Sales`\n   &lt;chr&gt;             &lt;list&gt;         \n 1 Amaretto          &lt;dbl [12]&gt;     \n 2 Caffe Latte       &lt;dbl [12]&gt;     \n 3 Caffe Mocha       &lt;dbl [12]&gt;     \n 4 Chamomile         &lt;dbl [12]&gt;     \n 5 Colombian         &lt;dbl [12]&gt;     \n 6 Darjeeling        &lt;dbl [12]&gt;     \n 7 Decaf Espresso    &lt;dbl [12]&gt;     \n 8 Decaf Irish Cream &lt;dbl [12]&gt;     \n 9 Earl Grey         &lt;dbl [12]&gt;     \n10 Green Tea         &lt;dbl [12]&gt;     \n11 Lemon             &lt;dbl [12]&gt;     \n12 Mint              &lt;dbl [12]&gt;     \n13 Regular Espresso  &lt;dbl [12]&gt;     \n\n\n\n\n\nreport %&gt;%\n  group_by(Product) %&gt;%\n  summarize('Monthly Sales' = list(Sales), \n            .groups = \"drop\") %&gt;%\n   gt() %&gt;%\n   gt_plt_sparkline('Monthly Sales',\n                    same_limit = FALSE)\n\n\n\n\n\n\n\n\n\n\n\nProduct\nMonthly Sales\n\n\n\n\nAmaretto\n\n\n\n   1.2K\n\n\n\nCaffe Latte\n\n\n\n   1.5K\n\n\n\nCaffe Mocha\n\n\n\n   3.7K\n\n\n\nChamomile\n\n\n\n   3.3K\n\n\n\nColombian\n\n\n\n   5.5K\n\n\n\nDarjeeling\n\n\n\n   3.0K\n\n\n\nDecaf Espresso\n\n\n\n   3.2K\n\n\n\nDecaf Irish Cream\n\n\n\n   2.7K\n\n\n\nEarl Grey\n\n\n\n   3.0K\n\n\n\nGreen Tea\n\n\n\n   1.5K\n\n\n\nLemon\n\n\n\n   4.4K\n\n\n\nMint\n\n\n\n   1.5K\n\n\n\nRegular Espresso\n\n\n\n   1.1K\n\n\n\n\n\n\n\n\n\n\n\nFirst, calculate summary statistics by using the code chunk below.\n\nreport %&gt;% \n  group_by(Product) %&gt;% \n  summarise(\"Min\" = min(Sales, na.rm = T),\n            \"Max\" = max(Sales, na.rm = T),\n            \"Average\" = mean(Sales, na.rm = T)\n            ) %&gt;%\n  gt() %&gt;%\n  fmt_number(columns = 4,\n    decimals = 2)\n\n\n\n\n\n\n\nProduct\nMin\nMax\nAverage\n\n\n\n\nAmaretto\n1016\n1210\n1,119.00\n\n\nCaffe Latte\n1398\n1653\n1,528.33\n\n\nCaffe Mocha\n3322\n3828\n3,613.92\n\n\nChamomile\n2967\n3395\n3,217.42\n\n\nColombian\n5132\n5961\n5,457.25\n\n\nDarjeeling\n2926\n3281\n3,112.67\n\n\nDecaf Espresso\n3181\n3493\n3,326.83\n\n\nDecaf Irish Cream\n2463\n2901\n2,648.25\n\n\nEarl Grey\n2730\n3005\n2,841.83\n\n\nGreen Tea\n1339\n1476\n1,398.75\n\n\nLemon\n3851\n4418\n4,080.83\n\n\nMint\n1388\n1669\n1,519.17\n\n\nRegular Espresso\n890\n1218\n1,023.42\n\n\n\n\n\n\n\n\n\n\nNext, use the code chunk below to add the statistics on the table.\n\nspark &lt;- report %&gt;%\n  group_by(Product) %&gt;%\n  summarize('Monthly Sales' = list(Sales), \n            .groups = \"drop\")\n\n\nsales &lt;- report %&gt;% \n  group_by(Product) %&gt;% \n  summarise(\"Min\" = min(Sales, na.rm = T),\n            \"Max\" = max(Sales, na.rm = T),\n            \"Average\" = mean(Sales, na.rm = T)\n            )\n\n\nsales_data = left_join(sales, spark)\n\n\n\n\n\nsales_data %&gt;%\n  gt() %&gt;%\n  gt_plt_sparkline('Monthly Sales',\n                   same_limit = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProduct\nMin\nMax\nAverage\nMonthly Sales\n\n\n\n\nAmaretto\n1016\n1210\n1119.000\n\n\n\n   1.2K\n\n\n\nCaffe Latte\n1398\n1653\n1528.333\n\n\n\n   1.5K\n\n\n\nCaffe Mocha\n3322\n3828\n3613.917\n\n\n\n   3.7K\n\n\n\nChamomile\n2967\n3395\n3217.417\n\n\n\n   3.3K\n\n\n\nColombian\n5132\n5961\n5457.250\n\n\n\n   5.5K\n\n\n\nDarjeeling\n2926\n3281\n3112.667\n\n\n\n   3.0K\n\n\n\nDecaf Espresso\n3181\n3493\n3326.833\n\n\n\n   3.2K\n\n\n\nDecaf Irish Cream\n2463\n2901\n2648.250\n\n\n\n   2.7K\n\n\n\nEarl Grey\n2730\n3005\n2841.833\n\n\n\n   3.0K\n\n\n\nGreen Tea\n1339\n1476\n1398.750\n\n\n\n   1.5K\n\n\n\nLemon\n3851\n4418\n4080.833\n\n\n\n   4.4K\n\n\n\nMint\n1388\n1669\n1519.167\n\n\n\n   1.5K\n\n\n\nRegular Espresso\n890\n1218\n1023.417\n\n\n\n   1.1K\n\n\n\n\n\n\n\n\n\n\n\nSimilarly, we can combining the bullet chart and sparklines using the steps below.\n\nbullet &lt;- coffeechain %&gt;%\n  filter(Date &gt;= \"2013-01-01\") %&gt;%\n  group_by(`Product`) %&gt;%\n  summarise(`Target` = sum(`Budget Sales`),\n            `Actual` = sum(`Sales`)) %&gt;%\n  ungroup() \n\n\nsales_data = sales_data %&gt;%\n  left_join(bullet)\n\n\nsales_data %&gt;%\n  gt() %&gt;%\n  gt_plt_sparkline('Monthly Sales') %&gt;%\n  gt_plt_bullet(column = Actual, \n                target = Target, \n                width = 28,\n                palette = c(\"lightblue\", \n                          \"black\")) %&gt;%\n  gt_theme_538()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProduct\nMin\nMax\nAverage\nMonthly Sales\nActual\n\n\n\n\nAmaretto\n1016\n1210\n1119.000\n\n\n\n   1.2K\n\n\n\n\n   \n\n\n\nCaffe Latte\n1398\n1653\n1528.333\n\n\n\n   1.5K\n\n\n\n\n   \n\n\n\nCaffe Mocha\n3322\n3828\n3613.917\n\n\n\n   3.7K\n\n\n\n\n   \n\n\n\nChamomile\n2967\n3395\n3217.417\n\n\n\n   3.3K\n\n\n\n\n   \n\n\n\nColombian\n5132\n5961\n5457.250\n\n\n\n   5.5K\n\n\n\n\n   \n\n\n\nDarjeeling\n2926\n3281\n3112.667\n\n\n\n   3.0K\n\n\n\n\n   \n\n\n\nDecaf Espresso\n3181\n3493\n3326.833\n\n\n\n   3.2K\n\n\n\n\n   \n\n\n\nDecaf Irish Cream\n2463\n2901\n2648.250\n\n\n\n   2.7K\n\n\n\n\n   \n\n\n\nEarl Grey\n2730\n3005\n2841.833\n\n\n\n   3.0K\n\n\n\n\n   \n\n\n\nGreen Tea\n1339\n1476\n1398.750\n\n\n\n   1.5K\n\n\n\n\n   \n\n\n\nLemon\n3851\n4418\n4080.833\n\n\n\n   4.4K\n\n\n\n\n   \n\n\n\nMint\n1388\n1669\n1519.167\n\n\n\n   1.5K\n\n\n\n\n   \n\n\n\nRegular Espresso\n890\n1218\n1023.417\n\n\n\n   1.1K"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#interactive-information-dashboard-design-reactable-and-reactablefmtr-methods",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#interactive-information-dashboard-design-reactable-and-reactablefmtr-methods",
    "title": "Hands-on_Ex10",
    "section": "",
    "text": "In this section, you will learn how to create interactive information dashboard by using reactable and reactablefmtr packages. Before getting started, it is highly recommended for you to visit the webpage of these two packages and review all the materials provided on the webpages at least once. You done not have to understand and remember everything provided but at least have an overview of the purposes and functions provided by them.\nIn order to build an interactive sparklines, we need to install dataui R package by using the code chunk below.\n\nremotes::install_github(\"timelyportfolio/dataui\")\n\nNext, you all need to load the package onto R environment by using the code chunk below.\n\nlibrary(dataui)\n\n\n\nSimilar to gtExtras, to plot an interactive sparklines by using reactablefmtr package we need to prepare the list field by using the code chunk below.\n\nreport &lt;- report %&gt;%\n  group_by(Product) %&gt;%\n  summarize(`Monthly Sales` = list(Sales))\n\nNext, react_sparkline will be to plot the sparklines as shown below.\n\nreactable(\n  report,\n  columns = list(\n    Product = colDef(maxWidth = 200),\n    `Monthly Sales` = colDef(\n      cell = react_sparkline(report)\n    )\n  )\n)\n\n\n\n\n\n\n\n\nBy default the pagesize is 10. In the code chunk below, arguments defaultPageSize is used to change the default setting.\n\nreactable(\n  report,\n  defaultPageSize = 13,\n  columns = list(\n    Product = colDef(maxWidth = 200),\n    `Monthly Sales` = colDef(\n      cell = react_sparkline(report)\n    )\n  )\n)\n\n\n\n\n\n\n\n\nIn the code chunk below highlight_points argument is used to show the minimum and maximum values points and label argument is used to label first and last values.\n\nreactable(\n  report,\n  defaultPageSize = 13,\n  columns = list(\n    Product = colDef(maxWidth = 200),\n    `Monthly Sales` = colDef(\n      cell = react_sparkline(\n        report,\n        highlight_points = highlight_points(\n          min = \"red\", max = \"blue\"),\n        labels = c(\"first\", \"last\")\n        )\n    )\n  )\n)\n\n\n\n\n\n\n\n\nIn the code chunk below statline argument is used to show the mean line.\n\nreactable(\n  report,\n  defaultPageSize = 13,\n  columns = list(\n    Product = colDef(maxWidth = 200),\n    `Monthly Sales` = colDef(\n      cell = react_sparkline(\n        report,\n        highlight_points = highlight_points(\n          min = \"red\", max = \"blue\"),\n        statline = \"mean\"\n        )\n    )\n  )\n)\n\n\n\n\n\n\n\n\nInstead adding reference line, bandline can be added by using the bandlineargument.\n\nreactable(\n  report,\n  defaultPageSize = 13,\n  columns = list(\n    Product = colDef(maxWidth = 200),\n    `Monthly Sales` = colDef(\n      cell = react_sparkline(\n        report,\n        highlight_points = highlight_points(\n          min = \"red\", max = \"blue\"),\n        line_width = 1,\n        bandline = \"innerquartiles\",\n        bandline_color = \"green\"\n        )\n    )\n  )\n)\n\n\n\n\n\n\n\n\nInstead of displaying the values as sparklines, we can display them as sparkbars as shiwn below.\n\nreactable(\n  report,\n  defaultPageSize = 13,\n  columns = list(\n    Product = colDef(maxWidth = 200),\n    `Monthly Sales` = colDef(\n      cell = react_sparkbar(\n        report,\n        highlight_bars = highlight_bars(\n          min = \"red\", max = \"blue\"),\n        bandline = \"innerquartiles\",\n        statline = \"mean\")\n    )\n  )\n)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04(c)/Hands-on_Ex04(c).html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex04(c)/Hands-on_Ex04(c).html#overview",
    "title": "Hands-on Exercise 4(c): Funnel Plots for Fair Comparisons",
    "section": "1 Overview",
    "text": "1 Overview\nFunnel plot is a specially designed data visualisation for conducting unbiased comparison between outlets, stores or business entities. By the end of this hands-on exercise, you will gain hands-on experience on:\n\nplotting funnel plots by using funnelPlotR package,\nplotting static funnel plot by using ggplot2 package, and\nplotting interactive funnel plot by using both plotly R and ggplot2 packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04(c)/Hands-on_Ex04(c).html#installing-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex04(c)/Hands-on_Ex04(c).html#installing-and-launching-r-packages",
    "title": "Hands-on Exercise 4(c): Funnel Plots for Fair Comparisons",
    "section": "2 Installing and Launching R Packages",
    "text": "2 Installing and Launching R Packages\nIn this exercise, four R packages will be used. They are:\n\nreadr for importing csv into R.\nFunnelPlotR for creating funnel plot.\nggplot2 for creating funnel plot manually.\nknitr for building static html table.\nplotly for creating interactive funnel plot.\n\n\n\nClick to view code\npacman::p_load(tidyverse, FunnelPlotR, plotly, knitr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04(c)/Hands-on_Ex04(c).html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex04(c)/Hands-on_Ex04(c).html#importing-data",
    "title": "Hands-on Exercise 4(c): Funnel Plots for Fair Comparisons",
    "section": "3 Importing Data",
    "text": "3 Importing Data\nIn this section, COVID-19_DKI_Jakarta will be used. The data was downloaded from Open Data Covid-19 Provinsi DKI Jakarta portal. For this hands-on exercise, we are going to compare the cumulative COVID-19 cases and death by sub-district (i.e. kelurahan) as at 31st July 2021, DKI Jakarta.\nThe code chunk below imports the data into R and save it into a tibble data frame object called covid19.\n\n\nClick to view code\ncovid19 &lt;- read_csv(\"Data/COVID-19_DKI_Jakarta.csv\") %&gt;%\n  mutate_if(is.character, as.factor)\ncovid19\n\n\n# A tibble: 267 × 7\n   `Sub-district ID` City       District `Sub-district` Positive Recovered Death\n               &lt;dbl&gt; &lt;fct&gt;      &lt;fct&gt;    &lt;fct&gt;             &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;\n 1        3172051003 JAKARTA U… PADEMAN… ANCOL              1776      1691    26\n 2        3173041007 JAKARTA B… TAMBORA  ANGKE              1783      1720    29\n 3        3175041005 JAKARTA T… KRAMAT … BALE KAMBANG       2049      1964    31\n 4        3175031003 JAKARTA T… JATINEG… BALI MESTER         827       797    13\n 5        3175101006 JAKARTA T… CIPAYUNG BAMBU APUS         2866      2792    27\n 6        3174031002 JAKARTA S… MAMPANG… BANGKA             1828      1757    26\n 7        3175051002 JAKARTA T… PASAR R… BARU               2541      2433    37\n 8        3175041004 JAKARTA T… KRAMAT … BATU AMPAR         3608      3445    68\n 9        3171071002 JAKARTA P… TANAH A… BENDUNGAN HIL…     2012      1937    38\n10        3175031002 JAKARTA T… JATINEG… BIDARA CINA        2900      2773    52\n# ℹ 257 more rows"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04(c)/Hands-on_Ex04(c).html#funnelplotr-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04(c)/Hands-on_Ex04(c).html#funnelplotr-methods",
    "title": "Hands-on Exercise 4(c): Funnel Plots for Fair Comparisons",
    "section": "4 FunnelPlotR methods",
    "text": "4 FunnelPlotR methods\nFunnelPlotR package uses ggplot to generate funnel plots. It requires a numerator(events of interest), denominator (population to be considered) and group. The key arguments selected for customisation are:\n\nlimit: plot limits (95 or 99).\nlabel_outliers: to label outliers (true or false).\nPoisson_limits: to add Poisson limits to the plot.\nOD_adjust: to add overdispersed limits to the plot.\nxrange and yrange: to specify the range to display for axes, acts like a zoom function.\nOther aesthetic components such as graph title, axis labels etc.\n\n\n4.1 FunnelPlotR methods: The basic plot\nThe code chunk below plots a funnel plot.\n\n\nClick to view code\nfunnel_plot(.data = covid19,\n            numerator = Positive,\n            denominator = Death,\n            group = 'Sub-district')\n\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 0 are outliers. \nPlot is adjusted for overdispersion. \n\n\nA funnel plot object with 267 points of which 0 are outliers. Plot is adjusted for overdispersion. Things to learn from the code chunk above.\n\ngroup in this function is different from the scatterplot. Here, it defines the level of the points to be plotted i.e. Sub-district, District or City. If Cityc is chosen, there are only six data points.\nBy default, data_typeargument is “SR”.\nlimit: Plot limits, accepted values are: 95 or 99, corresponding to 95% or 99.8% quantiles of the distribution.\n\n\n\n4.2 FunnelPlotR methods: Makeover 1\nThe code chunk below plots a funnel plot.\n\n\nClick to view code\nfunnel_plot(.data = covid19,\n  numerator = Death,\n  denominator = Positive,\n  group = `Sub-district`,\n  data_type = \"PR\",     #&lt;&lt;\n  x_range = c(0, 6500),  #&lt;&lt;\n  y_range = c(0, 0.05)   #&lt;&lt;\n)\n\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\nA funnel plot object with 267 points of which 7 are outliers. Plot is adjusted for overdispersion. Things to learn from the code chunk above. + data_type argument is used to change from default “SR” to “PR” (i.e. proportions). + xrange and yrange are used to set the range of x-axis and y-axis\n\n\n4.3 FunnelPlotR methods: Makeover 2\nThe code chunk below plots a funnel plot.\n\n\nClick to view code\nfunnel_plot(.data = covid19,\n            numerator = Death,\n            denominator = Positive,\n            group = `Sub-district`,\n            data_type = \"PR\",\n            x_range = c(0,6500),\n            y_range = c(0,0.05),\n            label = NA,\n            title = \"Cumulative COVID-19 Fatality Rate by Cumulative Total Number of COVID-19 Positive Cases\",\n            x_label = \"Cumulative COVID-19 Positive Cases\",\n            y_label = \"Cumulative Fatality Rate\")\n\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \nThings to learn from the code chunk above.\n\nlabel = NA argument is to removed the default label outliers feature.\ntitle argument is used to add plot title.\nx_label and y_label arguments are used to add/edit x-axis and y-axis titles."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04(c)/Hands-on_Ex04(c).html#funnel-plot-for-fair-visual-comparison-ggplot2-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04(c)/Hands-on_Ex04(c).html#funnel-plot-for-fair-visual-comparison-ggplot2-methods",
    "title": "Hands-on Exercise 4(c): Funnel Plots for Fair Comparisons",
    "section": "5 Funnel Plot for Fair Visual Comparison: ggplot2 methods",
    "text": "5 Funnel Plot for Fair Visual Comparison: ggplot2 methods\nIn this section, you will gain hands-on experience on building funnel plots step-by-step by using ggplot2. It aims to enhance you working experience of ggplot2 to customise speciallised data visualisation like funnel plot.\n\n5.1 Computing the basic derived fields\nTo plot the funnel plot from scratch, we need to derive cumulative death rate and standard error of cumulative death rate.\n\n\nClick to view code\ndf &lt;- covid19 %&gt;%\n  mutate(rate = Death / Positive) %&gt;%\n  mutate(rate.se = sqrt((rate*(1-rate)) / (Positive))) %&gt;%\n  filter(rate &gt; 0)\n\n\nNext, the fit.mean is computed by using the code chunk below.\n\n\nClick to view code\nfit.mean &lt;- weighted.mean(df$rate, 1/df$rate.se^2)\n\n\n\n\n5.2 Calculate lower and upper limits for 95% and 99.9% CI\nThe code chunk below is used to compute the lower and upper limits for 95% confidence interval.\n\n\nClick to view code\nnumber.seq &lt;- seq(1, max(df$Positive), 1)\nnumber.ll95 &lt;- fit.mean - 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul95 &lt;- fit.mean + 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ll999 &lt;- fit.mean - 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul999 &lt;- fit.mean + 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \ndfCI &lt;- data.frame(number.ll95, number.ul95, number.ll999, \n                   number.ul999, number.seq, fit.mean)\n\n\n\n\n5.3 Plotting a static funnel plot\nIn the code chunk below, ggplot2 functions are used to plot a static funnel plot.\n\n\nClick to view code\np &lt;- ggplot(df, aes(x = Positive, y = rate)) +\n  geom_point(aes(label=`Sub-district`), \n             alpha=0.4) +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_hline(data = dfCI, \n             aes(yintercept = fit.mean), \n             size = 0.4, \n             colour = \"grey40\") +\n  coord_cartesian(ylim=c(0,0.05)) +\n  annotate(\"text\", x = 1, y = -0.13, label = \"95%\", size = 3, colour = \"grey40\") + \n  annotate(\"text\", x = 4.5, y = -0.18, label = \"99%\", size = 3, colour = \"grey40\") + \n  ggtitle(\"Cumulative Fatality Rate by Cumulative Number of COVID-19 Cases\") +\n  xlab(\"Cumulative Number of COVID-19 Cases\") + \n  ylab(\"Cumulative Fatality Rate\") +\n  theme_light() +\n  theme(plot.title = element_text(size=12),\n        legend.position = c(0.91,0.85), \n        legend.title = element_text(size=7),\n        legend.text = element_text(size=7),\n        legend.background = element_rect(colour = \"grey60\", linetype = \"dotted\"),\n        legend.key.height = unit(0.3, \"cm\"))\np\n\n\n\n\n\n\n\n\n\n\n\n5.4 Interactive Funnel Plot: plotly + ggplot2\nThe funnel plot created using ggplot2 functions can be made interactive with ggplotly() of plotly r package.\n\n\nClick to view code\nfp_ggplotly &lt;- ggplotly(p,\n  tooltip = c(\"label\", \n              \"x\", \n              \"y\"))\nfp_ggplotly"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04(c)/Hands-on_Ex04(c).html#references",
    "href": "Hands-on_Ex/Hands-on_Ex04(c)/Hands-on_Ex04(c).html#references",
    "title": "Hands-on Exercise 4(c): Funnel Plots for Fair Comparisons",
    "section": "6 References",
    "text": "6 References\n\nfunnelPlotR package.\nFunnel Plots for Indirectly-standardised ratios.\nChanging funnel plot options\nggplot2 package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03(a)/Hands-on_Ex03(a).html#tooltip-effect-with-tooltip-aesthetic",
    "href": "Hands-on_Ex/Hands-on_Ex03(a)/Hands-on_Ex03(a).html#tooltip-effect-with-tooltip-aesthetic",
    "title": "Hands-on Exercise 3(a): Programming Interactive Data Visualisation with R",
    "section": "3.1 Tooltip effect with tooltip aesthetic",
    "text": "3.1 Tooltip effect with tooltip aesthetic\n\n\nClick to view code\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = ID),\n    stackgroups = TRUE, \n    binwidth = 1, \n    method = \"histodot\") +\n  scale_y_continuous(NULL, \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618\n)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03(a)/Hands-on_Ex03(a).html#displaying-multiple-information-on-tooltip",
    "href": "Hands-on_Ex/Hands-on_Ex03(a)/Hands-on_Ex03(a).html#displaying-multiple-information-on-tooltip",
    "title": "Hands-on Exercise 3(a): Programming Interactive Data Visualisation with R",
    "section": "4.1 Displaying multiple information on tooltip",
    "text": "4.1 Displaying multiple information on tooltip\n\n\nClick to view code\nexam_data$tooltip &lt;- c(paste0(     \n  \"Name = \", exam_data$ID,         \n  \"\\n Class = \", exam_data$CLASS)) \n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = exam_data$tooltip), \n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 8,\n  height_svg = 8*0.618\n)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03(a)/Hands-on_Ex03(a).html#customising-tooltip-style",
    "href": "Hands-on_Ex/Hands-on_Ex03(a)/Hands-on_Ex03(a).html#customising-tooltip-style",
    "title": "Hands-on Exercise 3(a): Programming Interactive Data Visualisation with R",
    "section": "4.2 Customising Tooltip style",
    "text": "4.2 Customising Tooltip style\n\n\nClick to view code\ntooltip_css &lt;- \"background-color:white; #&lt;&lt;\nfont-style:bold; color:black;\" #&lt;&lt;\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = ID),                   \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(    #&lt;&lt;\n    opts_tooltip(    #&lt;&lt;\n      css = tooltip_css)) #&lt;&lt;\n)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03(a)/Hands-on_Ex03(a).html#displaying-statistics-on-tooltip",
    "href": "Hands-on_Ex/Hands-on_Ex03(a)/Hands-on_Ex03(a).html#displaying-statistics-on-tooltip",
    "title": "Hands-on Exercise 3(a): Programming Interactive Data Visualisation with R",
    "section": "4.3 Displaying statistics on tooltip",
    "text": "4.3 Displaying statistics on tooltip\n\n\nClick to view code\ntooltip &lt;- function(y, ymax, accuracy = .01) {\n  mean &lt;- scales::number(y, accuracy = accuracy)\n  sem &lt;- scales::number(ymax - y, accuracy = accuracy)\n  paste(\"Mean maths scores:\", mean, \"+/-\", sem)\n}\n\ngg_point &lt;- ggplot(data=exam_data, \n                   aes(x = RACE),\n) +\n  stat_summary(aes(y = MATHS, \n                   tooltip = after_stat(  \n                     tooltip(y, ymax))),  \n    fun.data = \"mean_se\", \n    geom = GeomInteractiveCol,  \n    fill = \"light blue\"\n  ) +\n  stat_summary(aes(y = MATHS),\n    fun.data = mean_se,\n    geom = \"errorbar\", width = 0.2, size = 0.2\n  )\n\ngirafe(ggobj = gg_point,\n       width_svg = 8,\n       height_svg = 8*0.618)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03(a)/Hands-on_Ex03(a).html#hover-effect-with-data_id-aesthetic",
    "href": "Hands-on_Ex/Hands-on_Ex03(a)/Hands-on_Ex03(a).html#hover-effect-with-data_id-aesthetic",
    "title": "Hands-on Exercise 3(a): Programming Interactive Data Visualisation with R",
    "section": "4.4 Hover effect with data_id aesthetic",
    "text": "4.4 Hover effect with data_id aesthetic\n\n\nClick to view code\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(           \n    aes(data_id = CLASS),             \n    stackgroups = TRUE,               \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618                      \n)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03(a)/Hands-on_Ex03(a).html#styling-hover-effect",
    "href": "Hands-on_Ex/Hands-on_Ex03(a)/Hands-on_Ex03(a).html#styling-hover-effect",
    "title": "Hands-on Exercise 3(a): Programming Interactive Data Visualisation with R",
    "section": "4.5 Styling hover effect",
    "text": "4.5 Styling hover effect\n\n\nClick to view code\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03(a)/Hands-on_Ex03(a).html#combining-toolip-and-hover-effect",
    "href": "Hands-on_Ex/Hands-on_Ex03(a)/Hands-on_Ex03(a).html#combining-toolip-and-hover-effect",
    "title": "Hands-on Exercise 3(a): Programming Interactive Data Visualisation with R",
    "section": "4.6 Combining toolip and hover effect",
    "text": "4.6 Combining toolip and hover effect\n\n\nClick to view code\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = CLASS, \n        data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03(a)/Hands-on_Ex03(a).html#click-effect-with-onclick",
    "href": "Hands-on_Ex/Hands-on_Ex03(a)/Hands-on_Ex03(a).html#click-effect-with-onclick",
    "title": "Hands-on Exercise 3(a): Programming Interactive Data Visualisation with R",
    "section": "4.7 Click effect with onclick",
    "text": "4.7 Click effect with onclick\n\n\nClick to view code\nexam_data$onclick &lt;- sprintf(\"window.open(\\\"%s%s\\\")\",\n\"https://www.moe.gov.sg/schoolfinder?journey=Primary%20school\",\nas.character(exam_data$ID))\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(onclick = onclick),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03(a)/Hands-on_Ex03(a).html#coordinated-multiple-views-with-ggiraph",
    "href": "Hands-on_Ex/Hands-on_Ex03(a)/Hands-on_Ex03(a).html#coordinated-multiple-views-with-ggiraph",
    "title": "Hands-on Exercise 3(a): Programming Interactive Data Visualisation with R",
    "section": "4.8 Coordinated Multiple Views with ggiraph",
    "text": "4.8 Coordinated Multiple Views with ggiraph\n\n\nClick to view code\np1 &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +  \n  coord_cartesian(xlim=c(0,100)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\np2 &lt;- ggplot(data=exam_data, \n       aes(x = ENGLISH)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") + \n  coord_cartesian(xlim=c(0,100)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\ngirafe(code = print(p1 + p2), \n       width_svg = 6,\n       height_svg = 3,\n       options = list(\n         opts_hover(css = \"fill: #202020;\"),\n         opts_hover_inv(css = \"opacity:0.2;\")\n         )\n       )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03(a)/Hands-on_Ex03(a).html#interactive-data-visualisation---plotly-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03(a)/Hands-on_Ex03(a).html#interactive-data-visualisation---plotly-methods",
    "title": "Hands-on Exercise 3(a): Programming Interactive Data Visualisation with R",
    "section": "4.9 Interactive Data Visualisation - plotly methods!",
    "text": "4.9 Interactive Data Visualisation - plotly methods!\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\n\nClick to view code\ny1 &lt;- plot_ly(data = exam_data, \n             x = ~MATHS, \n             y = ~ENGLISH)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03(a)/Hands-on_Ex03(a).html#working-with-visual-variable-plot_ly-method",
    "href": "Hands-on_Ex/Hands-on_Ex03(a)/Hands-on_Ex03(a).html#working-with-visual-variable-plot_ly-method",
    "title": "Hands-on Exercise 3(a): Programming Interactive Data Visualisation with R",
    "section": "4.10 Working with visual variable: plot_ly() method",
    "text": "4.10 Working with visual variable: plot_ly() method\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\n\nClick to view code\ny2 &lt;- plot_ly(data = exam_data, \n        x = ~ENGLISH, \n        y = ~MATHS, \n        color = ~RACE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03(a)/Hands-on_Ex03(a).html#creating-an-interactive-scatter-plot-ggplotly-method",
    "href": "Hands-on_Ex/Hands-on_Ex03(a)/Hands-on_Ex03(a).html#creating-an-interactive-scatter-plot-ggplotly-method",
    "title": "Hands-on Exercise 3(a): Programming Interactive Data Visualisation with R",
    "section": "4.11 Creating an interactive scatter plot: ggplotly() method",
    "text": "4.11 Creating an interactive scatter plot: ggplotly() method\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\n\nClick to view code\np &lt;- ggplot(data=exam_data, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\ny3 &lt;- ggplotly(p)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03(a)/Hands-on_Ex03(a).html#coordinated-multiple-views-with-plotly",
    "href": "Hands-on_Ex/Hands-on_Ex03(a)/Hands-on_Ex03(a).html#coordinated-multiple-views-with-plotly",
    "title": "Hands-on Exercise 3(a): Programming Interactive Data Visualisation with R",
    "section": "4.12 Coordinated Multiple Views with plotly",
    "text": "4.12 Coordinated Multiple Views with plotly\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\n\nClick to view code\nd &lt;- highlight_key(exam_data)\np1 &lt;- ggplot(data=d, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\np2 &lt;- ggplot(data=d, \n            aes(x = MATHS,\n                y = SCIENCE)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\ny4 &lt;- subplot(ggplotly(p1),\n        ggplotly(p2))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03(a)/Hands-on_Ex03(a).html#interactive-data-visualisation---crosstalk-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03(a)/Hands-on_Ex03(a).html#interactive-data-visualisation---crosstalk-methods",
    "title": "Hands-on Exercise 3(a): Programming Interactive Data Visualisation with R",
    "section": "4.13 Interactive Data Visualisation - crosstalk methods!",
    "text": "4.13 Interactive Data Visualisation - crosstalk methods!\n\n4.13.1 Interactive Data Table: DT package\n\n\nClick to view code\nDT::datatable(exam_data, class= \"compact\")\n\n\n\n\n\n\n\n\n4.13.2 Linked brushing: crosstalk method\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nClick to view code\nd &lt;- highlight_key(exam_data) \np &lt;- ggplot(d, \n            aes(ENGLISH, \n                MATHS)) + \n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\ngg &lt;- highlight(ggplotly(p),        \n                \"plotly_selected\")  \n\ny5 &lt;- crosstalk::bscols(gg,               \n                  DT::datatable(d), \n                  widths = 5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03(b)/Hands-on_Ex03(b).html#building-a-static-population-bubble-plot",
    "href": "Hands-on_Ex/Hands-on_Ex03(b)/Hands-on_Ex03(b).html#building-a-static-population-bubble-plot",
    "title": "Hands-on Exercise 3(b): Programming Animated Statistical Graphics with R",
    "section": "3.1 Building a static population bubble plot",
    "text": "3.1 Building a static population bubble plot\n\n\nClick to view code\nggplot(globalPop, aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03(b)/Hands-on_Ex03(b).html#building-the-animated-bubble-plot",
    "href": "Hands-on_Ex/Hands-on_Ex03(b)/Hands-on_Ex03(b).html#building-the-animated-bubble-plot",
    "title": "Hands-on Exercise 3(b): Programming Animated Statistical Graphics with R",
    "section": "3.2 Building the animated bubble plot",
    "text": "3.2 Building the animated bubble plot\n\n\nClick to view code\nggplot(globalPop, aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young') +\n  transition_time(Year) +       \n  ease_aes('linear')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03(b)/Hands-on_Ex03(b).html#building-an-animated-bubble-plot-ggplotly-method",
    "href": "Hands-on_Ex/Hands-on_Ex03(b)/Hands-on_Ex03(b).html#building-an-animated-bubble-plot-ggplotly-method",
    "title": "Hands-on Exercise 3(b): Programming Animated Statistical Graphics with R",
    "section": "4.1 Building an animated bubble plot: ggplotly() method",
    "text": "4.1 Building an animated bubble plot: ggplotly() method\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\n\nClick to view code\ngg &lt;- ggplot(globalPop, \n       aes(x = Old, \n           y = Young, \n           size = Population, \n           colour = Country)) +\n  geom_point(aes(size = Population,\n                 frame = Year),\n             alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(x = '% Aged', \n       y = '% Young')\n\ny6 &lt;- ggplotly(gg)\n\n\n\n\n\n\nOvercome\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\n\nClick to view code\ngg &lt;- ggplot(globalPop, \n       aes(x = Old, \n           y = Young, \n           size = Population, \n           colour = Country)) +\n  geom_point(aes(size = Population,\n                 frame = Year),\n             alpha = 0.7) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(x = '% Aged', \n       y = '% Young') + \n  theme(legend.position='none')\n\ny7 &lt;- ggplotly(gg)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03(b)/Hands-on_Ex03(b).html#building-an-animated-bubble-plot-plot_ly-method",
    "href": "Hands-on_Ex/Hands-on_Ex03(b)/Hands-on_Ex03(b).html#building-an-animated-bubble-plot-plot_ly-method",
    "title": "Hands-on Exercise 3(b): Programming Animated Statistical Graphics with R",
    "section": "4.2 Building an animated bubble plot: plot_ly() method",
    "text": "4.2 Building an animated bubble plot: plot_ly() method\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\n\nClick to view code\nbp &lt;- globalPop %&gt;%\n  plot_ly(x = ~Old, \n          y = ~Young, \n          size = ~Population, \n          color = ~Continent,\n          sizes = c(2, 100),\n          frame = ~Year, \n          text = ~Country, \n          hoverinfo = \"text\",\n          type = 'scatter',\n          mode = 'markers'\n          ) %&gt;%\n  layout(showlegend = FALSE)\ny8 &lt;- bp"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09(e)/Hands-on_Ex09(e).html",
    "href": "Hands-on_Ex/Hands-on_Ex09(e)/Hands-on_Ex09(e).html",
    "title": "Hands-on_Ex09(e)",
    "section": "",
    "text": "Correlation coefficient is a popular statistic that use to measure the type and strength of the relationship between two variables. The values of a correlation coefficient ranges between -1.0 and 1.0. A correlation coefficient of 1 shows a perfect linear relationship between the two variables, while a -1.0 shows a perfect inverse relationship between the two variables. A correlation coefficient of 0.0 shows no linear relationship between the two variables.\nWhen multivariate data are used, the correlation coefficeints of the pair comparisons are displayed in a table form known as correlation matrix or scatterplot matrix.\nThere are three broad reasons for computing a correlation matrix.\n\nTo reveal the relationship between high-dimensional variables pair-wisely.\nTo input into other analyses. For example, people commonly use correlation matrices as inputs for exploratory factor analysis, confirmatory factor analysis, structural equation models, and linear regression when excluding missing values pairwise.\nAs a diagnostic when checking other analyses. For example, with linear regression a high amount of correlations suggests that the linear regression’s estimates will be unreliable.\n\nWhen the data is large, both in terms of the number of observations and the number of variables, Corrgram tend to be used to visually explore and analyse the structure and the patterns of relations among variables. It is designed based on two main schemes:\n\nRendering the value of a correlation to depict its sign and magnitude, and\nReordering the variables in a correlation matrix so that “similar” variables are positioned adjacently, facilitating perception.\n\nIn this hands-on exercise, you will learn how to plot data visualisation for visualising correlation matrix with R. It consists of three main sections. First, you will learn how to create correlation matrix using pairs()of R Graphics. Next, you will learn how to plot corrgram using corrplot package of R. Lastly, you will learn how to create an interactive correlation matrix using plotly R.\n\n\n\nBefore you get started, you are required to open a new Quarto document. Keep the default html authoring format.\nNext, you will use the code chunk below to install and launch corrplot, ggpubr, plotly and tidyverse in RStudio.\n\npacman::p_load(corrplot, ggstatsplot, tidyverse)\n\n\n\n\nIn this hands-on exercise, the Wine Quality Data Set of UCI Machine Learning Repository will be used. The data set consists of 13 variables and 6497 observations. For the purpose of this exercise, we have combined the red wine and white wine data into one data file. It is called wine_quality and is in csv file format.\n\n\nFirst, let us import the data into R by using read_csv() of readr package.\n\nwine &lt;- read_csv(\"data/wine_quality.csv\")\n\nNotice that beside quality and type, the rest of the variables are numerical and continuous data type.\n\n\n\n\nThere are more than one way to build scatterplot matrix with R. In this section, you will learn how to create a scatterplot matrix by using the pairs function of R Graphics.\nBefore you continue to the next step, you should read the syntax description of pairsfunction.\n4.1 Building a basic correlation matrix\nFigure below shows the scatter plot matrix of Wine Quality Data. It is a 11 by 11 matrix.\n\npairs(wine[,1:11])\n\n\n\n\n\n\n\n\nThe required input of pairs() can be a matrix or data frame. The code chunk used to create the scatterplot matrix is relatively simple. It uses the default pairs function. Columns 2 to 12 of wine dataframe is used to build the scatterplot matrix. The variables are: fixed acidity, volatile acidity, citric acid, residual sugar, chlorides, free sulfur dioxide, total sulfur dioxide, density, pH, sulphates and alcohol.\n\npairs(wine[,2:12])\n\n\n\n\n\n\n\n\n\n\npairs function of R Graphics provided many customisation arguments. For example, it is a common practice to show either the upper half or lower half of the correlation matrix instead of both. This is because a correlation matrix is symmetric.\nTo show the lower half of the correlation matrix, the upper.panel argument will be used as shown in the code chunk below.\n\npairs(wine[,2:12], upper.panel = NULL)\n\n\n\n\n\n\n\n\nSimilarly, you can display the upper half of the correlation matrix by using the code chun below.\n\npairs(wine[,2:12], lower.panel = NULL)\n\n\n\n\n\n\n\n\n\n\n\nTo show the correlation coefficient of each pair of variables instead of a scatter plot, panel.cor function will be used. This will also show higher correlations in a larger font.\nDon’t worry about the details for now-just type this code into your R session or script. Let’s have more fun way to display the correlation matrix.\n\npanel.cor &lt;- function(x, y, digits=2, prefix=\"\", cex.cor, ...) {\nusr &lt;- par(\"usr\")\non.exit(par(usr))\npar(usr = c(0, 1, 0, 1))\nr &lt;- abs(cor(x, y, use=\"complete.obs\"))\ntxt &lt;- format(c(r, 0.123456789), digits=digits)[1]\ntxt &lt;- paste(prefix, txt, sep=\"\")\nif(missing(cex.cor)) cex.cor &lt;- 0.8/strwidth(txt)\ntext(0.5, 0.5, txt, cex = cex.cor * (1 + r) / 2)\n}\n\npairs(wine[,2:12], \n      upper.panel = panel.cor)\n\n\n\n\n\n\n\n\n\n\n\n\nOne of the major limitation of the correlation matrix is that the scatter plots appear very cluttered when the number of observations is relatively large (i.e. more than 500 observations). To over come this problem, Corrgram data visualisation technique suggested by D. J. Murdoch and E. D. Chow (1996) and Friendly, M (2002) and will be used.\nThe are at least three R packages provide function to plot corrgram, they are:\n\ncorrgram\nellipse\ncorrplot\n\nOn top that, some R package like ggstatsplot package also provides functions for building corrgram.\nIn this section, you will learn how to visualising correlation matrix by using ggcorrmat() of ggstatsplotpackage.\n\n\nOn of the advantage of using ggcorrmat() over many other methods to visualise a correlation matrix is it’s ability to provide a comprehensive and yet professional statistical report as shown in the figure below.\n\nggstatsplot::ggcorrmat(\n  data = wine, \n  cor.vars = 1:11)\n\n\n\n\n\n\n\n\n\nggstatsplot::ggcorrmat(\n  data = wine, \n  cor.vars = 1:11,\n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10),\n  title    = \"Correlogram for wine dataset\",\n  subtitle = \"Four pairs are no significant at p &lt; 0.05\"\n)\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\ncor.vars argument is used to compute the correlation matrix needed to build the corrgram.\nggcorrplot.args argument provide additional (mostly aesthetic) arguments that will be passed to ggcorrplot::ggcorrplot function. The list should avoid any of the following arguments since they are already internally being used: corr, method, p.mat, sig.level, ggtheme, colors, lab, pch, legend.title, digits.\n\nThe sample sub-code chunk can be used to control specific component of the plot such as the font size of the x-axis, y-axis, and the statistical report.\n\nggplot.component = list(\n    theme(text=element_text(size=5),\n      axis.text.x = element_text(size = 8),\n      axis.text.y = element_text(size = 8)))\n\n\n\n\n\nSince ggstasplot is an extension of ggplot2, it also supports faceting. However the feature is not available in ggcorrmat() but in the grouped_ggcorrmat() of ggstatsplot.\n\ngrouped_ggcorrmat(\n  data = wine,\n  cor.vars = 1:11,\n  grouping.var = type,\n  type = \"robust\",\n  p.adjust.method = \"holm\",\n  plotgrid.args = list(ncol = 2),\n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10),\n  annotation.args = list(\n    tag_levels = \"a\",\n    title = \"Correlogram for wine dataset\",\n    subtitle = \"The measures are: alcohol, sulphates, fixed acidity, citric acid, chlorides, residual sugar, density, free sulfur dioxide and volatile acidity\",\n    caption = \"Dataset: UCI Machine Learning Repository\"\n  )\n)\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\nto build a facet plot, the only argument needed is grouping.var.\nBehind group_ggcorrmat(), patchwork package is used to create the multiplot. plotgrid.argsargument provides a list of additional arguments passed to patchwork::wrap_plots, except for guides argument which is already separately specified earlier.\nLikewise, annotation.args argument is calling plot annotation arguments of patchwork package.\n\n\n\n\nIn this hands-on exercise, we will focus on corrplot. However, you are encouraged to explore the other two packages too.\nBefore getting started, you are required to read An Introduction to corrplot Package in order to gain basic understanding of corrplot package.\n\n\nBefore we can plot a corrgram using corrplot(), we need to compute the correlation matrix of wine data frame.\nIn the code chunk below, cor() of R Stats is used to compute the correlation matrix of wine data frame.\n\nwine.cor &lt;- cor(wine[, 1:11])\n\nNext, corrplot() is used to plot the corrgram by using all the default setting as shown in the code chunk below.\n\ncorrplot(wine.cor)\n\n\n\n\n\n\n\n\nNotice that the default visual object used to plot the corrgram is circle. The default layout of the corrgram is a symmetric matrix. The default colour scheme is diverging blue-red. Blue colours are used to represent pair variables with positive correlation coefficients and red colours are used to represent pair variables with negative correlation coefficients. The intensity of the colour or also know as saturation is used to represent the strength of the correlation coefficient. Darker colours indicate relatively stronger linear relationship between the paired variables. On the other hand, lighter colours indicates relatively weaker linear relationship.\n\n\n\nIn corrplot package, there are seven visual geometrics (parameter method) can be used to encode the attribute values. They are: circle, square, ellipse, number, shade, color and pie. The default is circle. As shown in the previous section, the default visual geometric of corrplot matrix is circle. However, this default setting can be changed by using the method argument as shown in the code chunk below.\n\ncorrplot(wine.cor, \n         method = \"ellipse\") \n\n\n\n\n\n\n\n\nFeel free to change the method argument to other supported visual geometrics.\n\n\n\ncorrplor() supports three layout types, namely: “full”, “upper” or “lower”. The default is “full” which display full matrix. The default setting can be changed by using the type argument of corrplot().\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         type=\"lower\")\n\n\n\n\n\n\n\n\nThe default layout of the corrgram can be further customised. For example, arguments diag and tl.col are used to turn off the diagonal cells and to change the axis text label colour to black colour respectively as shown in the code chunk and figure below.\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         type=\"lower\",\n         diag = FALSE,\n         tl.col = \"black\")\n\n\n\n\n\n\n\n\nPlease feel free to experiment with other layout design argument such as tl.pos, tl.cex, tl.offset, cl.pos, cl.cex and cl.offset, just to mention a few of them.\n\n\n\nWith corrplot package, it is possible to design corrgram with mixed visual matrix of one half and numerical matrix on the other half. In order to create a coorgram with mixed layout, the corrplot.mixed(), a wrapped function for mixed visualisation style will be used.\nFigure below shows a mixed layout corrgram plotted using wine quality data.\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\n\n\n\n\nThe code chunk used to plot the corrgram are shown below.\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\n\n\n\n\nNotice that argument lower and upper are used to define the visualisation method used. In this case ellipse is used to map the lower half of the corrgram and numerical matrix (i.e. number) is used to map the upper half of the corrgram. The argument tl.pos, on the other, is used to specify the placement of the axis label. Lastly, the diag argument is used to specify the glyph on the principal diagonal of the corrgram.\n\n\n\nIn statistical analysis, we are also interested to know which pair of variables their correlation coefficients are statistically significant.\nFigure below shows a corrgram combined with the significant test. The corrgram reveals that not all correlation pairs are statistically significant. For example the correlation between total sulfur dioxide and free surfur dioxide is statistically significant at significant level of 0.1 but not the pair between total sulfur dioxide and citric acid.\nWith corrplot package, we can use the cor.mtest() to compute the p-values and confidence interval for each pair of variables.\n\nwine.sig = cor.mtest(wine.cor, conf.level= .95)\n\nWe can then use the p.mat argument of corrplot function as shown in the code chunk below.\n\ncorrplot(wine.cor,\n         method = \"number\",\n         type = \"lower\",\n         diag = FALSE,\n         tl.col = \"black\",\n         tl.srt = 45,\n         p.mat = wine.sig$p,\n         sig.level = .05)\n\n\n\n\n\n\n\n\n\n\n\nMatrix reorder is very important for mining the hiden structure and pattern in a corrgram. By default, the order of attributes of a corrgram is sorted according to the correlation matrix (i.e. “original”). The default setting can be over-write by using the order argument of corrplot(). Currently, corrplot package support four sorting methods, they are:\n\n“AOE” is for the angular order of the eigenvectors. See Michael Friendly (2002) for details.\n“FPC” for the first principal component order.\n“hclust” for hierarchical clustering order, and “hclust.method” for the agglomeration method to be used.\n\n“hclust.method” should be one of “ward”, “single”, “complete”, “average”, “mcquitty”, “median” or “centroid”.\n\n“alphabet” for alphabetical order.\n\n“AOE”, “FPC”, “hclust”, “alphabet”. More algorithms can be found in seriation package.\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               order=\"AOE\",\n               tl.col = \"black\")\n\n\n\n\n\n\n\n\n\n\n\nIf using hclust, corrplot() can draw rectangles around the corrgram based on the results of hierarchical clustering.\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         tl.pos = \"lt\",\n         tl.col = \"black\",\n         order=\"hclust\",\n         hclust.method = \"ward.D\",\n         addrect = 3)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09(e)/Hands-on_Ex09(e).html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex09(e)/Hands-on_Ex09(e).html#overview",
    "title": "Hands-on_Ex09(e)",
    "section": "",
    "text": "Correlation coefficient is a popular statistic that use to measure the type and strength of the relationship between two variables. The values of a correlation coefficient ranges between -1.0 and 1.0. A correlation coefficient of 1 shows a perfect linear relationship between the two variables, while a -1.0 shows a perfect inverse relationship between the two variables. A correlation coefficient of 0.0 shows no linear relationship between the two variables.\nWhen multivariate data are used, the correlation coefficeints of the pair comparisons are displayed in a table form known as correlation matrix or scatterplot matrix.\nThere are three broad reasons for computing a correlation matrix.\n\nTo reveal the relationship between high-dimensional variables pair-wisely.\nTo input into other analyses. For example, people commonly use correlation matrices as inputs for exploratory factor analysis, confirmatory factor analysis, structural equation models, and linear regression when excluding missing values pairwise.\nAs a diagnostic when checking other analyses. For example, with linear regression a high amount of correlations suggests that the linear regression’s estimates will be unreliable.\n\nWhen the data is large, both in terms of the number of observations and the number of variables, Corrgram tend to be used to visually explore and analyse the structure and the patterns of relations among variables. It is designed based on two main schemes:\n\nRendering the value of a correlation to depict its sign and magnitude, and\nReordering the variables in a correlation matrix so that “similar” variables are positioned adjacently, facilitating perception.\n\nIn this hands-on exercise, you will learn how to plot data visualisation for visualising correlation matrix with R. It consists of three main sections. First, you will learn how to create correlation matrix using pairs()of R Graphics. Next, you will learn how to plot corrgram using corrplot package of R. Lastly, you will learn how to create an interactive correlation matrix using plotly R."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09(e)/Hands-on_Ex09(e).html#installing-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex09(e)/Hands-on_Ex09(e).html#installing-and-launching-r-packages",
    "title": "Hands-on_Ex09(e)",
    "section": "",
    "text": "Before you get started, you are required to open a new Quarto document. Keep the default html authoring format.\nNext, you will use the code chunk below to install and launch corrplot, ggpubr, plotly and tidyverse in RStudio.\n\npacman::p_load(corrplot, ggstatsplot, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09(e)/Hands-on_Ex09(e).html#importing-and-preparing-the-data-set",
    "href": "Hands-on_Ex/Hands-on_Ex09(e)/Hands-on_Ex09(e).html#importing-and-preparing-the-data-set",
    "title": "Hands-on_Ex09(e)",
    "section": "",
    "text": "In this hands-on exercise, the Wine Quality Data Set of UCI Machine Learning Repository will be used. The data set consists of 13 variables and 6497 observations. For the purpose of this exercise, we have combined the red wine and white wine data into one data file. It is called wine_quality and is in csv file format.\n\n\nFirst, let us import the data into R by using read_csv() of readr package.\n\nwine &lt;- read_csv(\"data/wine_quality.csv\")\n\nNotice that beside quality and type, the rest of the variables are numerical and continuous data type."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09(e)/Hands-on_Ex09(e).html#building-correlation-matrix-pairs-method",
    "href": "Hands-on_Ex/Hands-on_Ex09(e)/Hands-on_Ex09(e).html#building-correlation-matrix-pairs-method",
    "title": "Hands-on_Ex09(e)",
    "section": "",
    "text": "There are more than one way to build scatterplot matrix with R. In this section, you will learn how to create a scatterplot matrix by using the pairs function of R Graphics.\nBefore you continue to the next step, you should read the syntax description of pairsfunction.\n4.1 Building a basic correlation matrix\nFigure below shows the scatter plot matrix of Wine Quality Data. It is a 11 by 11 matrix.\n\npairs(wine[,1:11])\n\n\n\n\n\n\n\n\nThe required input of pairs() can be a matrix or data frame. The code chunk used to create the scatterplot matrix is relatively simple. It uses the default pairs function. Columns 2 to 12 of wine dataframe is used to build the scatterplot matrix. The variables are: fixed acidity, volatile acidity, citric acid, residual sugar, chlorides, free sulfur dioxide, total sulfur dioxide, density, pH, sulphates and alcohol.\n\npairs(wine[,2:12])\n\n\n\n\n\n\n\n\n\n\npairs function of R Graphics provided many customisation arguments. For example, it is a common practice to show either the upper half or lower half of the correlation matrix instead of both. This is because a correlation matrix is symmetric.\nTo show the lower half of the correlation matrix, the upper.panel argument will be used as shown in the code chunk below.\n\npairs(wine[,2:12], upper.panel = NULL)\n\n\n\n\n\n\n\n\nSimilarly, you can display the upper half of the correlation matrix by using the code chun below.\n\npairs(wine[,2:12], lower.panel = NULL)\n\n\n\n\n\n\n\n\n\n\n\nTo show the correlation coefficient of each pair of variables instead of a scatter plot, panel.cor function will be used. This will also show higher correlations in a larger font.\nDon’t worry about the details for now-just type this code into your R session or script. Let’s have more fun way to display the correlation matrix.\n\npanel.cor &lt;- function(x, y, digits=2, prefix=\"\", cex.cor, ...) {\nusr &lt;- par(\"usr\")\non.exit(par(usr))\npar(usr = c(0, 1, 0, 1))\nr &lt;- abs(cor(x, y, use=\"complete.obs\"))\ntxt &lt;- format(c(r, 0.123456789), digits=digits)[1]\ntxt &lt;- paste(prefix, txt, sep=\"\")\nif(missing(cex.cor)) cex.cor &lt;- 0.8/strwidth(txt)\ntext(0.5, 0.5, txt, cex = cex.cor * (1 + r) / 2)\n}\n\npairs(wine[,2:12], \n      upper.panel = panel.cor)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09(e)/Hands-on_Ex09(e).html#visualising-correlation-matrix-ggcormat",
    "href": "Hands-on_Ex/Hands-on_Ex09(e)/Hands-on_Ex09(e).html#visualising-correlation-matrix-ggcormat",
    "title": "Hands-on_Ex09(e)",
    "section": "",
    "text": "One of the major limitation of the correlation matrix is that the scatter plots appear very cluttered when the number of observations is relatively large (i.e. more than 500 observations). To over come this problem, Corrgram data visualisation technique suggested by D. J. Murdoch and E. D. Chow (1996) and Friendly, M (2002) and will be used.\nThe are at least three R packages provide function to plot corrgram, they are:\n\ncorrgram\nellipse\ncorrplot\n\nOn top that, some R package like ggstatsplot package also provides functions for building corrgram.\nIn this section, you will learn how to visualising correlation matrix by using ggcorrmat() of ggstatsplotpackage.\n\n\nOn of the advantage of using ggcorrmat() over many other methods to visualise a correlation matrix is it’s ability to provide a comprehensive and yet professional statistical report as shown in the figure below.\n\nggstatsplot::ggcorrmat(\n  data = wine, \n  cor.vars = 1:11)\n\n\n\n\n\n\n\n\n\nggstatsplot::ggcorrmat(\n  data = wine, \n  cor.vars = 1:11,\n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10),\n  title    = \"Correlogram for wine dataset\",\n  subtitle = \"Four pairs are no significant at p &lt; 0.05\"\n)\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\ncor.vars argument is used to compute the correlation matrix needed to build the corrgram.\nggcorrplot.args argument provide additional (mostly aesthetic) arguments that will be passed to ggcorrplot::ggcorrplot function. The list should avoid any of the following arguments since they are already internally being used: corr, method, p.mat, sig.level, ggtheme, colors, lab, pch, legend.title, digits.\n\nThe sample sub-code chunk can be used to control specific component of the plot such as the font size of the x-axis, y-axis, and the statistical report.\n\nggplot.component = list(\n    theme(text=element_text(size=5),\n      axis.text.x = element_text(size = 8),\n      axis.text.y = element_text(size = 8)))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09(e)/Hands-on_Ex09(e).html#building-multiple-plots",
    "href": "Hands-on_Ex/Hands-on_Ex09(e)/Hands-on_Ex09(e).html#building-multiple-plots",
    "title": "Hands-on_Ex09(e)",
    "section": "",
    "text": "Since ggstasplot is an extension of ggplot2, it also supports faceting. However the feature is not available in ggcorrmat() but in the grouped_ggcorrmat() of ggstatsplot.\n\ngrouped_ggcorrmat(\n  data = wine,\n  cor.vars = 1:11,\n  grouping.var = type,\n  type = \"robust\",\n  p.adjust.method = \"holm\",\n  plotgrid.args = list(ncol = 2),\n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10),\n  annotation.args = list(\n    tag_levels = \"a\",\n    title = \"Correlogram for wine dataset\",\n    subtitle = \"The measures are: alcohol, sulphates, fixed acidity, citric acid, chlorides, residual sugar, density, free sulfur dioxide and volatile acidity\",\n    caption = \"Dataset: UCI Machine Learning Repository\"\n  )\n)\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\nto build a facet plot, the only argument needed is grouping.var.\nBehind group_ggcorrmat(), patchwork package is used to create the multiplot. plotgrid.argsargument provides a list of additional arguments passed to patchwork::wrap_plots, except for guides argument which is already separately specified earlier.\nLikewise, annotation.args argument is calling plot annotation arguments of patchwork package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09(e)/Hands-on_Ex09(e).html#visualising-correlation-matrix-using-corrplot-package",
    "href": "Hands-on_Ex/Hands-on_Ex09(e)/Hands-on_Ex09(e).html#visualising-correlation-matrix-using-corrplot-package",
    "title": "Hands-on_Ex09(e)",
    "section": "",
    "text": "In this hands-on exercise, we will focus on corrplot. However, you are encouraged to explore the other two packages too.\nBefore getting started, you are required to read An Introduction to corrplot Package in order to gain basic understanding of corrplot package.\n\n\nBefore we can plot a corrgram using corrplot(), we need to compute the correlation matrix of wine data frame.\nIn the code chunk below, cor() of R Stats is used to compute the correlation matrix of wine data frame.\n\nwine.cor &lt;- cor(wine[, 1:11])\n\nNext, corrplot() is used to plot the corrgram by using all the default setting as shown in the code chunk below.\n\ncorrplot(wine.cor)\n\n\n\n\n\n\n\n\nNotice that the default visual object used to plot the corrgram is circle. The default layout of the corrgram is a symmetric matrix. The default colour scheme is diverging blue-red. Blue colours are used to represent pair variables with positive correlation coefficients and red colours are used to represent pair variables with negative correlation coefficients. The intensity of the colour or also know as saturation is used to represent the strength of the correlation coefficient. Darker colours indicate relatively stronger linear relationship between the paired variables. On the other hand, lighter colours indicates relatively weaker linear relationship.\n\n\n\nIn corrplot package, there are seven visual geometrics (parameter method) can be used to encode the attribute values. They are: circle, square, ellipse, number, shade, color and pie. The default is circle. As shown in the previous section, the default visual geometric of corrplot matrix is circle. However, this default setting can be changed by using the method argument as shown in the code chunk below.\n\ncorrplot(wine.cor, \n         method = \"ellipse\") \n\n\n\n\n\n\n\n\nFeel free to change the method argument to other supported visual geometrics.\n\n\n\ncorrplor() supports three layout types, namely: “full”, “upper” or “lower”. The default is “full” which display full matrix. The default setting can be changed by using the type argument of corrplot().\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         type=\"lower\")\n\n\n\n\n\n\n\n\nThe default layout of the corrgram can be further customised. For example, arguments diag and tl.col are used to turn off the diagonal cells and to change the axis text label colour to black colour respectively as shown in the code chunk and figure below.\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         type=\"lower\",\n         diag = FALSE,\n         tl.col = \"black\")\n\n\n\n\n\n\n\n\nPlease feel free to experiment with other layout design argument such as tl.pos, tl.cex, tl.offset, cl.pos, cl.cex and cl.offset, just to mention a few of them.\n\n\n\nWith corrplot package, it is possible to design corrgram with mixed visual matrix of one half and numerical matrix on the other half. In order to create a coorgram with mixed layout, the corrplot.mixed(), a wrapped function for mixed visualisation style will be used.\nFigure below shows a mixed layout corrgram plotted using wine quality data.\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\n\n\n\n\nThe code chunk used to plot the corrgram are shown below.\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\n\n\n\n\nNotice that argument lower and upper are used to define the visualisation method used. In this case ellipse is used to map the lower half of the corrgram and numerical matrix (i.e. number) is used to map the upper half of the corrgram. The argument tl.pos, on the other, is used to specify the placement of the axis label. Lastly, the diag argument is used to specify the glyph on the principal diagonal of the corrgram.\n\n\n\nIn statistical analysis, we are also interested to know which pair of variables their correlation coefficients are statistically significant.\nFigure below shows a corrgram combined with the significant test. The corrgram reveals that not all correlation pairs are statistically significant. For example the correlation between total sulfur dioxide and free surfur dioxide is statistically significant at significant level of 0.1 but not the pair between total sulfur dioxide and citric acid.\nWith corrplot package, we can use the cor.mtest() to compute the p-values and confidence interval for each pair of variables.\n\nwine.sig = cor.mtest(wine.cor, conf.level= .95)\n\nWe can then use the p.mat argument of corrplot function as shown in the code chunk below.\n\ncorrplot(wine.cor,\n         method = \"number\",\n         type = \"lower\",\n         diag = FALSE,\n         tl.col = \"black\",\n         tl.srt = 45,\n         p.mat = wine.sig$p,\n         sig.level = .05)\n\n\n\n\n\n\n\n\n\n\n\nMatrix reorder is very important for mining the hiden structure and pattern in a corrgram. By default, the order of attributes of a corrgram is sorted according to the correlation matrix (i.e. “original”). The default setting can be over-write by using the order argument of corrplot(). Currently, corrplot package support four sorting methods, they are:\n\n“AOE” is for the angular order of the eigenvectors. See Michael Friendly (2002) for details.\n“FPC” for the first principal component order.\n“hclust” for hierarchical clustering order, and “hclust.method” for the agglomeration method to be used.\n\n“hclust.method” should be one of “ward”, “single”, “complete”, “average”, “mcquitty”, “median” or “centroid”.\n\n“alphabet” for alphabetical order.\n\n“AOE”, “FPC”, “hclust”, “alphabet”. More algorithms can be found in seriation package.\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               order=\"AOE\",\n               tl.col = \"black\")\n\n\n\n\n\n\n\n\n\n\n\nIf using hclust, corrplot() can draw rectangles around the corrgram based on the results of hierarchical clustering.\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         tl.pos = \"lt\",\n         tl.col = \"black\",\n         order=\"hclust\",\n         hclust.method = \"ward.D\",\n         addrect = 3)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09(e)/Hands-on_Ex09(e).html#r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex09(e)/Hands-on_Ex09(e).html#r-packages",
    "title": "Hands-on_Ex09(e)",
    "section": "7.1 R packages",
    "text": "7.1 R packages\n\nggcormat() of ggstatsplot package\nggscatmat and ggpairs of GGally.\ncorrplot. A graphical display of a correlation matrix or general matrix. It also contains some algorithms to do matrix reordering. In addition, corrplot is good at details, including choosing color, text labels, color labels, layout, etc.\ncorrgram calculates correlation of variables and displays the results graphically. Included panel functions can display points, shading, ellipses, and correlation values with confidence intervals."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#installing-and-loading-the-required-library",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#installing-and-loading-the-required-library",
    "title": "Hands-on Exercise 2: Beyond ggplot2 Fundamentals",
    "section": "1 Installing and Loading the required library",
    "text": "1 Installing and Loading the required library\n\n1.1 check the required packages: ggrepel, ggthemes, hrbrthemes, patchwork, ggplot2\n\n\nClick to view code\npacman::p_load(ggrepel, patchwork, ggthemes,\n               hrbrthemes, tidyverse, ggplot2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#importing-data",
    "title": "Hands-on Exercise 2: Beyond ggplot2 Fundamentals",
    "section": "2 Importing data",
    "text": "2 Importing data\n\n\nClick to view code\nexam_data &lt;- read.csv(\"data/Exam_data.csv\")\n\n\n\nreader is one of the tidyverse package"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-annotationggrepel",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-annotationggrepel",
    "title": "Hands-on Exercise 2: Beyond ggplot2 Fundamentals",
    "section": "3 Beyond ggplot2 Annotation:ggrepel",
    "text": "3 Beyond ggplot2 Annotation:ggrepel\n\n\nClick to view code\nggplot(data = exam_data,\n       aes(x = MATHS, y = ENGLISH)) +\n  geom_point() +\n  geom_smooth(method = lm, size = 0.5) +\n  geom_label(aes(label = ID),\n             hjust = 0.5,\n             vjust = -.5) +\n  coord_cartesian(xlim = c(0,100),\n                  ylim = c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n\n\n\n\n\n\n\n\n\norignal plot\n\n\nClick to view code\nggplot(data = exam_data,\n       aes(x = MATHS, y = ENGLISH)) +\n  geom_point() +\n  geom_smooth(method = lm, size = 0.5) +\n  geom_label_repel(aes(label = ID),\n             hjust = 0.5,\n             vjust = -.5) +\n  coord_cartesian(xlim = c(0,100),\n                  ylim = c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n\n\n\n\n\n\n\n\n\n\nusing ggrepel"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-themes",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-themes",
    "title": "Hands-on Exercise 2: Beyond ggplot2 Fundamentals",
    "section": "4 Beyond ggplot2 Themes",
    "text": "4 Beyond ggplot2 Themes\n\n4.1 Built_in themes\n\neight built_in themes: theme_gray(), theme_bw(), theme_classic(), theme_dark(), theme_light(), theme_linedraw(), theme_minimal(), and theme_void()\n\n\n4.1.1 theme_gray\n\n\nClick to view code\nggplot(data = exam_data, aes(x = MATHS)) +\n  geom_histogram(bins = 20, boundary = 100, color = \"grey25\",\n                 fill = \"grey90\") +\n  theme_gray() +\n  ggtitle(\"Distribution of Maths scores\")\n\n\n\n\n\n\n\n\n\n\n\n4.1.2 theme_bw\n\n\nClick to view code\nggplot(data = exam_data, aes(x = MATHS)) +\n  geom_histogram(bins = 20, boundary = 100, color = \"grey25\",\n                 fill = \"grey90\") +\n  theme_bw() +\n  ggtitle(\"Distribution of Maths scores\")\n\n\n\n\n\n\n\n\n\n\n\n4.1.3 theme_classic\n\n\nClick to view code\nggplot(data = exam_data, aes(x = MATHS)) +\n  geom_histogram(bins = 20, boundary = 100, color = \"grey25\",\n                 fill = \"grey90\") +\n  theme_classic() +\n  ggtitle(\"Distribution of Maths scores\")\n\n\n\n\n\n\n\n\n\n\n\n4.1.4 theme_dark\n\n\nClick to view code\nggplot(data = exam_data, aes(x = MATHS)) +\n  geom_histogram(bins = 20, boundary = 100, color = \"grey25\",\n                 fill = \"grey90\") +\n  theme_dark() +\n  ggtitle(\"Distribution of Maths scores\")\n\n\n\n\n\n\n\n\n\n\n\n4.1.5 theme_light\n\n\nClick to view code\nggplot(data = exam_data, aes(x = MATHS)) +\n  geom_histogram(bins = 20, boundary = 100, color = \"grey25\",\n                 fill = \"grey90\") +\n  theme_light() +\n  ggtitle(\"Distribution of Maths scores\")\n\n\n\n\n\n\n\n\n\n\n\n4.1.6 theme_linedraw\n\n\nClick to view code\nggplot(data = exam_data, aes(x = MATHS)) +\n  geom_histogram(bins = 20, boundary = 100, color = \"grey25\",\n                 fill = \"grey90\") +\n  theme_linedraw() +\n  ggtitle(\"Distribution of Maths scores\")\n\n\n\n\n\n\n\n\n\n\n\n4.1.7 theme_minimal\n\n\nClick to view code\nggplot(data = exam_data, aes(x = MATHS)) +\n  geom_histogram(bins = 20, boundary = 100, color = \"grey25\",\n                 fill = \"grey90\") +\n  theme_minimal() +\n  ggtitle(\"Distribution of Maths scores\")\n\n\n\n\n\n\n\n\n\n\n\n4.1.8 theme_void\n\n\nClick to view code\nggplot(data = exam_data, aes(x = MATHS)) +\n  geom_histogram(bins = 20, boundary = 100, color = \"grey25\",\n                 fill = \"grey90\") +\n  theme_void() +\n  ggtitle(\"Distribution of Maths scores\")\n\n\n\n\n\n\n\n\n\n\n\n\n4.2 Working with ggtheme package\n\n4.2.1 Economist theme\n\n\nClick to view code\nggplot(data = exam_data, aes(x = MATHS)) +\n  geom_histogram(bins = 20, boundary = 100, color = \"grey25\",\n                 fill = \"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_economist()\n\n\n\n\n\n\n\n\n\n\n\n\n4.3 Working with hrbyhems package\n\n4.3.1 hybrthmes (where lables are placed)\n\n\nClick to view code\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum()\n\n\n\n\n\n\n\n\n\n\n\n4.3.2 hybrthmes (add details)\n\n\nClick to view code\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum(axis_title_size = 18,\n              base_size = 15,\n              grid = \"Y\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-single-graph",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-single-graph",
    "title": "Hands-on Exercise 2: Beyond ggplot2 Fundamentals",
    "section": "5 Beyond Single Graph",
    "text": "5 Beyond Single Graph\n\n5.1 p1\n\n\nClick to view code\np1 &lt;- ggplot(data = exam_data,\n             aes(x = MATHS)) +\n  geom_histogram(bins = 20,\n                 boundary = 100,\n                 color = \"grey25\",\n                 fill = \"grey90\") +\n  coord_cartesian(xlim = c(0,100)) +\n  ggtitle(\"Distribution of Maths scores\")\n\n\n\n\n5.2 p2\n\n\nClick to view code\np2 &lt;- ggplot(data = exam_data,\n             aes(x = MATHS)) +\n  geom_histogram(bins = 20, boundary = 100,\n                 color = \"grey25\", fill = \"grey90\") +\n  coord_cartesian(xlim = c(0,100)) +\n  ggtitle(\"Distribution of Maths scores\")\n\n\n\n\n5.3 p3\n\n\nClick to view code\np3 &lt;- ggplot(data = exam_data,\n             aes(x = MATHS, y = ENGLISH)) +\n  geom_point() +\n  geom_smooth(method = lm, \n              size = .5) +\n  coord_cartesian(xlim = c(0,100), ylim = c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n\n\n\n5.4 show\n\n\nClick to view code\np1\n\n\n\n\n\n\n\n\n\nClick to view code\np2\n\n\n\n\n\n\n\n\n\nClick to view code\np3"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#creating-composite-graphics-pathwork-mehods",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#creating-composite-graphics-pathwork-mehods",
    "title": "Hands-on Exercise 2: Beyond ggplot2 Fundamentals",
    "section": "6 Creating Composite Graphics: pathwork mehods",
    "text": "6 Creating Composite Graphics: pathwork mehods\n\n6.1 Combining two ggplot2 graphs\n\n\nClick to view code\np1 + p2\n\n\n\n\n\n\n\n\n\n\n\n6.2 Combining three ggplot2 graphs\n\n\nClick to view code\n(p1/p2)|p3\n\n\n\n\n\n\n\n\n\n\n\n6.3 Creating a composite figure with tag\n\n\nClick to view code\n(p1/p2)|p3 +\n  plot_annotation(tag_levels = \"I\")\n\n\n\n\n\n\n\n\n\n\n\n6.4 Creating figure with insert\n\n\nClick to view code\np3 + inset_element(p2,\n                   left = 0.02,\n                   bottom = 0.7,\n                   right = 0.5,\n                   top = 1)\n\n\n\n\n\n\n\n\n\n\n\n6.5 Creating acompostie figure by using patchwork and ggtheme\n\n\nClick to view code\npatchwork &lt;- (p1/p2)|p3 \npatchwork & theme_economist()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "title": "Hands-on_Exercise 5: Visualising and Analysing Text Data with R: tidytext methods",
    "section": "",
    "text": "In this hands-on exercise, we will learn how to visualise and analyse text data using R.\nBy the end of this hands-on exercise, we will be able to:\n\nunderstand tidytext framework for processing, analysing and visualising text data,\nwrite function for importing multiple files into R,\ncombine multiple files into a single data frame,\nclean and wrangle text data by using tidyverse approach,\nvisualise words with Word Cloud,\ncompute term frequency–inverse document frequency (TF-IDF) using tidytext method, and\nvisualising texts and terms relationship."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#learning-outcome",
    "title": "Hands-on_Exercise 5: Visualising and Analysing Text Data with R: tidytext methods",
    "section": "",
    "text": "In this hands-on exercise, we will learn how to visualise and analyse text data using R.\nBy the end of this hands-on exercise, we will be able to:\n\nunderstand tidytext framework for processing, analysing and visualising text data,\nwrite function for importing multiple files into R,\ncombine multiple files into a single data frame,\nclean and wrangle text data by using tidyverse approach,\nvisualise words with Word Cloud,\ncompute term frequency–inverse document frequency (TF-IDF) using tidytext method, and\nvisualising texts and terms relationship."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#getting-started",
    "title": "Hands-on_Exercise 5: Visualising and Analysing Text Data with R: tidytext methods",
    "section": "2 Getting Started",
    "text": "2 Getting Started\n\n2.1 Installing and launching R packages\nIn this hands-on exercise, the following R packages for handling, processing, wrangling, analysing and visualising text data will be used:\n\ntidytext, tidyverse (mainly readr, purrr, stringr, ggplot2)\nwidyr,\nwordcloud and ggwordcloud,\ntextplot (required igraph, tidygraph and ggraph, )\nDT,\nlubridate and hms.\n\nThe code chunk:\n\n\nClick to view code\npacman::p_load(tidytext, widyr, wordcloud, DT, ggwordcloud, textplot, lubridate, hms, tidyverse, tidygraph, ggraph, igraph)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#importing-multiple-text-files-from-multiple-folders",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#importing-multiple-text-files-from-multiple-folders",
    "title": "Hands-on_Exercise 5: Visualising and Analysing Text Data with R: tidytext methods",
    "section": "3 Importing Multiple Text Files from Multiple Folders",
    "text": "3 Importing Multiple Text Files from Multiple Folders\n\n3.1 Creating a folder list\n\n\nClick to view code\nnews20 &lt;- \"data/20news\"\n\n\n\n\n3.2 Define a function to read all files from a folder into a data frame\n\n\nClick to view code\nread_folder &lt;- function(infolder) {\n  tibble(file = dir(infolder, \n                    full.names = TRUE)) %&gt;%\n    mutate(text = map(file, \n                      read_lines)) %&gt;%\n    transmute(id = basename(file), \n              text) %&gt;%\n    unnest(text)\n}"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#importing-multiple-text-files-from-multiple-folders-1",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#importing-multiple-text-files-from-multiple-folders-1",
    "title": "Hands-on_Exercise 5: Visualising and Analysing Text Data with R: tidytext methods",
    "section": "4 Importing Multiple Text Files from Multiple Folders",
    "text": "4 Importing Multiple Text Files from Multiple Folders\n\n4.1 Reading in all the messages from the 20news folder\n\n\nClick to view code\nraw_text &lt;- tibble(folder = \n                     dir(news20, \n                         full.names = TRUE)) %&gt;%\n  mutate(folder_out = map(folder, \n                          read_folder)) %&gt;%\n  unnest(cols = c(folder_out)) %&gt;%\n  transmute(newsgroup = basename(folder), \n            id, text)\nwrite_rds(raw_text, \"data/news20.rds\")\n\n\n\nread_lines()map()unnest()mutate()transmute()read_rds()\n\n\nread_lines() of readr package is used to read up to n_max lines from a file.\n\n\nmap() of purrr package is used to transform their input by applying a function to each element of a list and returning an object of the same length as the input.\n\n\nunnest() of dplyr package is used to flatten a list-column of data frames back out into regular columns.\n\n\nmutate() of dplyr is used to add new variables and preserves existing ones;\n\n\ntransmute() of dplyr is used to add new variables and drops existing ones.\n\n\nread_rds() is used to save the extracted and combined data frame as rds file for future use.\n\n\n\n5 Initial EDA\nFigure below shows the frequency of messages by newsgroup.\n\n\n\n\n\n\n\n\n\nThe code chunk:\n\n\nClick to view code\nraw_text &lt;- read_rds(\"data/news20.rds\")\nraw_text %&gt;%\n  group_by(newsgroup) %&gt;%\n  summarize(messages = n_distinct(id)) %&gt;%\n  ggplot(aes(messages, newsgroup)) +\n  geom_col(fill = \"lightblue\") +\n  labs(y = NULL)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#introducing-tidytext",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#introducing-tidytext",
    "title": "Hands-on_Exercise 5: Visualising and Analysing Text Data with R: tidytext methods",
    "section": "6 Introducing tidytext",
    "text": "6 Introducing tidytext\n\nUsing tidy data principles in processing, analysing and visualising text data.\nMuch of the infrastructure needed for text mining with tidy data frames already exists in packages like ‘dplyr’, ‘broom’, ‘tidyr’, and ‘ggplot2’.\n\nFigure below shows the workflow using tidytext approach for processing and visualising text data.\n\n\n6.1 Removing header and automated email signitures\nNotice that each message has some structure and extra text that we don’t want to include in our analysis. For example, every message has a header, containing field such as “from:” or “in_reply_to:” that describe the message. Some also have automated email signatures, which occur after a line like “–”.\n\n\nClick to view code\ncleaned_text &lt;- raw_text %&gt;%\n  group_by(newsgroup, id) %&gt;%\n  filter(cumsum(text == \"\") &gt; 0,\n         cumsum(str_detect(\n           text, \"^--\")) == 0) %&gt;%\n  ungroup()\n\n\n\n\n\n\n\n\nThings to learn from the code chunk:\n\n\n\n\ncumsum() of base R is used to return a vector whose elements are the cumulative sums of the elements of the argument.\nstr_detect() from stringr is used to detect the presence or absence of a pattern in a string.\n\n\n\n\n\n6.2 Removing lines with nested text representing quotes from other users.\nIn this code chunk below, regular expressions are used to remove with nested text representing quotes from other users.\n\n\nClick to view code\ncleaned_text &lt;- cleaned_text %&gt;%\n  filter(str_detect(text, \"^[^&gt;]+[A-Za-z\\\\d]\")\n         | text == \"\",\n         !str_detect(text, \n                     \"writes(:|\\\\.\\\\.\\\\.)$\"),\n         !str_detect(text, \n                     \"^In article &lt;\")\n  )\n\n\n\nstr_detect()filter()\n\n\nstr_detect() from stringr is used to detect the presence or absence of a pattern in a string.\n\n\nfilter() of dplyr package is used to subset a data frame, retaining all rows that satisfy the specified conditions.\n\n\n\n\n\n6.3 Text Data Processing\nIn this code chunk below, unnest_tokens() of tidytext package is used to split the dataset into tokens, while stop_words() is used to remove stop-words.\n\n\nClick to view code\nusenet_words &lt;- cleaned_text %&gt;%\n  unnest_tokens(word, text) %&gt;%\n  filter(str_detect(word, \"[a-z']$\"),\n         !word %in% stop_words$word)\n\n\nNow that we’ve removed the headers, signatures, and formatting, we can start exploring common words. For starters, we could find the most common words in the entire dataset, or within particular newsgroups.\n\n\nClick to view code\nusenet_words %&gt;%\n  count(word, sort = TRUE)\n\n\n# A tibble: 5,542 × 2\n   word           n\n   &lt;chr&gt;      &lt;int&gt;\n 1 people        57\n 2 time          50\n 3 jesus         47\n 4 god           44\n 5 message       40\n 6 br            27\n 7 bible         23\n 8 drive         23\n 9 homosexual    23\n10 read          22\n# ℹ 5,532 more rows\n\n\nInstead of counting individual word, you can also count words within by newsgroup by using the code chunk below.\n\n\nClick to view code\nwords_by_newsgroup &lt;- usenet_words %&gt;%\n  count(newsgroup, word, sort = TRUE) %&gt;%\n  ungroup()\n\n\n\n\n6.4 Visualising Words in newsgroups\nIn this code chunk below, wordcloud() of wordcloud package is used to plot a static wordcloud.\n\n\nClick to view code\nwordcloud(words_by_newsgroup$word,\n          words_by_newsgroup$n,\n          max.words = 300)\n\n\n\n\n\n\n\n\n\n\n\n6.5 Visualising Words in newsgroups The wordcloud below is plotted by using ggwordcloud package.\nThe code chunk used:\n\n\nClick to view code\nset.seed(1234)\n\nwords_by_newsgroup %&gt;%\n  filter(n &gt; 0) %&gt;%\nggplot(aes(label = word,\n           size = n)) +\n  geom_text_wordcloud() +\n  theme_minimal() +\n  facet_wrap(~newsgroup)\n\n\n\n\n\n\n\n\n\n7 Basic Concept of TF-IDF\n\ntf–idf, short for term frequency–inverse document frequency, is a numerical statistic that is intended to reflect how important a word is to a document in a collection of corpus.\n\n\n\n\n7.1 Computing tf-idf within newsgroups\nThe code chunk below uses bind_tf_idf() of tidytext to compute and bind the term frequency, inverse document frequency and ti-idf of a tidy text dataset to the dataset.\n\n\nClick to view code\ntf_idf &lt;- words_by_newsgroup %&gt;%\n  bind_tf_idf(word, newsgroup, n) %&gt;%\n  arrange(desc(tf_idf))\n\n\n\n\n7.2 Visualising tf-idf as interactive table\nTable below is an interactive table created by using datatable().\n\n\n7.3 Visualising tf-idf as interactive table\nThe code chunk below uses datatable() of DT package to create a html table that allows pagination of rows and columns.\n\n\nClick to view code\nDT::datatable(tf_idf, filter = 'top') %&gt;% \n  formatRound(columns = c('tf', 'idf', \n                          'tf_idf'), \n              digits = 3) %&gt;%\n  formatStyle(0, \n              target = 'row', \n              lineHeight='25%')\n\n\n\n\n\n\n\nfilter()formatRound()formatStyle\n\n\nfilter() argument is used to turn control the filter UI.\n\n\nformatRound() is used to customise the values format. The argument digits define the number of decimal places.\n\n\nformatStyle() is used to customise the output table. In this example, the arguments targetand lineHeight are used to reduce the line height by 25%.\n\n\n\nTo learn more about customising DT’s table, visit this link.\n\n\n7.4 Visualising tf-idf within newsgroups\nFacet bar charts technique is used to visualise the tf-idf values of science related newsgroup.\n\nThe code chunk used to prepare the plot.\n\n\nClick to view code\ntf_idf %&gt;%\n  filter(str_detect(newsgroup, \"^sci\\\\.\")) %&gt;%\n  group_by(newsgroup) %&gt;%\n  slice_max(tf_idf, \n            n = 12) %&gt;%\n  ungroup() %&gt;%\n  mutate(word = reorder(word, \n                        tf_idf)) %&gt;%\n  ggplot(aes(tf_idf, \n             word, \n             fill = newsgroup)) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(~ newsgroup, \n             scales = \"free\") +\n  labs(x = \"tf-idf\", \n       y = NULL)\n\n\n\n\n\n\n\n\n\n\n\n7.5 Counting and correlating pairs of words with the widyr package\n\nTo count the number of times that two words appear within the same document, or to see how correlated they are.\nMost operations for finding pairwise counts or correlations need to turn the data into a wide matrix first.\nwidyr package first ‘casts’ a tidy dataset into a wide matrix, performs an operation such as a correlation on it, then re-tidies the result.\n\n\nIn this code chunk below, pairwise_cor() of widyr package is used to compute the correlation between newsgroup based on the common words found.\n\n\n7.6 Visualising correlation as a network\nNow, we can visualise the relationship between newgroups in network graph as shown below.\nset.seed(2017)\nnewsgroup_cors %&gt;% filter(correlation &gt; .025) %&gt;% graph_from_data_frame() %&gt;% ggraph(layout = “fr”) + geom_edge_link(aes(alpha = correlation, width = correlation)) + geom_node_point(size = 6, color = “lightblue”) + geom_node_text(aes(label = name), color = “red”, repel = TRUE) + theme_void()\n\n\n7.7 Bigram\nIn this code chunk below, a bigram data frame is created by using unnest_tokens() of tidytext.\n\n\nClick to view code\nbigrams &lt;- cleaned_text %&gt;%\n  unnest_tokens(bigram, \n                text, \n                token = \"ngrams\", \n                n = 2)\nbigrams\n\n\n# A tibble: 28,824 × 3\n   newsgroup   id    bigram    \n   &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;     \n 1 alt.atheism 54256 &lt;NA&gt;      \n 2 alt.atheism 54256 &lt;NA&gt;      \n 3 alt.atheism 54256 as i      \n 4 alt.atheism 54256 i don't   \n 5 alt.atheism 54256 don't know\n 6 alt.atheism 54256 know this \n 7 alt.atheism 54256 this book \n 8 alt.atheism 54256 book i    \n 9 alt.atheism 54256 i will    \n10 alt.atheism 54256 will use  \n# ℹ 28,814 more rows\n\n\n\n\n7.8 Counting bigrams\nThe code chunk is used to count and sort the bigram data frame ascendingly.\n\n\nClick to view code\nbigrams_count &lt;- bigrams %&gt;%\n  filter(bigram != 'NA') %&gt;%\n  count(bigram, sort = TRUE)\nbigrams_count\n\n\n# A tibble: 19,885 × 2\n   bigram       n\n   &lt;chr&gt;    &lt;int&gt;\n 1 of the     169\n 2 in the     113\n 3 to the      74\n 4 to be       59\n 5 for the     52\n 6 i have      48\n 7 that the    47\n 8 if you      40\n 9 on the      39\n10 it is       38\n# ℹ 19,875 more rows\n\n\n\n\n7.9 Cleaning bigram\nThe code chunk below is used to seperate the bigram into two words.\n\n\nClick to view code\nbigrams_separated &lt;- bigrams %&gt;%\n  filter(bigram != 'NA') %&gt;%\n  separate(bigram, c(\"word1\", \"word2\"), \n           sep = \" \")\n\nbigrams_filtered &lt;- bigrams_separated %&gt;%\n  filter(!word1 %in% stop_words$word) %&gt;%\n  filter(!word2 %in% stop_words$word)\nbigrams_filtered\n\n\n# A tibble: 4,604 × 4\n   newsgroup   id    word1        word2        \n   &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;        &lt;chr&gt;        \n 1 alt.atheism 54256 defines      god          \n 2 alt.atheism 54256 term         preclues     \n 3 alt.atheism 54256 science      ideas        \n 4 alt.atheism 54256 ideas        drawn        \n 5 alt.atheism 54256 supernatural precludes    \n 6 alt.atheism 54256 scientific   assertions   \n 7 alt.atheism 54256 religious    dogma        \n 8 alt.atheism 54256 religion     involves     \n 9 alt.atheism 54256 involves     circumventing\n10 alt.atheism 54256 gain         absolute     \n# ℹ 4,594 more rows\n\n\n\n\n7.10 Counting the bigram again\n\n\nClick to view code\nbigram_counts &lt;- bigrams_filtered %&gt;% \n  count(word1, word2, sort = TRUE)\n\n\n\n\n7.11 Create a network graph from bigram data frame\nIn the code chunk below, a network graph is created by using graph_from_data_frame()of igraph package\n\n\nClick to view code\nbigram_graph &lt;- bigram_counts %&gt;%\n  filter(n &gt; 3) %&gt;%\n  graph_from_data_frame()\nbigram_graph\n\n\nIGRAPH cc2da52 DN-- 40 24 -- \n+ attr: name (v/c), n (e/n)\n+ edges from cc2da52 (vertex names):\n [1] 1          -&gt;2           1          -&gt;3           static     -&gt;void       \n [4] time       -&gt;pad         1          -&gt;4           infield    -&gt;fly        \n [7] mat        -&gt;28          vv         -&gt;vv          1          -&gt;5          \n[10] cock       -&gt;crow        noticeshell-&gt;widget      27         -&gt;1993       \n[13] 3          -&gt;4           child      -&gt;molestation cock       -&gt;crew       \n[16] gun        -&gt;violence    heat       -&gt;sink        homosexual -&gt;male       \n[19] homosexual -&gt;women       include    -&gt;xol         mary       -&gt;magdalene  \n[22] read       -&gt;write       rev        -&gt;20          tt         -&gt;ee         \n\n\n\n\n7.12 Visualizing a network of bigrams with ggraph\nIn this code chunk below, ggraph package is used to plot the bigram.\n\n\nClick to view code\nset.seed(1234)\n\nggraph(bigram_graph, layout = \"fr\") +\n  geom_edge_link() +\n  geom_node_point() +\n  geom_node_text(aes(label = name), \n                 vjust = 1, \n                 hjust = 1)\n\n\n\n\n\n\n\n\n\n\n\n7.13 Revised version\n\n\nClick to view code\nset.seed(1234)\n\na &lt;- grid::arrow(type = \"closed\", \n                 length = unit(.15,\n                               \"inches\"))\n\nggraph(bigram_graph, \n       layout = \"fr\") +\n  geom_edge_link(aes(edge_alpha = n), \n                 show.legend = FALSE,\n                 arrow = a, \n                 end_cap = circle(.07,\n                                  'inches')) +\n  geom_node_point(color = \"lightblue\", \n                  size = 5) +\n  geom_node_text(aes(label = name), \n                 vjust = 1, \n                 hjust = 1) +\n  theme_void()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#references",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#references",
    "title": "Hands-on_Exercise 5: Visualising and Analysing Text Data with R: tidytext methods",
    "section": "8 References",
    "text": "8 References\n\n8.0.1 widyr\n\nReference guide\n\nwidyr: Widen, process, and re-tidy a dataset\nUnited Nations Voting Correlations"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08(a)/Hands-on_Ex08(a).html",
    "href": "Hands-on_Ex/Hands-on_Ex08(a)/Hands-on_Ex08(a).html",
    "title": "Hands-on_Ex08(a)",
    "section": "",
    "text": "Choropleth mapping involves the symbolisation of enumeration units, such as countries, provinces, states, counties or census units, using area patterns or graduated colors. For example, a social scientist may need to use a choropleth map to portray the spatial distribution of aged population of Singapore by Master Plan 2014 Subzone Boundary.\nIn this chapter, you will learn how to plot functional and truthful choropleth maps by using an R package called tmap package.\n\n\n\nIn this hands-on exercise, the key R package use is tmap package in R. Beside tmappackage, four other R packages will be used. They are:\n\nreadr for importing delimited text file,\ntidyr for tidying data,\ndplyr for wrangling data and\nsf for handling geospatial data.\n\nAmong the four packages, readr, tidyr and dplyr are part of tidyverse package.\nThe code chunk below will be used to install and load these packages in RStudio.\n\npacman::p_load(sf, tmap, tidyverse)\n\n\n\n\n\n\nTwo data set will be used to create the choropleth map. They are:\n\nMaster Plan 2014 Subzone Boundary (Web) (i.e. MP14_SUBZONE_WEB_PL) in ESRI shapefile format. It can be downloaded at data.gov.sg This is a geospatial data. It consists of the geographical boundary of Singapore at the planning subzone level. The data is based on URA Master Plan 2014.\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2011-2020 in csv format (i.e. respopagesextod2011to2020.csv). This is an aspatial data fie. It can be downloaded at Department of Statistics, Singapore Although it does not contain any coordinates values, but it’s PA and SZ fields can be used as unique identifiers to geocode to MP14_SUBZONE_WEB_PL shapefile.\n\n\n\n\nThe code chunk below uses the st_read() function of sf package to import MP14_SUBZONE_WEB_PL shapefile into R as a simple feature data frame called mpsz.\n\nmpsz &lt;- st_read(dsn = \"111/222\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Applications/SMU/S2/ISSS608 Visual Analytics and Application/jiaxun.zou/ISSS608-VAA/Hands-on_Ex/Hands-on_Ex08(a)/111/222' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nYou can examine the content of mpsz by using the code chunk below.\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\nNotice that only the first ten records will be displayed.\n\n\n\nNext, we will import respopagsex2011to2020.csv file into RStudio and save the file into an R dataframe called popagsex.\nThe task will be performed by using read_csv() function of readr package as shown in the code chunk below.\n\npopdata &lt;- read_csv(\"111/aspatial/respopagesextod2011to2020.csv\")\n\n\n\n\nBefore a thematic map can be prepared, you are required to prepare a data table with year 2020 values. The data table should include the variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY.\n\nYOUNG: age group 0 to 4 until age groyup 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age group, and\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\n\nThe following data wrangling and transformation functions will be used:\n\npivot_wider() of tidyr package, and\nmutate(), filter(), group_by() and select() of dplyr package\n\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup() %&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n\n\n\nBefore we can perform the georelational join, one extra step is required to convert the values in PA and SZ fields to uppercase. This is because the values of PA and SZ fields are made up of upper- and lowercase. On the other, hand the SUBZONE_N and PLN_AREA_N are in uppercase.\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ),\n            .funs = funs(toupper)) %&gt;%\n  filter('ECONOmY ACTIVE' &gt; 0)\n\nNext, left_join() of dplyr is used to join the geographical data and attribute table using planning subzone name e.g. SUBZONE_N and SZ as the common identifier.\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\nThing to learn from the code chunk above:\nleft_join() of dplyr package is used with mpsz simple feature data frame as the left data table is to ensure that the output will be a simple features data frame.\n\nwrite_rds(mpsz_pop2020, \"111/rds/mpszpop2020.rds\")\n\n\n\n\n\n\nTwo approaches can be used to prepare thematic map using tmap, they are:\n\nPlotting a thematic map quickly by using qtm().\nPlotting highly customisable thematic map by using tmap elements.\n\n\n\nThe easiest and quickest to draw a choropleth map using tmap is using qtm(). It is concise and provides a good default visualisation in many cases.\nThe code chunk below will draw a cartographic standard choropleth map as shown below.\n\ntmap_mode(\"plot\")\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\ntmap_mode() with “plot” option is used to produce a static map. For interactive mode, “view” option should be used.\nfill argument is used to map the attribute (i.e. DEPENDENCY)\n\n\n\n\nDespite its usefulness of drawing a choropleth map quickly and easily, the disadvantge of qtm() is that it makes aesthetics of individual layers harder to control. To draw a high quality cartographic choropleth map as shown in the figure below, tmap’s drawing elements should be used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\nIn the following sub-section, we will share with you tmap functions that used to plot these elements.\n\n\nThe basic building block of tmap is tm_shape() followed by one or more layer elemments such as tm_fill() and tm_polygons().\nIn the code chunk below, tm_shape() is used to define the input data (i.e mpsz_pop2020) and tm_polygons() is used to draw the planning subzone polygons\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n\n\n\n\n\nTo draw a choropleth map showing the geographical distribution of a selected variable by planning subzone, we just need to assign the target variable such as Dependency to tm_polygons().\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nThings to learn from tm_polugons():\n\nThe default interval binning used to draw the choropleth map is called “pretty”. A detailed discussion of the data claasification methods supported by tamp will be provided in sub-section 4.3.\nThe default colour scheme used is [Yl0rRd] of ColorBrewer, You will learn more about the color scheme in sub-section 4.4.\nBy defailt, Missing value will be shaded in grey.\n\n4.2.3 Drawing a choropleth map using tm_fill() and *tm_border()** Actually, tm_polygons() is a wraper of tm_fill() and tm_border(). tm_fill() shades the polygons by using the default colour scheme and tm_borders() adds the borders of the shapefile onto the choropleth map.\nThe code chunk below draws a choropleth map by using tm_fill() alone.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nNotice that the planning subzones are shared according to the respective dependecy values\nTo add the boundary of the planning subzones, tm_borders will be used as shown in the code chunk below.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1, alpha = 1)\n\n\n\n\n\n\n\n\nNotice that light-gray border lines have been added on the choropleth map.\nThe alpha argument is used to define transparency number between 0 (totally transparent) and 1 (not transparent). By default, the alpha value of the col is used (normally 1).\nBeside alpha argument, there are three other arguments for tm_borders(), they are:\n\ncol = border colour,\nlwd = border line width. The default is 1, and\nlty = border line type. The default is “solid”.\n\n\n\n\n\nMost choropleth maps employ some methods of data classification. The point of classification is to take a large number of observations and group them into data ranges or classes.\ntmap provides a total ten data classification methods, namely: fixed, sd, equal, pretty(default), quantile, kmeans, hclust, bclust, fisher, and jenks.\nTo define a data classification method, the style argument of tm_fill() or tm_polygons() will be used.\n\n\nThe code chunk below shows a quantile data classification that used 5 classes.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nIn the code chunk below, equal data classification method is used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nNotice that the distribution of quantile data classification method are more evenly distributed then equal data classification method.\n\n\n\nFor all the built-in styles, the category breaks are computed internally. In order to override these defaults, the breakpoints can be set explicitly by means of the breaksargument to the tm_fill(). It is important to note that, in tmap the breaks include a minimum and maximum. As a result, in order to end up with n categories, n+1 elements must be specified in the breaks option (the values must be in increasing order).\nBefore we get started, it is always a good practice to get some descriptive statistics on the variable before setting the break points. Code chunk below will be used to compute and display the descriptive statistics of DEPENDENCY field.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7866  0.8585  0.8763 19.0000      92 \n\n\nWith reference to the results above, we set break point at 0.60, 0.70, 0.80, and 0.90. In addition, we also need to include a minimum and maximum, which we set at 0 and 100. Our breaks vector is thus c(0, 0.60, 0.70, 0.80, 0.90, 1.00)\nNow, we will plot the choropleth map by using the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\ntmap supports colour ramps either defined by the user or a set of predefined colour ramps from the RColorBrewer package.\n\n\nTo change the colour, we assign the preferred colour to palette argument of tm_fill()as shown in the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nNotice that the choropleth map is shaded in green.\nTo reverse the colour shading, add a “-” prefix.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nNotice that the colour scheme has been reversed.\n\n\n\n\nMap layout refers to the combination of all map elements into a cohensive map. Map elements include among others the objects to be mapped, the title, the scale bar, the compass, margins and aspects ratios. Colour settings and data classification methods covered in the previous section relate to the palette and break-points are used to affect how the map looks.\n\n\nIn tmap, several legend options are provided to change the placement, format and appearance of the legend.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\ntmap allows a wide variety of layout settings to be changed. They can be called by using tmap_style().\nThe code chunk below shows the classic style is used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\n\n\n\n\n\n\n\n\n\n\nBeside map style, tmap also also provides arguments to draw other map furniture such as compass, scale bar and grid lines.\nIn the code chunk below, tm_compass(), tm_scale_bar() and tm_grid() are used to add compass, scale bar and grid lines onto the choropleth map.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\nTo reset the default style, refer to the code chunk below.\n\ntmap_style(\"white\")\n\n\n\n\n\nSmall multiple maps, also referred to as facet maps, are composed of many maps arrange side-by-side, and sometimes stacked vertically. Small multiple maps enable the visualisation of how spatial relationships change with respect to another variable, such as time.\nIn tmap, small multiple maps can be plotted in three ways:\n\nby assigning multiple values to at least one of the asthetic arguments,\nby defining a group-by variable in tm_facets(), and\nby creating multiple stand-alone maps with tmap_arrange().\n\n\n\nIn this example, small multiple choropleth maps are created by defining ncols in tm_fill()\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\n\n\n\n\n\n\n\nIn this example, small multiple choropleth maps are created by assigning multiple values to at least one of the aesthetic arguments\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n\nIn this example, multiple small choropleth maps are created by using tm_facets().\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=FALSE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\nIn this example, multiple small choropleth maps are created by creating multiple stand-alone maps with tmap_arrange().\n\nyoungmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n\nInstead of creating small multiple choropleth map, you can also use selection funtion to map spatial objects meeting the selection criterion.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntmap: Thematic Maps in R\ntmap\ntmap: get started!\ntmap: changes in version 2.0\ntmap: creating thematic maps in a flexible way (useR!2015)\nExploring and presenting maps with tmap (useR!2017)\n\n\n\n\n\nsf: Simple Features for R\nSimple Features for R: StandardizedSupport for Spatial Vector Data\nReading, Writing and Converting Simple Features\n\n\n\n\n\ndplyr\nTidy data\ntidyr: Easily Tidy Data with ‘spread()’ and ‘gather()’ Functions"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08(a)/Hands-on_Ex08(a).html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex08(a)/Hands-on_Ex08(a).html#overview",
    "title": "Hands-on_Ex08(a)",
    "section": "",
    "text": "Choropleth mapping involves the symbolisation of enumeration units, such as countries, provinces, states, counties or census units, using area patterns or graduated colors. For example, a social scientist may need to use a choropleth map to portray the spatial distribution of aged population of Singapore by Master Plan 2014 Subzone Boundary.\nIn this chapter, you will learn how to plot functional and truthful choropleth maps by using an R package called tmap package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08(a)/Hands-on_Ex08(a).html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex08(a)/Hands-on_Ex08(a).html#getting-started",
    "title": "Hands-on_Ex08(a)",
    "section": "",
    "text": "In this hands-on exercise, the key R package use is tmap package in R. Beside tmappackage, four other R packages will be used. They are:\n\nreadr for importing delimited text file,\ntidyr for tidying data,\ndplyr for wrangling data and\nsf for handling geospatial data.\n\nAmong the four packages, readr, tidyr and dplyr are part of tidyverse package.\nThe code chunk below will be used to install and load these packages in RStudio.\n\npacman::p_load(sf, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08(a)/Hands-on_Ex08(a).html#importing-data-into-r",
    "href": "Hands-on_Ex/Hands-on_Ex08(a)/Hands-on_Ex08(a).html#importing-data-into-r",
    "title": "Hands-on_Ex08(a)",
    "section": "",
    "text": "Two data set will be used to create the choropleth map. They are:\n\nMaster Plan 2014 Subzone Boundary (Web) (i.e. MP14_SUBZONE_WEB_PL) in ESRI shapefile format. It can be downloaded at data.gov.sg This is a geospatial data. It consists of the geographical boundary of Singapore at the planning subzone level. The data is based on URA Master Plan 2014.\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2011-2020 in csv format (i.e. respopagesextod2011to2020.csv). This is an aspatial data fie. It can be downloaded at Department of Statistics, Singapore Although it does not contain any coordinates values, but it’s PA and SZ fields can be used as unique identifiers to geocode to MP14_SUBZONE_WEB_PL shapefile.\n\n\n\n\nThe code chunk below uses the st_read() function of sf package to import MP14_SUBZONE_WEB_PL shapefile into R as a simple feature data frame called mpsz.\n\nmpsz &lt;- st_read(dsn = \"111/222\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Applications/SMU/S2/ISSS608 Visual Analytics and Application/jiaxun.zou/ISSS608-VAA/Hands-on_Ex/Hands-on_Ex08(a)/111/222' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nYou can examine the content of mpsz by using the code chunk below.\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\nNotice that only the first ten records will be displayed.\n\n\n\nNext, we will import respopagsex2011to2020.csv file into RStudio and save the file into an R dataframe called popagsex.\nThe task will be performed by using read_csv() function of readr package as shown in the code chunk below.\n\npopdata &lt;- read_csv(\"111/aspatial/respopagesextod2011to2020.csv\")\n\n\n\n\nBefore a thematic map can be prepared, you are required to prepare a data table with year 2020 values. The data table should include the variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY.\n\nYOUNG: age group 0 to 4 until age groyup 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age group, and\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\n\nThe following data wrangling and transformation functions will be used:\n\npivot_wider() of tidyr package, and\nmutate(), filter(), group_by() and select() of dplyr package\n\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup() %&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n\n\n\nBefore we can perform the georelational join, one extra step is required to convert the values in PA and SZ fields to uppercase. This is because the values of PA and SZ fields are made up of upper- and lowercase. On the other, hand the SUBZONE_N and PLN_AREA_N are in uppercase.\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ),\n            .funs = funs(toupper)) %&gt;%\n  filter('ECONOmY ACTIVE' &gt; 0)\n\nNext, left_join() of dplyr is used to join the geographical data and attribute table using planning subzone name e.g. SUBZONE_N and SZ as the common identifier.\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\nThing to learn from the code chunk above:\nleft_join() of dplyr package is used with mpsz simple feature data frame as the left data table is to ensure that the output will be a simple features data frame.\n\nwrite_rds(mpsz_pop2020, \"111/rds/mpszpop2020.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08(a)/Hands-on_Ex08(a).html#choropleth-mapping-geospatial-data-using-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex08(a)/Hands-on_Ex08(a).html#choropleth-mapping-geospatial-data-using-tmap",
    "title": "Hands-on_Ex08(a)",
    "section": "",
    "text": "Two approaches can be used to prepare thematic map using tmap, they are:\n\nPlotting a thematic map quickly by using qtm().\nPlotting highly customisable thematic map by using tmap elements.\n\n\n\nThe easiest and quickest to draw a choropleth map using tmap is using qtm(). It is concise and provides a good default visualisation in many cases.\nThe code chunk below will draw a cartographic standard choropleth map as shown below.\n\ntmap_mode(\"plot\")\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\ntmap_mode() with “plot” option is used to produce a static map. For interactive mode, “view” option should be used.\nfill argument is used to map the attribute (i.e. DEPENDENCY)\n\n\n\n\nDespite its usefulness of drawing a choropleth map quickly and easily, the disadvantge of qtm() is that it makes aesthetics of individual layers harder to control. To draw a high quality cartographic choropleth map as shown in the figure below, tmap’s drawing elements should be used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\nIn the following sub-section, we will share with you tmap functions that used to plot these elements.\n\n\nThe basic building block of tmap is tm_shape() followed by one or more layer elemments such as tm_fill() and tm_polygons().\nIn the code chunk below, tm_shape() is used to define the input data (i.e mpsz_pop2020) and tm_polygons() is used to draw the planning subzone polygons\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n\n\n\n\n\nTo draw a choropleth map showing the geographical distribution of a selected variable by planning subzone, we just need to assign the target variable such as Dependency to tm_polygons().\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nThings to learn from tm_polugons():\n\nThe default interval binning used to draw the choropleth map is called “pretty”. A detailed discussion of the data claasification methods supported by tamp will be provided in sub-section 4.3.\nThe default colour scheme used is [Yl0rRd] of ColorBrewer, You will learn more about the color scheme in sub-section 4.4.\nBy defailt, Missing value will be shaded in grey.\n\n4.2.3 Drawing a choropleth map using tm_fill() and *tm_border()** Actually, tm_polygons() is a wraper of tm_fill() and tm_border(). tm_fill() shades the polygons by using the default colour scheme and tm_borders() adds the borders of the shapefile onto the choropleth map.\nThe code chunk below draws a choropleth map by using tm_fill() alone.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nNotice that the planning subzones are shared according to the respective dependecy values\nTo add the boundary of the planning subzones, tm_borders will be used as shown in the code chunk below.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1, alpha = 1)\n\n\n\n\n\n\n\n\nNotice that light-gray border lines have been added on the choropleth map.\nThe alpha argument is used to define transparency number between 0 (totally transparent) and 1 (not transparent). By default, the alpha value of the col is used (normally 1).\nBeside alpha argument, there are three other arguments for tm_borders(), they are:\n\ncol = border colour,\nlwd = border line width. The default is 1, and\nlty = border line type. The default is “solid”.\n\n\n\n\n\nMost choropleth maps employ some methods of data classification. The point of classification is to take a large number of observations and group them into data ranges or classes.\ntmap provides a total ten data classification methods, namely: fixed, sd, equal, pretty(default), quantile, kmeans, hclust, bclust, fisher, and jenks.\nTo define a data classification method, the style argument of tm_fill() or tm_polygons() will be used.\n\n\nThe code chunk below shows a quantile data classification that used 5 classes.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nIn the code chunk below, equal data classification method is used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nNotice that the distribution of quantile data classification method are more evenly distributed then equal data classification method.\n\n\n\nFor all the built-in styles, the category breaks are computed internally. In order to override these defaults, the breakpoints can be set explicitly by means of the breaksargument to the tm_fill(). It is important to note that, in tmap the breaks include a minimum and maximum. As a result, in order to end up with n categories, n+1 elements must be specified in the breaks option (the values must be in increasing order).\nBefore we get started, it is always a good practice to get some descriptive statistics on the variable before setting the break points. Code chunk below will be used to compute and display the descriptive statistics of DEPENDENCY field.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7866  0.8585  0.8763 19.0000      92 \n\n\nWith reference to the results above, we set break point at 0.60, 0.70, 0.80, and 0.90. In addition, we also need to include a minimum and maximum, which we set at 0 and 100. Our breaks vector is thus c(0, 0.60, 0.70, 0.80, 0.90, 1.00)\nNow, we will plot the choropleth map by using the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\ntmap supports colour ramps either defined by the user or a set of predefined colour ramps from the RColorBrewer package.\n\n\nTo change the colour, we assign the preferred colour to palette argument of tm_fill()as shown in the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nNotice that the choropleth map is shaded in green.\nTo reverse the colour shading, add a “-” prefix.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nNotice that the colour scheme has been reversed.\n\n\n\n\nMap layout refers to the combination of all map elements into a cohensive map. Map elements include among others the objects to be mapped, the title, the scale bar, the compass, margins and aspects ratios. Colour settings and data classification methods covered in the previous section relate to the palette and break-points are used to affect how the map looks.\n\n\nIn tmap, several legend options are provided to change the placement, format and appearance of the legend.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\ntmap allows a wide variety of layout settings to be changed. They can be called by using tmap_style().\nThe code chunk below shows the classic style is used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\n\n\n\n\n\n\n\n\n\n\nBeside map style, tmap also also provides arguments to draw other map furniture such as compass, scale bar and grid lines.\nIn the code chunk below, tm_compass(), tm_scale_bar() and tm_grid() are used to add compass, scale bar and grid lines onto the choropleth map.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\nTo reset the default style, refer to the code chunk below.\n\ntmap_style(\"white\")\n\n\n\n\n\nSmall multiple maps, also referred to as facet maps, are composed of many maps arrange side-by-side, and sometimes stacked vertically. Small multiple maps enable the visualisation of how spatial relationships change with respect to another variable, such as time.\nIn tmap, small multiple maps can be plotted in three ways:\n\nby assigning multiple values to at least one of the asthetic arguments,\nby defining a group-by variable in tm_facets(), and\nby creating multiple stand-alone maps with tmap_arrange().\n\n\n\nIn this example, small multiple choropleth maps are created by defining ncols in tm_fill()\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\n\n\n\n\n\n\n\nIn this example, small multiple choropleth maps are created by assigning multiple values to at least one of the aesthetic arguments\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n\nIn this example, multiple small choropleth maps are created by using tm_facets().\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=FALSE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\nIn this example, multiple small choropleth maps are created by creating multiple stand-alone maps with tmap_arrange().\n\nyoungmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n\nInstead of creating small multiple choropleth map, you can also use selection funtion to map spatial objects meeting the selection criterion.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08(a)/Hands-on_Ex08(a).html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex08(a)/Hands-on_Ex08(a).html#reference",
    "title": "Hands-on_Ex08(a)",
    "section": "",
    "text": "tmap: Thematic Maps in R\ntmap\ntmap: get started!\ntmap: changes in version 2.0\ntmap: creating thematic maps in a flexible way (useR!2015)\nExploring and presenting maps with tmap (useR!2017)\n\n\n\n\n\nsf: Simple Features for R\nSimple Features for R: StandardizedSupport for Spatial Vector Data\nReading, Writing and Converting Simple Features\n\n\n\n\n\ndplyr\nTidy data\ntidyr: Easily Tidy Data with ‘spread()’ and ‘gather()’ Functions"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09(c)/Hands-on_Ex09(c).html",
    "href": "Hands-on_Ex/Hands-on_Ex09(c)/Hands-on_Ex09(c).html",
    "title": "Hands-on_Ex09(c)",
    "section": "",
    "text": "Parallel coordinates plot is a data visualisation specially designed for visualising and analysing multivariate, numerical data. It is ideal for comparing multiple variables together and seeing the relationships between them. For example, the variables contribute to Happiness Index. Parallel coordinates was invented by Alfred Inselberg in the 1970s as a way to visualize high-dimensional data. This data visualisation technique is more often found in academic and scientific communities than in business and consumer data visualizations. As pointed out by Stephen Few(2006), “This certainly isn’t a chart that you would present to the board of directors or place on your Web site for the general public. In fact, the strength of parallel coordinates isn’t in their ability to communicate some truth in the data to others, but rather in their ability to bring meaningful multivariate patterns and comparisons to light when used interactively for analysis.” For example, parallel coordinates plot can be used to characterise clusters detected during customer segmentation.\nBy the end of this hands-on exercise, you will gain hands-on experience on:\n\nplotting statistic parallel coordinates plots by using ggparcoord() of GGally package,\nplotting interactive parallel coordinates plots by using parcoords package, and\nplotting interactive parallel coordinates plots by using parallelPlot package.\n\n\n\n\nFor this exercise, the GGally, parcoords, parallelPlot and tidyverse packages will be used.\nThe code chunks below are used to install and load the packages in R.\n\npacman::p_load(GGally, parallelPlot, tidyverse)\n\n\n\n\nIn this hands-on exercise, the World Happinees 2018 (http://worldhappiness.report/ed/2018/) data will be used. The data set is download at https://s3.amazonaws.com/happiness-report/2018/WHR2018Chapter2OnlineData.xls. The original data set is in Microsoft Excel format. It has been extracted and saved in csv file called WHData-2018.csv.\nIn the code chunk below, read_csv() of readr package is used to import WHData-2018.csv into R and save it into a tibble data frame object called wh.\n\nwh &lt;- read_csv(\"data/WHData-2018.csv\")\n\n\n\n\nIn this section, you will learn how to plot static parallel coordinates plot by using ggparcoord() of GGally package. Before getting started, it is a good practice to read the function description in detail.\n\n\nCode chunk below shows a typical syntax used to plot a basic static parallel coordinates plot by using ggparcoord().\n\nggparcoord(data = wh, \n           columns = c(7:12))\n\n\n\n\n\n\n\n\nNotice that only two argument namely data and columns is used. Data argument is used to map the data object (i.e. wh) and columns is used to select the columns for preparing the parallel coordinates plot.\n\n\n\nThe basic parallel coordinates failed to reveal any meaning understanding of the World Happiness measures. In this section, you will learn how to makeover the plot by using a collection of arguments provided by ggparcoord().\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Parallel Coordinates Plot of World Happines Variables\")\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above.\n\ngroupColumn argument is used to group the observations (i.e. parallel lines) by using a single variable (i.e. Region) and colour the parallel coordinates lines by region name.\nscale argument is used to scale the variables in the parallel coordinate plot by using uniminmaxmethod. The method univariately scale each variable so the minimum of the variable is zero and the maximum is one.\nalphaLines argument is used to reduce the intensity of the line colour to 0.2. The permissible value range is between 0 to 1.\nboxplot argument is used to turn on the boxplot by using logical TRUE. The default is FALSE.\ntitle argument is used to provide the parallel coordinates plot a title.\n\n\n\n\nSince ggparcoord() is developed by extending ggplot2 package, we can combination use some of the ggplot2 function when plotting a parallel coordinates plot.\nIn the code chunk below, facet_wrap() of ggplot2 is used to plot 10 small multiple parallel coordinates plots. Each plot represent one geographical region such as East Asia.\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region)\n\n\n\n\n\n\n\n\nOne of the aesthetic defect of the current design is that some of the variable names overlap on x-axis.\n\n\n\nTo make the x-axis text label easy to read, let us rotate the labels by 30 degrees. We can rotate axis text labels using theme() function in ggplot2 as shown in the code chunk below\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region) + \n  theme(axis.text.x = element_text(angle = 30))\n\n\n\n\n\n\n\n\nThing to learn from the code chunk above:\n\nTo rotate x-axis text labels, we use axis.text.x as argument to theme() function. And we specify element_text(angle = 30) to rotate the x-axis text by an angle 30 degree.\n\n\n\n\nRotating x-axis text labels to 30 degrees makes the label overlap with the plot and we can avoid this by adjusting the text location using hjust argument to theme’s text element with element_text(). We use axis.text.x as we want to change the look of x-axis text.\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region) + \n  theme(axis.text.x = element_text(angle = 30, hjust=1))\n\n\n\n\n\n\n\n\n\n\n\n\nparallelPlot is an R package specially designed to plot a parallel coordinates plot by using ‘htmlwidgets’ package and d3.js. In this section, you will learn how to use functions provided in parallelPlot package to build interactive parallel coordinates plot.\n\n\nThe code chunk below plot an interactive parallel coordinates plot by using parallelPlot().\n\nwh &lt;- wh %&gt;%\n  select(\"Happiness score\", c(7:12))\nparallelPlot(wh,\n             width = 320,\n             height = 250)\n\n\n\n\n\nNotice that some of the axis labels are too long. You will learn how to overcome this problem in the next step.\n\n\n\nIn the code chunk below, rotateTitle argument is used to avoid overlapping axis labels.\n\nparallelPlot(wh,\n             rotateTitle = TRUE)\n\n\n\n\n\nOne of the useful interactive feature of parallelPlot is we can click on a variable of interest, for example Happiness score, the monotonous blue colour (default) will change a blues with different intensity colour scheme will be used.\n\n\n\nWe can change the default blue colour scheme by using continousCS argument as shown in the code chunl below.\n\nparallelPlot(wh,\n             continuousCS = \"YlOrRd\",\n             rotateTitle = TRUE)\n\n\n\n\n\n\n\n\nIn the code chunk below, histoVisibility argument is used to plot histogram along the axis of each variables.\n\nhistoVisibility &lt;- rep(TRUE, ncol(wh))\nparallelPlot(wh,\n             rotateTitle = TRUE,\n             histoVisibility = histoVisibility)\n\n\n\n\n\n\n\n\n\n\nggparcoord() of GGally package\nparcoords user guide\nparallelPlot"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09(c)/Hands-on_Ex09(c).html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex09(c)/Hands-on_Ex09(c).html#overview",
    "title": "Hands-on_Ex09(c)",
    "section": "",
    "text": "Parallel coordinates plot is a data visualisation specially designed for visualising and analysing multivariate, numerical data. It is ideal for comparing multiple variables together and seeing the relationships between them. For example, the variables contribute to Happiness Index. Parallel coordinates was invented by Alfred Inselberg in the 1970s as a way to visualize high-dimensional data. This data visualisation technique is more often found in academic and scientific communities than in business and consumer data visualizations. As pointed out by Stephen Few(2006), “This certainly isn’t a chart that you would present to the board of directors or place on your Web site for the general public. In fact, the strength of parallel coordinates isn’t in their ability to communicate some truth in the data to others, but rather in their ability to bring meaningful multivariate patterns and comparisons to light when used interactively for analysis.” For example, parallel coordinates plot can be used to characterise clusters detected during customer segmentation.\nBy the end of this hands-on exercise, you will gain hands-on experience on:\n\nplotting statistic parallel coordinates plots by using ggparcoord() of GGally package,\nplotting interactive parallel coordinates plots by using parcoords package, and\nplotting interactive parallel coordinates plots by using parallelPlot package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09(c)/Hands-on_Ex09(c).html#installing-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex09(c)/Hands-on_Ex09(c).html#installing-and-launching-r-packages",
    "title": "Hands-on_Ex09(c)",
    "section": "",
    "text": "For this exercise, the GGally, parcoords, parallelPlot and tidyverse packages will be used.\nThe code chunks below are used to install and load the packages in R.\n\npacman::p_load(GGally, parallelPlot, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09(c)/Hands-on_Ex09(c).html#data-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex09(c)/Hands-on_Ex09(c).html#data-preparation",
    "title": "Hands-on_Ex09(c)",
    "section": "",
    "text": "In this hands-on exercise, the World Happinees 2018 (http://worldhappiness.report/ed/2018/) data will be used. The data set is download at https://s3.amazonaws.com/happiness-report/2018/WHR2018Chapter2OnlineData.xls. The original data set is in Microsoft Excel format. It has been extracted and saved in csv file called WHData-2018.csv.\nIn the code chunk below, read_csv() of readr package is used to import WHData-2018.csv into R and save it into a tibble data frame object called wh.\n\nwh &lt;- read_csv(\"data/WHData-2018.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09(c)/Hands-on_Ex09(c).html#plotting-static-parallel-coordinates-plot",
    "href": "Hands-on_Ex/Hands-on_Ex09(c)/Hands-on_Ex09(c).html#plotting-static-parallel-coordinates-plot",
    "title": "Hands-on_Ex09(c)",
    "section": "",
    "text": "In this section, you will learn how to plot static parallel coordinates plot by using ggparcoord() of GGally package. Before getting started, it is a good practice to read the function description in detail.\n\n\nCode chunk below shows a typical syntax used to plot a basic static parallel coordinates plot by using ggparcoord().\n\nggparcoord(data = wh, \n           columns = c(7:12))\n\n\n\n\n\n\n\n\nNotice that only two argument namely data and columns is used. Data argument is used to map the data object (i.e. wh) and columns is used to select the columns for preparing the parallel coordinates plot.\n\n\n\nThe basic parallel coordinates failed to reveal any meaning understanding of the World Happiness measures. In this section, you will learn how to makeover the plot by using a collection of arguments provided by ggparcoord().\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Parallel Coordinates Plot of World Happines Variables\")\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above.\n\ngroupColumn argument is used to group the observations (i.e. parallel lines) by using a single variable (i.e. Region) and colour the parallel coordinates lines by region name.\nscale argument is used to scale the variables in the parallel coordinate plot by using uniminmaxmethod. The method univariately scale each variable so the minimum of the variable is zero and the maximum is one.\nalphaLines argument is used to reduce the intensity of the line colour to 0.2. The permissible value range is between 0 to 1.\nboxplot argument is used to turn on the boxplot by using logical TRUE. The default is FALSE.\ntitle argument is used to provide the parallel coordinates plot a title.\n\n\n\n\nSince ggparcoord() is developed by extending ggplot2 package, we can combination use some of the ggplot2 function when plotting a parallel coordinates plot.\nIn the code chunk below, facet_wrap() of ggplot2 is used to plot 10 small multiple parallel coordinates plots. Each plot represent one geographical region such as East Asia.\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region)\n\n\n\n\n\n\n\n\nOne of the aesthetic defect of the current design is that some of the variable names overlap on x-axis.\n\n\n\nTo make the x-axis text label easy to read, let us rotate the labels by 30 degrees. We can rotate axis text labels using theme() function in ggplot2 as shown in the code chunk below\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region) + \n  theme(axis.text.x = element_text(angle = 30))\n\n\n\n\n\n\n\n\nThing to learn from the code chunk above:\n\nTo rotate x-axis text labels, we use axis.text.x as argument to theme() function. And we specify element_text(angle = 30) to rotate the x-axis text by an angle 30 degree.\n\n\n\n\nRotating x-axis text labels to 30 degrees makes the label overlap with the plot and we can avoid this by adjusting the text location using hjust argument to theme’s text element with element_text(). We use axis.text.x as we want to change the look of x-axis text.\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region) + \n  theme(axis.text.x = element_text(angle = 30, hjust=1))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09(c)/Hands-on_Ex09(c).html#plotting-interactive-parallel-coordinates-plot-parallelplot-methods",
    "href": "Hands-on_Ex/Hands-on_Ex09(c)/Hands-on_Ex09(c).html#plotting-interactive-parallel-coordinates-plot-parallelplot-methods",
    "title": "Hands-on_Ex09(c)",
    "section": "",
    "text": "parallelPlot is an R package specially designed to plot a parallel coordinates plot by using ‘htmlwidgets’ package and d3.js. In this section, you will learn how to use functions provided in parallelPlot package to build interactive parallel coordinates plot.\n\n\nThe code chunk below plot an interactive parallel coordinates plot by using parallelPlot().\n\nwh &lt;- wh %&gt;%\n  select(\"Happiness score\", c(7:12))\nparallelPlot(wh,\n             width = 320,\n             height = 250)\n\n\n\n\n\nNotice that some of the axis labels are too long. You will learn how to overcome this problem in the next step.\n\n\n\nIn the code chunk below, rotateTitle argument is used to avoid overlapping axis labels.\n\nparallelPlot(wh,\n             rotateTitle = TRUE)\n\n\n\n\n\nOne of the useful interactive feature of parallelPlot is we can click on a variable of interest, for example Happiness score, the monotonous blue colour (default) will change a blues with different intensity colour scheme will be used.\n\n\n\nWe can change the default blue colour scheme by using continousCS argument as shown in the code chunl below.\n\nparallelPlot(wh,\n             continuousCS = \"YlOrRd\",\n             rotateTitle = TRUE)\n\n\n\n\n\n\n\n\nIn the code chunk below, histoVisibility argument is used to plot histogram along the axis of each variables.\n\nhistoVisibility &lt;- rep(TRUE, ncol(wh))\nparallelPlot(wh,\n             rotateTitle = TRUE,\n             histoVisibility = histoVisibility)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09(c)/Hands-on_Ex09(c).html#references",
    "href": "Hands-on_Ex/Hands-on_Ex09(c)/Hands-on_Ex09(c).html#references",
    "title": "Hands-on_Ex09(c)",
    "section": "",
    "text": "ggparcoord() of GGally package\nparcoords user guide\nparallelPlot"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09(d)/Hands-on_Ex09(d).html",
    "href": "Hands-on_Ex/Hands-on_Ex09(d)/Hands-on_Ex09(d).html",
    "title": "Hands-on_Ex09(d)",
    "section": "",
    "text": "In this hands-on exercise, you will gain hands-on experiences on designing treemap using appropriate R packages. The hands-on exercise consists of three main section. First, you will learn how to manipulate transaction data into a treemap strcuture by using selected functions provided in dplyr package. Then, you will learn how to plot static treemap by using treemap package. In the third section, you will learn how to design interactive treemap by using d3treeR package.\n\n\n\nBefore we get started, you are required to check if treemap and tidyverse pacakges have been installed in you R.\n\npacman::p_load(treemap, treemapify, tidyverse) \n\n\n\n\nIn this exercise, REALIS2018.csv data will be used. This dataset provides information of private property transaction records in 2018. The dataset is extracted from REALIS portal (https://spring.ura.gov.sg/lad/ore/login/index.cfm) of Urban Redevelopment Authority (URA)\n3.1 Importing the data set\nIn the code chunk below, read_csv() of readr is used to import realis2018.csv into R and parsed it into tibble R data.frame format.\n\nrealis2018 &lt;- read_csv(\"data/realis2018.csv\")\n\nThe output tibble data.frame is called realis2018.\n\n\nThe data.frame realis2018 is in trasaction record form, which is highly disaggregated and not appropriate to be used to plot a treemap. In this section, we will perform the following steps to manipulate and prepare a data.frtame that is appropriate for treemap visualisation:\n\ngroup transaction records by Project Name, Planning Region, Planning Area, Property Type and Type of Sale, and\ncompute Total Unit Sold, Total Area, Median Unit Price and Median Transacted Price by applying appropriate summary statistics on No. of Units, Area (sqm), Unit Price ($ psm) and Transacted Price ($) respectively.\n\nTwo key verbs of dplyr package, namely: group_by() and summarize() will be used to perform these steps.\ngroup_by() breaks down a data.frame into specified groups of rows. When you then apply the verbs above on the resulting object they’ll be automatically applied “by group”.\nGrouping affects the verbs as follows:\n\ngrouped select() is the same as ungrouped select(), except that grouping variables are always retained.\ngrouped arrange() is the same as ungrouped; unless you set .by_group = TRUE, in which case it orders first by the grouping variables.\nmutate() and filter() are most useful in conjunction with window functions (like rank(), or min(x) == x). They are described in detail in vignette(“window-functions”).\nsample_n() and sample_frac() sample the specified number/fraction of rows in each group.\nsummarise() computes the summary for each group.\n\nIn our case, group_by() will used together with summarise() to derive the summarised data.frame\n\n\n\nThe code chank below shows a typical two lines code approach to perform the steps.\n\nrealis2018_grouped &lt;- group_by(realis2018, `Project Name`,\n                               `Planning Region`, `Planning Area`, \n                               `Property Type`, `Type of Sale`)\nrealis2018_summarised &lt;- summarise(realis2018_grouped, \n                          `Total Unit Sold` = sum(`No. of Units`, na.rm = TRUE),\n                          `Total Area` = sum(`Area (sqm)`, na.rm = TRUE),\n                          `Median Unit Price ($ psm)` = median(`Unit Price ($ psm)`, na.rm = TRUE), \n                          `Median Transacted Price` = median(`Transacted Price ($)`, na.rm = TRUE))\n\nThe code chunk above is not very efficient because we have to give each intermediate data.frame a name, even though we don’t have to care about it.\n\n\n\nThe code chunk below shows a more efficient way to tackle the same processes by using the pipe, %&gt;%:\n\nrealis2018_summarised &lt;- realis2018 %&gt;% \n  group_by(`Project Name`,`Planning Region`, \n           `Planning Area`, `Property Type`, \n           `Type of Sale`) %&gt;%\n  summarise(`Total Unit Sold` = sum(`No. of Units`, na.rm = TRUE), \n            `Total Area` = sum(`Area (sqm)`, na.rm = TRUE),\n            `Median Unit Price ($ psm)` = median(`Unit Price ($ psm)`, na.rm = TRUE),\n            `Median Transacted Price` = median(`Transacted Price ($)`, na.rm = TRUE))\n\n\n\n\n\ntreemap package is a R package specially designed to offer great flexibility in drawing treemaps. The core function, namely: treemap() offers at least 43 arguments. In this section, we will only explore the major arguments for designing elegent and yet truthful treemaps.\n\n\nIn this section, treemap() of Treemap package is used to plot a treemap showing the distribution of median unit prices and total unit sold of resale condominium by geographic hierarchy in 2017.\nFirst, we will select records belongs to resale condominium property type from realis2018_selected data frame.\n\nrealis2018_selected &lt;- realis2018_summarised %&gt;%\n  filter(`Property Type` == \"Condominium\", `Type of Sale` == \"Resale\")\n\n\n\n\nThe code chunk below designed a treemap by using three core arguments of treemap(), namely: index, vSize and vColor.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\nThings to learn from the three arguments used:\n\nindex\n\nThe index vector must consist of at least two column names or else no hierarchy treemap will be plotted.\nIf multiple column names are provided, such as the code chunk above, the first name is the highest aggregation level, the second name the second highest aggregation level, and so on.\n\nvSize\n\nThe column must not contain negative values. This is because it’s vaues will be used to map the sizes of the rectangles of the treemaps.\n\n\nWarning:\nThe treemap above was wrongly coloured. For a correctly designed treemap, the colours of the rectagles should be in different intensity showing, in our case, median unit prices.\nFor treemap(), vColor is used in combination with the argument type to determines the colours of the rectangles. Without defining type, like the code chunk above, treemap() assumes type = index, in our case, the hierarchy of planning areas.\n\n\n\nIn the code chunk below, type argument is define as value.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type = \"value\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\nThinking to learn from the conde chunk above.\n\nThe rectangles are coloured with different intensity of green, reflecting their respective median unit prices.\nThe legend reveals that the values are binned into ten bins, i.e. 0-5000, 5000-10000, etc. with an equal interval of 5000.\n\n\n\n\nThere are two arguments that determine the mapping to color palettes: mapping and palette. The only difference between “value” and “manual” is the default value for mapping. The “value” treemap considers palette to be a diverging color palette (say ColorBrewer’s “RdYlBu”), and maps it in such a way that 0 corresponds to the middle color (typically white or yellow), -max(abs(values)) to the left-end color, and max(abs(values)), to the right-end color. The “manual” treemap simply maps min(values) to the left-end color, max(values) to the right-end color, and mean(range(values)) to the middle color.\n\n\n\nThe code chunk below shows a value type treemap.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"value\",\n        palette=\"RdYlBu\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\nThing to learn from the code chunk above:\n\nalthough the colour palette used is RdYlBu but there are no red rectangles in the treemap above. This is because all the median unit prices are positive.\nThe reason why we see only 5000 to 45000 in the legend is because the range argument is by default c(min(values, max(values)) with some pretty rounding.\n\n\n\n\nThe “manual” type does not interpret the values as the “value” type does. Instead, the value range is mapped linearly to the colour palette.\nThe code chunk below shows a manual type treemap.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"RdYlBu\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\nThe colour scheme used is very copnfusing. This is because mapping = (min(values), mean(range(values)), max(values)). It is not wise to use diverging colour palette such as RdYlBu if the values are all positive or negative\n\nTo overcome this problem, a single colour palette such as Blues should be used.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\n\ntreemap() supports two popular treemap layouts, namely: “squarified” and “pivotSize”. The default is “pivotSize”.\nThe squarified treemap algorithm (Bruls et al., 2000) produces good aspect ratios, but ignores the sorting order of the rectangles (sortID). The ordered treemap, pivot-by-size, algorithm (Bederson et al., 2002) takes the sorting order (sortID) into account while aspect ratios are still acceptable.\n\n\n\nThe code chunk below plots a squarified treemap by changing the algorithm argument.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        algorithm = \"squarified\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\n\nWhen “pivotSize” algorithm is used, sortID argument can be used to dertemine the order in which the rectangles are placed from top left to bottom right.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        algorithm = \"pivotSize\",\n        sortID = \"Median Transacted Price\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\n\n\ntreemapify is a R package specially developed to draw treemaps in ggplot2. In this section, you will learn how to designing treemps closely resemble treemaps designing in previous section by using treemapify. Before you getting started, you should read Introduction to “treemapify” its user guide.\n\n\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`),\n       layout = \"scol\",\n       start = \"bottomleft\") + \n  geom_treemap() +\n  scale_fill_gradient(low = \"light blue\", high = \"blue\")\n\n\n\n\n\n\n\n\n\n\n\nGroup by Planning Region\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`),\n       start = \"topleft\") + \n  geom_treemap()\n\n\n\n\n\n\n\n\nGroup by Planning Area\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`,\n           subgroup2 = `Planning Area`)) + \n  geom_treemap()\n\n\n\n\n\n\n\n\nAdding boundary line\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`,\n           subgroup2 = `Planning Area`)) + \n  geom_treemap() +\n  geom_treemap_subgroup2_border(colour = \"gray40\",\n                                size = 2) +\n  geom_treemap_subgroup_border(colour = \"gray20\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis slide shows you how to install a R package which is not available in cran.\n\nIf this is the first time you install a package from github, you should install devtools package by using the code below or else you can skip this step.\n\n\n# install.packages(\"devtools\")\n\n\nNext, you will load the devtools library and install the package found in github by using the codes below.\n\n\n# library(devtools)\n# install_github(\"timelyportfolio/d3treeR\")\n\n\nNow you are ready to launch d3treeR package\n\n\n# library(d3treeR)\n\n\n\n\nThe codes below perform two processes.\n\ntreemap() is used to build a treemap by using selected variables in condominium data.frame. The treemap created is save as object called tm\n\n\ntm &lt;- treemap(realis2018_summarised,\n        index=c(\"Planning Region\", \"Planning Area\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"value\",\n        title=\"Private Residential Property Sold, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\nThen d3tree() is used to build an interactive treemap.\n\n\n# d3tree(tm,rootname = \"Singapore\" )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09(d)/Hands-on_Ex09(d).html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex09(d)/Hands-on_Ex09(d).html#overview",
    "title": "Hands-on_Ex09(d)",
    "section": "",
    "text": "In this hands-on exercise, you will gain hands-on experiences on designing treemap using appropriate R packages. The hands-on exercise consists of three main section. First, you will learn how to manipulate transaction data into a treemap strcuture by using selected functions provided in dplyr package. Then, you will learn how to plot static treemap by using treemap package. In the third section, you will learn how to design interactive treemap by using d3treeR package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09(d)/Hands-on_Ex09(d).html#installing-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex09(d)/Hands-on_Ex09(d).html#installing-and-launching-r-packages",
    "title": "Hands-on_Ex09(d)",
    "section": "",
    "text": "Before we get started, you are required to check if treemap and tidyverse pacakges have been installed in you R.\n\npacman::p_load(treemap, treemapify, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09(d)/Hands-on_Ex09(d).html#data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex09(d)/Hands-on_Ex09(d).html#data-wrangling",
    "title": "Hands-on_Ex09(d)",
    "section": "",
    "text": "In this exercise, REALIS2018.csv data will be used. This dataset provides information of private property transaction records in 2018. The dataset is extracted from REALIS portal (https://spring.ura.gov.sg/lad/ore/login/index.cfm) of Urban Redevelopment Authority (URA)\n3.1 Importing the data set\nIn the code chunk below, read_csv() of readr is used to import realis2018.csv into R and parsed it into tibble R data.frame format.\n\nrealis2018 &lt;- read_csv(\"data/realis2018.csv\")\n\nThe output tibble data.frame is called realis2018.\n\n\nThe data.frame realis2018 is in trasaction record form, which is highly disaggregated and not appropriate to be used to plot a treemap. In this section, we will perform the following steps to manipulate and prepare a data.frtame that is appropriate for treemap visualisation:\n\ngroup transaction records by Project Name, Planning Region, Planning Area, Property Type and Type of Sale, and\ncompute Total Unit Sold, Total Area, Median Unit Price and Median Transacted Price by applying appropriate summary statistics on No. of Units, Area (sqm), Unit Price ($ psm) and Transacted Price ($) respectively.\n\nTwo key verbs of dplyr package, namely: group_by() and summarize() will be used to perform these steps.\ngroup_by() breaks down a data.frame into specified groups of rows. When you then apply the verbs above on the resulting object they’ll be automatically applied “by group”.\nGrouping affects the verbs as follows:\n\ngrouped select() is the same as ungrouped select(), except that grouping variables are always retained.\ngrouped arrange() is the same as ungrouped; unless you set .by_group = TRUE, in which case it orders first by the grouping variables.\nmutate() and filter() are most useful in conjunction with window functions (like rank(), or min(x) == x). They are described in detail in vignette(“window-functions”).\nsample_n() and sample_frac() sample the specified number/fraction of rows in each group.\nsummarise() computes the summary for each group.\n\nIn our case, group_by() will used together with summarise() to derive the summarised data.frame\n\n\n\nThe code chank below shows a typical two lines code approach to perform the steps.\n\nrealis2018_grouped &lt;- group_by(realis2018, `Project Name`,\n                               `Planning Region`, `Planning Area`, \n                               `Property Type`, `Type of Sale`)\nrealis2018_summarised &lt;- summarise(realis2018_grouped, \n                          `Total Unit Sold` = sum(`No. of Units`, na.rm = TRUE),\n                          `Total Area` = sum(`Area (sqm)`, na.rm = TRUE),\n                          `Median Unit Price ($ psm)` = median(`Unit Price ($ psm)`, na.rm = TRUE), \n                          `Median Transacted Price` = median(`Transacted Price ($)`, na.rm = TRUE))\n\nThe code chunk above is not very efficient because we have to give each intermediate data.frame a name, even though we don’t have to care about it.\n\n\n\nThe code chunk below shows a more efficient way to tackle the same processes by using the pipe, %&gt;%:\n\nrealis2018_summarised &lt;- realis2018 %&gt;% \n  group_by(`Project Name`,`Planning Region`, \n           `Planning Area`, `Property Type`, \n           `Type of Sale`) %&gt;%\n  summarise(`Total Unit Sold` = sum(`No. of Units`, na.rm = TRUE), \n            `Total Area` = sum(`Area (sqm)`, na.rm = TRUE),\n            `Median Unit Price ($ psm)` = median(`Unit Price ($ psm)`, na.rm = TRUE),\n            `Median Transacted Price` = median(`Transacted Price ($)`, na.rm = TRUE))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09(d)/Hands-on_Ex09(d).html#designing-treemap-with-treemap-package",
    "href": "Hands-on_Ex/Hands-on_Ex09(d)/Hands-on_Ex09(d).html#designing-treemap-with-treemap-package",
    "title": "Hands-on_Ex09(d)",
    "section": "",
    "text": "treemap package is a R package specially designed to offer great flexibility in drawing treemaps. The core function, namely: treemap() offers at least 43 arguments. In this section, we will only explore the major arguments for designing elegent and yet truthful treemaps.\n\n\nIn this section, treemap() of Treemap package is used to plot a treemap showing the distribution of median unit prices and total unit sold of resale condominium by geographic hierarchy in 2017.\nFirst, we will select records belongs to resale condominium property type from realis2018_selected data frame.\n\nrealis2018_selected &lt;- realis2018_summarised %&gt;%\n  filter(`Property Type` == \"Condominium\", `Type of Sale` == \"Resale\")\n\n\n\n\nThe code chunk below designed a treemap by using three core arguments of treemap(), namely: index, vSize and vColor.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\nThings to learn from the three arguments used:\n\nindex\n\nThe index vector must consist of at least two column names or else no hierarchy treemap will be plotted.\nIf multiple column names are provided, such as the code chunk above, the first name is the highest aggregation level, the second name the second highest aggregation level, and so on.\n\nvSize\n\nThe column must not contain negative values. This is because it’s vaues will be used to map the sizes of the rectangles of the treemaps.\n\n\nWarning:\nThe treemap above was wrongly coloured. For a correctly designed treemap, the colours of the rectagles should be in different intensity showing, in our case, median unit prices.\nFor treemap(), vColor is used in combination with the argument type to determines the colours of the rectangles. Without defining type, like the code chunk above, treemap() assumes type = index, in our case, the hierarchy of planning areas.\n\n\n\nIn the code chunk below, type argument is define as value.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type = \"value\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\nThinking to learn from the conde chunk above.\n\nThe rectangles are coloured with different intensity of green, reflecting their respective median unit prices.\nThe legend reveals that the values are binned into ten bins, i.e. 0-5000, 5000-10000, etc. with an equal interval of 5000.\n\n\n\n\nThere are two arguments that determine the mapping to color palettes: mapping and palette. The only difference between “value” and “manual” is the default value for mapping. The “value” treemap considers palette to be a diverging color palette (say ColorBrewer’s “RdYlBu”), and maps it in such a way that 0 corresponds to the middle color (typically white or yellow), -max(abs(values)) to the left-end color, and max(abs(values)), to the right-end color. The “manual” treemap simply maps min(values) to the left-end color, max(values) to the right-end color, and mean(range(values)) to the middle color.\n\n\n\nThe code chunk below shows a value type treemap.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"value\",\n        palette=\"RdYlBu\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\nThing to learn from the code chunk above:\n\nalthough the colour palette used is RdYlBu but there are no red rectangles in the treemap above. This is because all the median unit prices are positive.\nThe reason why we see only 5000 to 45000 in the legend is because the range argument is by default c(min(values, max(values)) with some pretty rounding.\n\n\n\n\nThe “manual” type does not interpret the values as the “value” type does. Instead, the value range is mapped linearly to the colour palette.\nThe code chunk below shows a manual type treemap.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"RdYlBu\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\nThe colour scheme used is very copnfusing. This is because mapping = (min(values), mean(range(values)), max(values)). It is not wise to use diverging colour palette such as RdYlBu if the values are all positive or negative\n\nTo overcome this problem, a single colour palette such as Blues should be used.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\n\ntreemap() supports two popular treemap layouts, namely: “squarified” and “pivotSize”. The default is “pivotSize”.\nThe squarified treemap algorithm (Bruls et al., 2000) produces good aspect ratios, but ignores the sorting order of the rectangles (sortID). The ordered treemap, pivot-by-size, algorithm (Bederson et al., 2002) takes the sorting order (sortID) into account while aspect ratios are still acceptable.\n\n\n\nThe code chunk below plots a squarified treemap by changing the algorithm argument.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        algorithm = \"squarified\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\n\nWhen “pivotSize” algorithm is used, sortID argument can be used to dertemine the order in which the rectangles are placed from top left to bottom right.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        algorithm = \"pivotSize\",\n        sortID = \"Median Transacted Price\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09(d)/Hands-on_Ex09(d).html#designing-treemap-using-treemapify-package",
    "href": "Hands-on_Ex/Hands-on_Ex09(d)/Hands-on_Ex09(d).html#designing-treemap-using-treemapify-package",
    "title": "Hands-on_Ex09(d)",
    "section": "",
    "text": "treemapify is a R package specially developed to draw treemaps in ggplot2. In this section, you will learn how to designing treemps closely resemble treemaps designing in previous section by using treemapify. Before you getting started, you should read Introduction to “treemapify” its user guide.\n\n\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`),\n       layout = \"scol\",\n       start = \"bottomleft\") + \n  geom_treemap() +\n  scale_fill_gradient(low = \"light blue\", high = \"blue\")\n\n\n\n\n\n\n\n\n\n\n\nGroup by Planning Region\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`),\n       start = \"topleft\") + \n  geom_treemap()\n\n\n\n\n\n\n\n\nGroup by Planning Area\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`,\n           subgroup2 = `Planning Area`)) + \n  geom_treemap()\n\n\n\n\n\n\n\n\nAdding boundary line\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`,\n           subgroup2 = `Planning Area`)) + \n  geom_treemap() +\n  geom_treemap_subgroup2_border(colour = \"gray40\",\n                                size = 2) +\n  geom_treemap_subgroup_border(colour = \"gray20\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09(d)/Hands-on_Ex09(d).html#designing-interactive-treemap-using-d3treer",
    "href": "Hands-on_Ex/Hands-on_Ex09(d)/Hands-on_Ex09(d).html#designing-interactive-treemap-using-d3treer",
    "title": "Hands-on_Ex09(d)",
    "section": "",
    "text": "This slide shows you how to install a R package which is not available in cran.\n\nIf this is the first time you install a package from github, you should install devtools package by using the code below or else you can skip this step.\n\n\n# install.packages(\"devtools\")\n\n\nNext, you will load the devtools library and install the package found in github by using the codes below.\n\n\n# library(devtools)\n# install_github(\"timelyportfolio/d3treeR\")\n\n\nNow you are ready to launch d3treeR package\n\n\n# library(d3treeR)\n\n\n\n\nThe codes below perform two processes.\n\ntreemap() is used to build a treemap by using selected variables in condominium data.frame. The treemap created is save as object called tm\n\n\ntm &lt;- treemap(realis2018_summarised,\n        index=c(\"Planning Region\", \"Planning Area\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"value\",\n        title=\"Private Residential Property Sold, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\nThen d3tree() is used to build an interactive treemap.\n\n\n# d3tree(tm,rootname = \"Singapore\" )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#dotplotwith-y-axis",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#dotplotwith-y-axis",
    "title": "Hands-on Exercise 1: A Layered Grammar of Graphics: ggplot2 methods",
    "section": "4.1 Dotplot(with y-axis)",
    "text": "4.1 Dotplot(with y-axis)\n\n\nClick to view code\nggplot(data = exam_data,\n       aes(x = ENGLISH)) +\n  geom_dotplot(dotsize = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#dotplotturn-off-y-axis",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#dotplotturn-off-y-axis",
    "title": "Hands-on Exercise 1: A Layered Grammar of Graphics: ggplot2 methods",
    "section": "4.2 Dotplot(turn-off y-axis)",
    "text": "4.2 Dotplot(turn-off y-axis)\n\n\nClick to view code\nggplot(data = exam_data,\n       aes(x = ENGLISH)) +\n  geom_dotplot(binwidth = 2.5,\n               dotsize = 0.5) +\n  scale_y_continuous(NULL,\n                     breaks = NULL)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#histogram-default-bin-is-30",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#histogram-default-bin-is-30",
    "title": "Hands-on Exercise 1: A Layered Grammar of Graphics: ggplot2 methods",
    "section": "4.3 Histogram (default bin is 30)",
    "text": "4.3 Histogram (default bin is 30)\n\n\nClick to view code\nggplot(data = exam_data,\n       aes(x = ENGLISH)) +\n  geom_histogram()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#histogram-changeing-geom",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#histogram-changeing-geom",
    "title": "Hands-on Exercise 1: A Layered Grammar of Graphics: ggplot2 methods",
    "section": "4.4 Histogram (changeing geom())",
    "text": "4.4 Histogram (changeing geom())\n\n\nClick to view code\nggplot(data = exam_data,\n       aes(x = ENGLISH)) +\n  geom_histogram(bins = 20,\n                 color = \"black\",\n                 fill = \"light blue\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#histogram-changeing-aes",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#histogram-changeing-aes",
    "title": "Hands-on Exercise 1: A Layered Grammar of Graphics: ggplot2 methods",
    "section": "4.5 Histogram (changeing aes())",
    "text": "4.5 Histogram (changeing aes())\n\n\nClick to view code\nggplot(data = exam_data,\n       aes(x = ENGLISH,\n           fill = GENDER)) +\n  geom_histogram(bins = 20,\n                 color = \"grey30\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#density",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#density",
    "title": "Hands-on Exercise 1: A Layered Grammar of Graphics: ggplot2 methods",
    "section": "4.6 Density",
    "text": "4.6 Density\n\n\nClick to view code\nggplot(data = exam_data,\n       aes(x = ENGLISH,\n           color = CLASS)) +\n  geom_density()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#boxplot-with-notch",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#boxplot-with-notch",
    "title": "Hands-on Exercise 1: A Layered Grammar of Graphics: ggplot2 methods",
    "section": "4.7 Boxplot (with notch)",
    "text": "4.7 Boxplot (with notch)\n\n\nClick to view code\nggplot(data = exam_data,\n       aes(y = ENGLISH,\n           x = GENDER)) +\n  geom_boxplot(notch = TRUE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#violin-comparing-multiple-data-distribution",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#violin-comparing-multiple-data-distribution",
    "title": "Hands-on Exercise 1: A Layered Grammar of Graphics: ggplot2 methods",
    "section": "4.8 Violin (Comparing multiple data distribution)",
    "text": "4.8 Violin (Comparing multiple data distribution)\n\n\nClick to view code\nggplot(data = exam_data,\n       aes(y = ENGLISH,\n           x = GENDER)) +\n  geom_violin()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#point",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#point",
    "title": "Hands-on Exercise 1: A Layered Grammar of Graphics: ggplot2 methods",
    "section": "4.9 Point",
    "text": "4.9 Point\n\n\nClick to view code\nggplot(data = exam_data,\n       aes(x = ENGLISH,\n           y = MATHS)) +\n  geom_point()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#combine-jitter-refers-to-a-technique-used-to-add-small-random-bariation-to-data-points",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#combine-jitter-refers-to-a-technique-used-to-add-small-random-bariation-to-data-points",
    "title": "Hands-on Exercise 1: A Layered Grammar of Graphics: ggplot2 methods",
    "section": "4.10 Combine (“jitter” refers to a technique used to add small random bariation to data points)",
    "text": "4.10 Combine (“jitter” refers to a technique used to add small random bariation to data points)\n\n\nClick to view code\nggplot(data = exam_data,\n       aes(y = ENGLISH,\n           x = GENDER)) +\n  geom_boxplot() +\n  geom_point(position = \"jitter\",\n             size = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#stat-before",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#stat-before",
    "title": "Hands-on Exercise 1: A Layered Grammar of Graphics: ggplot2 methods",
    "section": "5.1 Stat (Before)",
    "text": "5.1 Stat (Before)\n\n\nClick to view code\nggplot(data = exam_data,\n       aes(y = ENGLISH, x = GENDER)) +\n  geom_boxplot()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#stat-after",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#stat-after",
    "title": "Hands-on Exercise 1: A Layered Grammar of Graphics: ggplot2 methods",
    "section": "5.2 Stat (After)",
    "text": "5.2 Stat (After)\n\n\nClick to view code\nggplot(data = exam_data,\n       aes(y = ENGLISH,\n           x = GENDER)) +\n  geom_boxplot() +\n  stat_summary(geom = \"point\",\n               fun.y = \"mean\",\n               colour = \"red\",\n               size = 4)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#add-curve-on-a-scatterplot",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#add-curve-on-a-scatterplot",
    "title": "Hands-on Exercise 1: A Layered Grammar of Graphics: ggplot2 methods",
    "section": "5.3 Add curve on a scatterplot",
    "text": "5.3 Add curve on a scatterplot\n\n\nClick to view code\nggplot(data = exam_data,\n       aes(y = ENGLISH, x = MATHS)) +\n  geom_point() +\n  geom_smooth(size = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#facet_wrap",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#facet_wrap",
    "title": "Hands-on Exercise 1: A Layered Grammar of Graphics: ggplot2 methods",
    "section": "5.4 Facet_wrap",
    "text": "5.4 Facet_wrap\n\n\nClick to view code\nggplot(data = exam_data,\n       aes(x = MATHS)) +\n  geom_histogram(bins = 20) +\n  facet_wrap(~ CLASS)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#facet_grid",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#facet_grid",
    "title": "Hands-on Exercise 1: A Layered Grammar of Graphics: ggplot2 methods",
    "section": "5.5 Facet_grid",
    "text": "5.5 Facet_grid\n\n\nClick to view code\nggplot(data = exam_data,\n       aes(x = MATHS)) +\n  geom_histogram(bins = 20) +\n  facet_grid(~ CLASS)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#before",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#before",
    "title": "Hands-on Exercise 1: A Layered Grammar of Graphics: ggplot2 methods",
    "section": "6.1 (before)",
    "text": "6.1 (before)\n\n\nClick to view code\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-coordinate-after",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-coordinate-after",
    "title": "Hands-on Exercise 1: A Layered Grammar of Graphics: ggplot2 methods",
    "section": "6.2 Working with coordinate (after)",
    "text": "6.2 Working with coordinate (after)\n\n\nClick to view code\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#changing-the-y--and-x-axis-range-before",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#changing-the-y--and-x-axis-range-before",
    "title": "Hands-on Exercise 1: A Layered Grammar of Graphics: ggplot2 methods",
    "section": "6.3 Changing the y- and x-axis range (before)",
    "text": "6.3 Changing the y- and x-axis range (before)\n\n\nClick to view code\nggplot(data = exam_data,\n       aes(x = MATHS, y = ENGLISH)) +\n  geom_point() +\n  geom_smooth(method = lm, size=0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#changing-the-y--and-x-axis-range-after",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#changing-the-y--and-x-axis-range-after",
    "title": "Hands-on Exercise 1: A Layered Grammar of Graphics: ggplot2 methods",
    "section": "6.4 Changing the y- and x-axis range (after)",
    "text": "6.4 Changing the y- and x-axis range (after)\n\n\nClick to view code\nggplot(data = exam_data,\n       aes(x = MATHS, y = ENGLISH)) +\n  geom_point() +\n  geom_smooth(method = lm, size=0.5) +\n  coord_cartesian(xlim = c(0,100),\n                  ylim = c(0,100))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#classic",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#classic",
    "title": "Hands-on Exercise 1: A Layered Grammar of Graphics: ggplot2 methods",
    "section": "7.1 Classic",
    "text": "7.1 Classic\n\n\nClick to view code\nggplot(data = exam_data,\n       aes(x = RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_classic()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#minimal",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#minimal",
    "title": "Hands-on Exercise 1: A Layered Grammar of Graphics: ggplot2 methods",
    "section": "7.2 Minimal",
    "text": "7.2 Minimal\n\n\nClick to view code\nggplot(data = exam_data,\n       aes(x = RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_minimal()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04(a)/Hands-on_Ex04(a).html",
    "href": "Hands-on_Ex/Hands-on_Ex04(a)/Hands-on_Ex04(a).html",
    "title": "Hands-on Exercise 4(a)",
    "section": "",
    "text": "In this hands-on exercise, you will gain hands-in experience on using:\n\nggstatsplot package to create visual graphics with rich statistical information\nperformance package to visualise model diagnostics, and\noarameters package to visualise model parameters"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04(a)/Hands-on_Ex04(a).html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex04(a)/Hands-on_Ex04(a).html#learning-outcome",
    "title": "Hands-on Exercise 4(a)",
    "section": "",
    "text": "In this hands-on exercise, you will gain hands-in experience on using:\n\nggstatsplot package to create visual graphics with rich statistical information\nperformance package to visualise model diagnostics, and\noarameters package to visualise model parameters"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04(a)/Hands-on_Ex04(a).html#visual-statistical-analysis-with-ggstatsplot",
    "href": "Hands-on_Ex/Hands-on_Ex04(a)/Hands-on_Ex04(a).html#visual-statistical-analysis-with-ggstatsplot",
    "title": "Hands-on Exercise 4(a)",
    "section": "2 Visual Statistical Analysis with ggstatsplot",
    "text": "2 Visual Statistical Analysis with ggstatsplot\nggstatsplot  is an extension of ggplot2 package for creating graphics with\ndetails from statistical tests included in the information-rich plots themselves."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04(a)/Hands-on_Ex04(a).html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex04(a)/Hands-on_Ex04(a).html#getting-started",
    "title": "Hands-on Exercise 4(a)",
    "section": "3 Getting started",
    "text": "3 Getting started\n\n3.1 Installing and launching R packages\nIn this exercise, ggstatsplot and tidyverse will be used.\n\n\nClick to view code\npacman::p_load(ggstatsplot, tidyverse, dplyr)\n\n\n\n\n3.2 Importing Data\n\n\n\n\n\n\nDoDoDo\n\n\n\nImporting Exam.csv data by using appropriate tidyverse package.\n\n\n\n\nClick to view code\nExam_data &lt;- read.csv(\"data/Exam_data.csv\")\nExam_data\n\n\n            ID CLASS GENDER    RACE ENGLISH MATHS SCIENCE\n1   Student321    3I   Male   Malay      21     9      15\n2   Student305    3I Female   Malay      24    22      16\n3   Student289    3H   Male Chinese      26    16      16\n4   Student227    3F   Male Chinese      27    77      31\n5   Student318    3I   Male   Malay      27    11      25\n6   Student306    3I Female   Malay      31    16      16\n7   Student313    3I   Male Chinese      31    21      25\n8   Student316    3I   Male   Malay      31    18      27\n9   Student312    3I   Male   Malay      33    19      15\n10  Student297    3H   Male  Indian      34    49      37\n11  Student314    3I   Male Chinese      34    39      42\n12  Student278    3H Female   Malay      36    35      22\n13  Student302    3I Female Chinese      36    23      32\n14  Student323    3I   Male Chinese      36    36      36\n15  Student296    3H   Male Chinese      37    49      35\n16  Student311    3I Female Chinese      38    30      45\n17  Student304    3I Female   Malay      39    21      21\n18  Student307    3I Female   Malay      39    24      35\n19  Student259    3G   Male   Malay      40    54      26\n20  Student273    3H Female   Malay      40    36      24\n21  Student292    3H   Male   Malay      40    40      31\n22  Student303    3I Female   Malay      40    20      32\n23  Student177    3E   Male Chinese      41    71      40\n24  Student253    3G   Male  Others      41    51      37\n25  Student294    3H   Male   Malay      41    32      26\n26  Student287    3H   Male   Malay      42    32      27\n27  Student293    3H   Male   Malay      42    37      23\n28  Student290    3H   Male   Malay      43    30      31\n29  Student295    3H   Male  Indian      43    35      38\n30  Student319    3I   Male  Indian      43    25      24\n31  Student309    3I Female   Malay      44    24      24\n32  Student315    3I   Male   Malay      44    19      35\n33  Student288    3H   Male Chinese      45    50      27\n34  Student301    3I Female   Malay      45    32      30\n35  Student248    3G   Male Chinese      46    55      17\n36  Student277    3H Female   Malay      46    31      34\n37  Student171    3E Female Chinese      48    56      49\n38  Student324    3I   Male Chinese      48    41      41\n39  Student258    3G   Male   Malay      49    30      32\n40  Student282    3H Female Chinese      49    44      19\n41  Student298    3H   Male   Malay      49    41      32\n42  Student317    3I   Male   Malay      49    34      31\n43  Student276    3H Female   Malay      50    35      40\n44  Student286    3H   Male   Malay      50    56      36\n45  Student310    3I Female   Malay      50    58      50\n46  Student215    3F Female Chinese      51    74      54\n47  Student200    3F Female Chinese      52    71      47\n48  Student202    3F Female Chinese      52    55      39\n49  Student264    3G   Male  Indian      52    42      16\n50  Student322    3I   Male   Malay      52    58      41\n51  Student117    3C   Male Chinese      53    90      46\n52  Student199    3F Female Chinese      53    77      57\n53  Student251    3G   Male Chinese      53    51      45\n54  Student320    3I   Male   Malay      53    25      48\n55  Student188    3E   Male Chinese      54    65      40\n56  Student231    3F   Male Chinese      54    78      60\n57  Student255    3G   Male Chinese      54    54      32\n58  Student262    3G   Male   Malay      54    59      45\n59  Student265    3G   Male Chinese      54    38      46\n60  Student271    3H Female Chinese      54    52      52\n61  Student272    3H Female   Malay      54    33      37\n62  Student279    3H Female  Indian      54    48      53\n63  Student283    3H Female   Malay      55    43      45\n64  Student284    3H Female Chinese      55    56      45\n65  Student241    3G Female   Malay      56    52      57\n66  Student261    3G   Male   Malay      56    37      34\n67  Student291    3H   Male   Malay      56    44      46\n68  Student299    3H   Male   Malay      56    52      59\n69  Student198    3F Female Chinese      57    74      62\n70  Student201    3F Female Chinese      57    67      67\n71  Student212    3F Female   Malay      57    63      55\n72  Student226    3F   Male   Malay      57    75      58\n73  Student240    3G Female   Malay      57    49      45\n74  Student266    3G Female Chinese      57    47      64\n75  Student274    3H Female   Malay      57    50      39\n76  Student179    3E   Male Chinese      58    69      57\n77  Student185    3E   Male   Malay      58    78      66\n78  Student224    3F   Male   Malay      58    64      60\n79  Student280    3H Female   Malay      58    47      47\n80  Student281    3H Female  Indian      58    40      46\n81  Student163    3E Female   Malay      59    58      36\n82  Student225    3F   Male   Malay      59    74      45\n83  Student115    3C   Male Chinese      60    72      52\n84  Student203    3F Female Chinese      60    75      61\n85  Student246    3G Female   Malay      60    43      44\n86  Student263    3G   Male  Indian      60    68      63\n87  Student082    3C Female Chinese      61    85      68\n88  Student114    3C   Male Chinese      61    79      50\n89  Student119    3D Female Chinese      61    62      49\n90  Student191    3E   Male Chinese      61    88      52\n91  Student206    3F Female   Malay      61    62      55\n92  Student219    3F   Male   Malay      61    63      60\n93  Student244    3G Female   Malay      61    58      46\n94  Student269    3H Female Chinese      61    52      46\n95  Student186    3E   Male Chinese      62    85      74\n96  Student189    3E   Male Chinese      62    58      59\n97  Student210    3F Female Chinese      62    74      68\n98  Student221    3F   Male   Malay      62    58      58\n99  Student245    3G Female   Malay      62    45      52\n100 Student260    3G   Male   Malay      62    79      57\n101 Student085    3C Female Chinese      63    64      49\n102 Student106    3C   Male Chinese      63    84      44\n103 Student148    3D   Male Chinese      63    74      63\n104 Student220    3F   Male Chinese      63    71      64\n105 Student235    3G Female   Malay      63    50      48\n106 Student270    3H Female Chinese      63    70      53\n107 Student285    3H Female Chinese      63    46      50\n108 Student300    3H Female  Others      63    67      65\n109 Student141    3D   Male  Indian      64    78      76\n110 Student157    3E Female Chinese      64    66      67\n111 Student175    3E   Male   Malay      64    66      54\n112 Student176    3E   Male Chinese      64    64      49\n113 Student184    3E   Male   Malay      64    65      63\n114 Student209    3F Female   Malay      64    69      55\n115 Student252    3G   Male Chinese      64    36      41\n116 Student275    3H Female   Malay      64    54      54\n117 Student098    3C   Male Chinese      65    90      63\n118 Student105    3C   Male Chinese      65    80      73\n119 Student155    3D   Male Chinese      65    68      66\n120 Student156    3E Female Chinese      65    78      65\n121 Student167    3E Female   Malay      65    79      51\n122 Student228    3F   Male   Malay      65    65      60\n123 Student234    3G Female   Malay      65    49      41\n124 Student238    3G Female Chinese      65    81      78\n125 Student133    3D Female   Malay      66    76      56\n126 Student162    3E Female   Malay      66    61      56\n127 Student180    3E   Male Chinese      66    71      72\n128 Student197    3F Female Chinese      66    72      61\n129 Student208    3F Female   Malay      66    64      69\n130 Student213    3F Female   Malay      66    70      61\n131 Student218    3F   Male Chinese      66    63      64\n132 Student229    3F   Male Chinese      66    80      74\n133 Student242    3G Female Chinese      66    63      50\n134 Student256    3G   Male   Malay      66    64      61\n135 Student112    3C   Male Chinese      67    73      54\n136 Student140    3D   Male Chinese      67    86      76\n137 Student183    3E   Male   Malay      67    72      63\n138 Student211    3F Female  Others      67    70      68\n139 Student223    3F   Male   Malay      67    68      59\n140 Student232    3F Female Chinese      67    95      84\n141 Student233    3F Female Chinese      67    80      56\n142 Student243    3G Female   Malay      67    53      44\n143 Student249    3G   Male Chinese      67    81      74\n144 Student254    3G   Male Chinese      67    74      59\n145 Student026    3A   Male Chinese      68    87      66\n146 Student097    3C   Male   Malay      68    63      50\n147 Student116    3C   Male Chinese      68    79      77\n148 Student145    3D   Male Chinese      68    83      65\n149 Student159    3E Female   Malay      68    74      58\n150 Student190    3E   Male  Others      68    67      59\n151 Student207    3F Female   Malay      68    69      65\n152 Student250    3G   Male Chinese      68    60      59\n153 Student268    3H Female   Malay      68    61      64\n154 Student204    3F Female   Malay      69    75      54\n155 Student216    3F Female Chinese      69    67      69\n156 Student247    3G Female Chinese      69    62      58\n157 Student257    3G   Male   Malay      69    44      50\n158 Student021    3A   Male Chinese      70    90      72\n159 Student126    3D Female  Others      70    70      68\n160 Student192    3E   Male   Malay      70    66      63\n161 Student205    3F Female   Malay      70    70      58\n162 Student230    3F   Male   Malay      70    84      73\n163 Student237    3G Female   Malay      70    63      42\n164 Student048    3B Female Chinese      71    82      72\n165 Student096    3C   Male   Malay      71    65      57\n166 Student100    3C   Male Chinese      71    82      72\n167 Student103    3C   Male Chinese      71    75      52\n168 Student131    3D Female  Others      71    75      74\n169 Student161    3E Female   Malay      71    79      68\n170 Student173    3E Female Chinese      71    89      83\n171 Student182    3E   Male Chinese      71    77      72\n172 Student217    3F   Male Chinese      71    74      68\n173 Student267    3G Female Chinese      71    63      58\n174 Student020    3A Female Chinese      72    91      77\n175 Student073    3B   Male Chinese      72    83      69\n176 Student079    3C Female Chinese      72    60      37\n177 Student132    3D Female Chinese      72    71      61\n178 Student136    3D   Male Chinese      72    96      77\n179 Student147    3D   Male Chinese      72    79      79\n180 Student151    3D   Male Chinese      72    74      78\n181 Student168    3E Female   Malay      72    52      55\n182 Student025    3A   Male Chinese      73    91      74\n183 Student046    3B Female Chinese      73    65      75\n184 Student087    3C Female Chinese      73    85      71\n185 Student089    3C Female Chinese      73    74      68\n186 Student090    3C Female Chinese      73    73      69\n187 Student094    3C Female Chinese      73    69      62\n188 Student099    3C   Male Chinese      73    79      74\n189 Student111    3C   Male   Malay      73    66      53\n190 Student118    3D Female Chinese      73    81      65\n191 Student120    3D Female Chinese      73    72      70\n192 Student122    3D Female Chinese      73    77      76\n193 Student143    3D   Male Chinese      73    74      72\n194 Student146    3D   Male Chinese      73    79      66\n195 Student150    3D   Male   Malay      73    85      71\n196 Student153    3D   Male Chinese      73    83      74\n197 Student170    3E Female  Indian      73    83      57\n198 Student174    3E   Male   Malay      73    75      69\n199 Student181    3E   Male Chinese      73    77      68\n200 Student214    3F Female Chinese      73    82      62\n201 Student088    3C Female Chinese      74    88      72\n202 Student101    3C   Male Chinese      74    75      80\n203 Student113    3C   Male Chinese      74    78      71\n204 Student137    3D   Male Chinese      74    86      77\n205 Student139    3D   Male Chinese      74    87      65\n206 Student158    3E Female Chinese      74    82      75\n207 Student169    3E Female Chinese      74    59      61\n208 Student236    3G Female Chinese      74    60      46\n209 Student067    3B   Male Chinese      75    84      80\n210 Student074    3B   Male Chinese      75    83      75\n211 Student093    3C Female Chinese      75    85      71\n212 Student110    3C   Male   Malay      75    76      72\n213 Student154    3D   Male Chinese      75    58      67\n214 Student178    3E   Male Chinese      75    68      64\n215 Student195    3F Female Chinese      75    70      73\n216 Student011    3A Female Chinese      76    91      74\n217 Student024    3A   Male Chinese      76    88      72\n218 Student035    3A   Male Chinese      76    89      71\n219 Student083    3C Female   Malay      76    75      63\n220 Student124    3D Female Chinese      76    67      53\n221 Student165    3E Female Chinese      76    82      67\n222 Student166    3E Female Chinese      76    80      75\n223 Student172    3E Female Chinese      76    71      62\n224 Student187    3E   Male Chinese      76    88      71\n225 Student053    3B Female Chinese      77    79      77\n226 Student054    3B Female Chinese      77    85      78\n227 Student063    3B Female Chinese      77    69      72\n228 Student068    3B   Male Chinese      77    93      82\n229 Student072    3B   Male Chinese      77    79      76\n230 Student104    3C   Male Chinese      77    91      72\n231 Student109    3C   Male   Malay      77    81      69\n232 Student125    3D Female Chinese      77    85      78\n233 Student129    3D Female Chinese      77    80      66\n234 Student134    3D Female Chinese      77    74      67\n235 Student142    3D   Male Chinese      77    89      80\n236 Student164    3E Female   Malay      77    54      68\n237 Student194    3E Female Chinese      77    78      72\n238 Student196    3F Female Chinese      77    80      69\n239 Student222    3F   Male   Malay      77    77      72\n240 Student006    3A Female Chinese      78    75      70\n241 Student032    3A   Male   Malay      78    85      84\n242 Student045    3B Female   Malay      78    83      65\n243 Student070    3B   Male   Malay      78    95      70\n244 Student092    3C Female Chinese      78    86      84\n245 Student108    3C   Male Chinese      78    78      70\n246 Student138    3D   Male  Indian      78    78      65\n247 Student149    3D   Male   Malay      78    83      79\n248 Student152    3D   Male  Others      78    61      74\n249 Student160    3E Female   Malay      78    71      49\n250 Student019    3A Female Chinese      79    77      70\n251 Student023    3A   Male Chinese      79    94      79\n252 Student028    3A   Male Chinese      79    90      80\n253 Student065    3B Female Chinese      79    91      85\n254 Student069    3B   Male Chinese      79    86      81\n255 Student080    3C Female   Malay      79    73      58\n256 Student086    3C Female   Malay      79    79      69\n257 Student091    3C Female Chinese      79    82      61\n258 Student095    3C Female Chinese      79    86      75\n259 Student107    3C   Male Chinese      79    92      61\n260 Student144    3D   Male Chinese      79    86      77\n261 Student004    3A Female Chinese      80    89      73\n262 Student034    3A   Male Chinese      80    88      78\n263 Student055    3B Female Chinese      80    89      85\n264 Student060    3B Female   Malay      80    79      77\n265 Student078    3B Female Chinese      80    97      83\n266 Student081    3C Female Chinese      80    76      69\n267 Student239    3G Female   Malay      80    56      52\n268 Student005    3A Female Chinese      81    79      62\n269 Student052    3B Female Chinese      81    85      82\n270 Student062    3B Female   Malay      81    87      81\n271 Student102    3C   Male Chinese      81    78      70\n272 Student121    3D Female   Malay      81    82      71\n273 Student123    3D Female Chinese      81    74      70\n274 Student128    3D Female  Others      81    76      70\n275 Student008    3A Female Chinese      82    78      82\n276 Student047    3B Female Chinese      82    86      78\n277 Student058    3B Female   Malay      82    81      65\n278 Student064    3B Female   Malay      82    87      78\n279 Student130    3D Female   Malay      82    80      67\n280 Student014    3A Female Chinese      83    93      84\n281 Student018    3A Female  Indian      83    90      83\n282 Student029    3A   Male Chinese      83    87      89\n283 Student050    3B Female Chinese      83    89      84\n284 Student066    3B   Male Chinese      83    97      88\n285 Student075    3B   Male Chinese      83    80      79\n286 Student084    3C Female Chinese      83    76      56\n287 Student127    3D Female   Malay      83    81      60\n288 Student003    3A Female Chinese      84    91      82\n289 Student037    3A   Male Chinese      84    91      74\n290 Student041    3B Female Chinese      84    85      78\n291 Student043    3B Female Chinese      84    97      88\n292 Student051    3B Female Chinese      84    83      70\n293 Student057    3B Female   Malay      84    90      80\n294 Student027    3A   Male Chinese      85    98      80\n295 Student031    3A   Male Chinese      85    91      78\n296 Student044    3B Female Chinese      85    92      84\n297 Student049    3B Female Chinese      85    86      83\n298 Student056    3B Female Chinese      85    86      77\n299 Student059    3B Female   Malay      85    74      75\n300 Student061    3B Female   Malay      85    87      79\n301 Student076    3B   Male Chinese      85    85      82\n302 Student135    3D Female Chinese      85    86      81\n303 Student001    3A Female Chinese      86    90      85\n304 Student033    3A   Male Chinese      86    95      84\n305 Student038    3A   Male Chinese      86    91      87\n306 Student071    3B   Male Chinese      86    91      88\n307 Student077    3B   Male Chinese      86    91      88\n308 Student009    3A Female Chinese      87    95      82\n309 Student022    3A   Male Chinese      87    90      91\n310 Student042    3B Female  Indian      87    92      81\n311 Student007    3A Female Chinese      88    91      86\n312 Student030    3A   Male Chinese      88    89      83\n313 Student040    3A Female   Malay      88    87      85\n314 Student039    3A   Male Chinese      89    97      90\n315 Student002    3A Female Chinese      90    93      89\n316 Student013    3A Female Chinese      90    97      90\n317 Student017    3A Female Chinese      90    85      89\n318 Student016    3A Female Chinese      91    95      91\n319 Student015    3A Female  Others      92    90      87\n320 Student010    3A Female Chinese      93    93      90\n321 Student012    3A Female Chinese      93    97      84\n322 Student036    3A   Male Chinese      96    99      96\n\n\n\n\n3.3 One-sample test: gghistostats() method\nIn the code chunk below, gghistostats() is used to to build an visual of one-sample test on English scores.\n\n\nClick to view code\nset.seed(1234)\n\ngghistostats(data = Exam_data,\n             x = ENGLISH,\n             type = \"bayes\",\n             test.value = 60,\n             xlab = \"English scores\")\n\n\n\n\n\n\n\n\n\n\n\n3.4 Unpacking the Bayes Factor\n\nA Bayes factor is the ratio of the likelihood of one particular hypothesis to the likelihood of another. It can be interpreted as a measure of the strength of evidence in favor of one theory among two competinf theories.\nThat’s because the Bayes factor gives us a way to evaluate the data in favor of a null hypothesis, and to use external information to do so. It tells us what the weight of the evidence os in favor of a given hypothesis.\nWhen we are comparing two hypotheses, H1(the alternate hypothesis) and H0 (the null hypothesis), the Bayes Factor is often written as B10, It can be defined mathematically as:\nThe Schwarz criterion is one of the easiest ways to calculate rough approximation of the Bayes Factor.\n\n\n\n3.5 How to interpret Bayes Factor\nA Bayes Factor can be any positive number. One of the most common interpretations is this one—first proposed by Harold Jeffereys (1961) and slightly modified by Lee and Wagenmakers in 2013:\n\n\n3.6 Two-sample mean test: ggbetweenstats()\nIn the code chunk below, ggbetweenstats() is used to build a visual for two-sample mean test of Maths scores by gender.\n\n\nClick to view code\nggbetweenstats(data = Exam_data,\n               x = GENDER,\n               y = MATHS,\n               type = \"np\",\n               message = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n3.7 Onewat ANOVA Test: ggbetweenstats() method\nIn the code chunk below, ggbetweenstats() is used to build a visual for One-way ANOVA test on English score by race.\n\n\nClick to view code\nggbetweenstats(data = Exam_data,\n               x = RACE,\n               y = ENGLISH,\n               type = \"p\",\n               mean.ci = TRUE,\n               pairwise_comparisons = TRUE,\n               pairwise.display = \"s\",\n               p.adjust.method = \"fdr\",\n               messages = FALSE)\n\n\n\n\n\n\n\n\n\n\n3.7.1 ggbetweenstats - Summary of tests\n\n\n\n\n\n\n\n3.8 Significant Test of Correlation: ggscatterstats()\nIn the code chunk below, ggscatterstats() is used to build a visual for Significant Test of Correlation between Maths scores and English scores.\n\n\nClick to view code\nggscatterstats(data = Exam_data,\n               x = MATHS,\n               y = ENGLISH,\n               marginal = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n3.9 Significant Test of Association (Depedence) : ggbarstats() methods\nIn the code chunk below, the Maths scores is binned into a 4-class variable by using cut().\n\n\nClick to view code\nExam_data1 &lt;- Exam_data %&gt;%\n  mutate(MATHS_bins = cut(MATHS,\n                          breaks = c(0,60,75,85,100)))\n\n\nIn this code chunk below ggbarstats() is used to build a visual for Significant Test of Association\n\n\nClick to view code\nggbarstats(Exam_data1,\n           x = MATHS_bins,\n           y = GENDER)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04(a)/Hands-on_Ex04(a).html#visualising-models",
    "href": "Hands-on_Ex/Hands-on_Ex04(a)/Hands-on_Ex04(a).html#visualising-models",
    "title": "Hands-on Exercise 4(a)",
    "section": "4 Visualising Models",
    "text": "4 Visualising Models\nIn this section, you will learn how to visualise model diagnostic and model parameters by using parameters package.\n\nToyota Corolla case study will be used. The purpose of study is to build a model to discover factors affecting prices of used-cars by taking into consideration a set of explanatory variables."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04(a)/Hands-on_Ex04(a).html#getting-started-1",
    "href": "Hands-on_Ex/Hands-on_Ex04(a)/Hands-on_Ex04(a).html#getting-started-1",
    "title": "Hands-on Exercise 4(a)",
    "section": "5 Getting Started",
    "text": "5 Getting Started"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04(a)/Hands-on_Ex04(a).html#installing-and-loading-the-required-libraries",
    "href": "Hands-on_Ex/Hands-on_Ex04(a)/Hands-on_Ex04(a).html#installing-and-loading-the-required-libraries",
    "title": "Hands-on Exercise 4(a)",
    "section": "6 Installing and loading the required libraries",
    "text": "6 Installing and loading the required libraries\n\n\nClick to view code\npacman::p_load(readxl, performance, parameters, qqplort)\n\n\n\n6.1 Installing and loading the required libraries\nIn the code chunk below, read_xls() of readxl package is used to import the data worksheet of ToyotaCorolla.xls workbook into R.\n\n\nClick to view code\ncar_resale &lt;- read_xls(\"data/ToyotaCorolla.xls\",\n                       \"data\")\ncar_resale\n\n\n# A tibble: 1,436 × 38\n      Id Model    Price Age_08_04 Mfg_Month Mfg_Year     KM Quarterly_Tax Weight\n   &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt;\n 1    81 TOYOTA … 18950        25         8     2002  20019           100   1180\n 2     1 TOYOTA … 13500        23        10     2002  46986           210   1165\n 3     2 TOYOTA … 13750        23        10     2002  72937           210   1165\n 4     3  TOYOTA… 13950        24         9     2002  41711           210   1165\n 5     4 TOYOTA … 14950        26         7     2002  48000           210   1165\n 6     5 TOYOTA … 13750        30         3     2002  38500           210   1170\n 7     6 TOYOTA … 12950        32         1     2002  61000           210   1170\n 8     7  TOYOTA… 16900        27         6     2002  94612           210   1245\n 9     8 TOYOTA … 18600        30         3     2002  75889           210   1245\n10    44 TOYOTA … 16950        27         6     2002 110404           234   1255\n# ℹ 1,426 more rows\n# ℹ 29 more variables: Guarantee_Period &lt;dbl&gt;, HP_Bin &lt;chr&gt;, CC_bin &lt;chr&gt;,\n#   Doors &lt;dbl&gt;, Gears &lt;dbl&gt;, Cylinders &lt;dbl&gt;, Fuel_Type &lt;chr&gt;, Color &lt;chr&gt;,\n#   Met_Color &lt;dbl&gt;, Automatic &lt;dbl&gt;, Mfr_Guarantee &lt;dbl&gt;,\n#   BOVAG_Guarantee &lt;dbl&gt;, ABS &lt;dbl&gt;, Airbag_1 &lt;dbl&gt;, Airbag_2 &lt;dbl&gt;,\n#   Airco &lt;dbl&gt;, Automatic_airco &lt;dbl&gt;, Boardcomputer &lt;dbl&gt;, CD_Player &lt;dbl&gt;,\n#   Central_Lock &lt;dbl&gt;, Powered_Windows &lt;dbl&gt;, Power_Steering &lt;dbl&gt;, …\n\n\nNotice that the output object car_resale is a tibble data frame.\n\n\n6.2 Multiple Regression Model using lm()\nThe code chunk below is used to calibrate a multiple linear regression model by using lm() of Base Stats of R.\n\n\nClick to view code\nmodel &lt;- lm(Price ~ Age_08_04 + Mfg_Year + KM + \n              Weight + Guarantee_Period, data = car_resale)\nmodel\n\n\n\nCall:\nlm(formula = Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nCoefficients:\n     (Intercept)         Age_08_04          Mfg_Year                KM  \n      -2.637e+06        -1.409e+01         1.315e+03        -2.323e-02  \n          Weight  Guarantee_Period  \n       1.903e+01         2.770e+01  \n\n\n\n\n6.3 Model Diagnostic: checking for multicolinearity:\nIn the code chunk, check_collinearity() of performance package.\n\n\nClick to view code\ncheck_collinearity(model)\n\n\n# Check for Multicollinearity\n\nLow Correlation\n\n             Term  VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n               KM 1.46 [ 1.37,  1.57]         1.21      0.68     [0.64, 0.73]\n           Weight 1.41 [ 1.32,  1.51]         1.19      0.71     [0.66, 0.76]\n Guarantee_Period 1.04 [ 1.01,  1.17]         1.02      0.97     [0.86, 0.99]\n\nHigh Correlation\n\n      Term   VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n Age_08_04 31.07 [28.08, 34.38]         5.57      0.03     [0.03, 0.04]\n  Mfg_Year 31.16 [28.16, 34.48]         5.58      0.03     [0.03, 0.04]\n\n\n\n\nClick to view code\ncheck_c &lt;- check_collinearity(model)\nplot(check_c)\n\n\n\n\n\n\n\n\n\n\n\n6.4 Model Diagnostic: checking normality assumption\nIn the code chunk, check_normality() of performance package.\n\n\nClick to view code\nmodel1 &lt;- lm(Price ~ Age_08_04 + KM + Weight + Guarantee_Period,\n             data = car_resale)\n\n\n\n\nClick to view code\ncheck_n &lt;- check_normality(model1)\n\n\n\n\nClick to view code\nplot(check_n)\n\n\n\n\n\n\n\n\n\n\n\n6.5 Model Diagnostic: Check model for homogeneity of variances\nIn the code chunk, check_heteroscedasticity() of performance package.\n\n\nClick to view code\ncheck_h &lt;- check_heteroscedasticity(model1)\n\n\n\n\nClick to view code\nplot(check_h)\n\n\n\n\n\n\n\n\n\n\n\n6.6 Model Diagnostic: Complete check\nWe can also perform the complete by using check_model().\n\n\nClick to view code\ncheck_model(model1)\n\n\n\n\n\n\n\n\n\n\n\n6.7 Visualising Regression Parameters: see methods\nIn the code below, plot() of see package and parameters() of parameters package is used to visualise the parameters of a regression model.\n\n\nClick to view code\nplot(parameters(model1))\n\n\n\n\n\n\n\n\n\n\n\n6.8 Visualising Regression Parameters: ggcoefstats()methods\nIn the code below, ggcoefstats() of ggstatsplot package to visualise the parameters of a regression model.\n\n\nClick to view code\nggcoefstats(model1, \n            output = \"plot\")"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\nThis is about but no about"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "title": "Take-home_Ex03",
    "section": "",
    "text": "In this challenge, I will attempt to do the following:\n\n\nUse visual analytics to identify the relationship of entities\n\n\nBased on the visualization on Network, infer a network ownership or influence\n\n\n\n\n\n\n\n\nClick to view code\npacman::p_load(tidyverse, readtext, skimr, knitr,\n               quanteda, tidytext, jsonlite, dplyr,\n               tidyr, tidygraph, ggraph, igraph, lubridate,\n               visNetwork, ggplot2, gganimate, gridExtra)\n\n\n\n\n\n\n\n\n\n\nClick to view code\nmc3_data &lt;- fromJSON(\"data/MC3/mc3 1.json\")\nclass(mc3_data)\n\n\n[1] \"list\"\n\n\n\n\n\n\nEdgesNodes\n\n\n\n\nClick to view code\nmc3_edges &lt;- as_tibble(mc3_data$link)\nglimpse(mc3_edges)\n\n\nRows: 75,817\nColumns: 11\n$ start_date          &lt;chr&gt; \"2016-10-29T00:00:00\", \"2035-06-03T00:00:00\", \"202…\n$ type                &lt;chr&gt; \"Event.Owns.Shareholdership\", \"Event.Owns.Sharehol…\n$ `_last_edited_by`   &lt;chr&gt; \"Pelagia Alethea Mordoch\", \"Niklaus Oberon\", \"Pela…\n$ `_last_edited_date` &lt;chr&gt; \"2035-01-01T00:00:00\", \"2035-07-15T00:00:00\", \"203…\n$ `_date_added`       &lt;chr&gt; \"2035-01-01T00:00:00\", \"2035-07-15T00:00:00\", \"203…\n$ `_raw_source`       &lt;chr&gt; \"Existing Corporate Structure Data\", \"Oceanus Corp…\n$ `_algorithm`        &lt;chr&gt; \"Automatic Import\", \"Manual Entry\", \"Automatic Imp…\n$ source              &lt;chr&gt; \"Avery Inc\", \"Berger-Hayes\", \"Bowers Group\", \"Bowm…\n$ target              &lt;chr&gt; \"Allen, Nichols and Thompson\", \"Jensen, Morris and…\n$ key                 &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ end_date            &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n\n\n\n\n\n\nClick to view code\nmc3_nodes &lt;- as_tibble(mc3_data$nodes)\nglimpse(mc3_nodes)\n\n\nRows: 60,520\nColumns: 15\n$ type                &lt;chr&gt; \"Entity.Organization.Company\", \"Entity.Organizatio…\n$ country             &lt;chr&gt; \"Uziland\", \"Mawalara\", \"Uzifrica\", \"Islavaragon\", …\n$ ProductServices     &lt;chr&gt; \"Unknown\", \"Furniture and home accessories\", \"Food…\n$ PointOfContact      &lt;chr&gt; \"Rebecca Lewis\", \"Michael Lopez\", \"Steven Robertso…\n$ HeadOfOrg           &lt;chr&gt; \"Émilie-Susan Benoit\", \"Honoré Lemoine\", \"Jules La…\n$ founding_date       &lt;chr&gt; \"1954-04-24T00:00:00\", \"2009-06-12T00:00:00\", \"202…\n$ revenue             &lt;dbl&gt; 5994.73, 71766.67, 0.00, 0.00, 4746.67, 46566.67, …\n$ TradeDescription    &lt;chr&gt; \"Unknown\", \"Abbott-Gomez is a leading manufacturer…\n$ `_last_edited_by`   &lt;chr&gt; \"Pelagia Alethea Mordoch\", \"Pelagia Alethea Mordoc…\n$ `_last_edited_date` &lt;chr&gt; \"2035-01-01T00:00:00\", \"2035-01-01T00:00:00\", \"203…\n$ `_date_added`       &lt;chr&gt; \"2035-01-01T00:00:00\", \"2035-01-01T00:00:00\", \"203…\n$ `_raw_source`       &lt;chr&gt; \"Existing Corporate Structure Data\", \"Existing Cor…\n$ `_algorithm`        &lt;chr&gt; \"Automatic Import\", \"Automatic Import\", \"Automatic…\n$ id                  &lt;chr&gt; \"Abbott, Mcbride and Edwards\", \"Abbott-Gomez\", \"Ab…\n$ dob                 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n\n\n\n\n\n\n\n\n\nEdgesNodes\n\n\n\n\nClick to view code\n# Assume the end_data which is NA be filled by 2035-12-12\nmc3_edges_add &lt;- mc3_edges %&gt;%\n  mutate(\n    start_date = as.Date(start_date, format = \"%Y-%m-%d\"),\n    end_date = as.Date(ifelse(is.na(end_date), \"2035-12-12\", as.character(end_date)), format = \"%Y-%m-%d\")\n  ) %&gt;%\n  filter(!is.na(start_date))\n\n# Display the modified dataset\nglimpse(mc3_edges_add)\n\n\nRows: 75,727\nColumns: 11\n$ start_date          &lt;date&gt; 2016-10-29, 2035-06-03, 2028-11-20, 2024-09-04, 2…\n$ type                &lt;chr&gt; \"Event.Owns.Shareholdership\", \"Event.Owns.Sharehol…\n$ `_last_edited_by`   &lt;chr&gt; \"Pelagia Alethea Mordoch\", \"Niklaus Oberon\", \"Pela…\n$ `_last_edited_date` &lt;chr&gt; \"2035-01-01T00:00:00\", \"2035-07-15T00:00:00\", \"203…\n$ `_date_added`       &lt;chr&gt; \"2035-01-01T00:00:00\", \"2035-07-15T00:00:00\", \"203…\n$ `_raw_source`       &lt;chr&gt; \"Existing Corporate Structure Data\", \"Oceanus Corp…\n$ `_algorithm`        &lt;chr&gt; \"Automatic Import\", \"Manual Entry\", \"Automatic Imp…\n$ source              &lt;chr&gt; \"Avery Inc\", \"Berger-Hayes\", \"Bowers Group\", \"Bowm…\n$ target              &lt;chr&gt; \"Allen, Nichols and Thompson\", \"Jensen, Morris and…\n$ key                 &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ end_date            &lt;date&gt; 2035-12-12, 2035-12-12, 2035-12-12, 2035-12-12, 2…\n\n\n\n\nClick to view code\nmc3_edges_filt &lt;- mc3_edges_add %&gt;% select(type, source, target, start_date, end_date)\nglimpse(mc3_edges_filt)\n\n\nRows: 75,727\nColumns: 5\n$ type       &lt;chr&gt; \"Event.Owns.Shareholdership\", \"Event.Owns.Shareholdership\",…\n$ source     &lt;chr&gt; \"Avery Inc\", \"Berger-Hayes\", \"Bowers Group\", \"Bowman-Howe\",…\n$ target     &lt;chr&gt; \"Allen, Nichols and Thompson\", \"Jensen, Morris and Downs\", …\n$ start_date &lt;date&gt; 2016-10-29, 2035-06-03, 2028-11-20, 2024-09-04, 2034-11-12…\n$ end_date   &lt;date&gt; 2035-12-12, 2035-12-12, 2035-12-12, 2035-12-12, 2035-12-12…\n\n\n\n\n\n\nClick to view code\nmc3_nodes_filt &lt;- mc3_nodes %&gt;% select(type, id, country)\nglimpse(mc3_nodes_filt)\n\n\nRows: 60,520\nColumns: 3\n$ type    &lt;chr&gt; \"Entity.Organization.Company\", \"Entity.Organization.Company\", …\n$ id      &lt;chr&gt; \"Abbott, Mcbride and Edwards\", \"Abbott-Gomez\", \"Abbott-Harriso…\n$ country &lt;chr&gt; \"Uziland\", \"Mawalara\", \"Uzifrica\", \"Islavaragon\", \"Oceanus\", \"…\n\n\n\n\n\n\n\n\n\nEdgesNodes\n\n\n\n\nClick to view code\nskim(mc3_edges_filt)\n\n\n\nData summary\n\n\nName\nmc3_edges_filt\n\n\nNumber of rows\n75727\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n3\n\n\nDate\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\ntype\n0\n1\n14\n31\n0\n4\n0\n\n\nsource\n0\n1\n6\n42\n0\n51995\n0\n\n\ntarget\n0\n1\n6\n48\n0\n8872\n0\n\n\n\nVariable type: Date\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\nstart_date\n0\n1\n1952-05-31\n2035-12-29\n2023-12-12\n11468\n\n\nend_date\n0\n1\n2035-01-01\n2035-12-29\n2035-12-12\n73\n\n\n\n\n\n\n\nClick to view code\np1 &lt;- ggplot(data = mc3_edges_filt, aes(x = type, fill = type)) +\n  geom_bar() + theme(axis.text.x = element_text(angle = 60, hjust = 1))\np1\n\n\n\n\n\n\n\n\n\n\n\n\n\nClick to view code\nskim(mc3_nodes_filt)\n\n\n\nData summary\n\n\nName\nmc3_nodes_filt\n\n\nNumber of rows\n60520\n\n\nNumber of columns\n3\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\ntype\n0\n1\n13\n36\n0\n8\n0\n\n\nid\n0\n1\n6\n48\n0\n60520\n0\n\n\ncountry\n0\n1\n4\n15\n0\n86\n0\n\n\n\n\n\n\n\nClick to view code\np2 &lt;- ggplot(data = mc3_nodes_filt, aes(x = type, fill = type)) +\n  geom_bar() + theme(axis.text.x = element_text(angle = 60, hjust = 1))\np2 \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nAccording to the VAST2024 - MC3 Data Description, the person node include Entity.Person and Entity.Person.CEO, the other were included in the Company.\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nBased on this plot, the edge date will be used, and the company name to define company; Meanwhile, the type in node will be used, source and target will be choosed to decide the “from” and “to”.\n\n\n\n\n\n3.1.1 Nodes3.1.2 Edges\n\n\nThe code chunk below will be used to extract the nodes data.frame of mc3_data and save it as a tibble data.frame called mc3_nodes.\n\n\nClick to view code\n# Clean and select columns from mc3_data$nodes\nmc3_nodes_clean &lt;- as_tibble(mc3_nodes_filt) %&gt;%\n  mutate(type = type,\n         id = id) %&gt;%\n  select(id, type) %&gt;%\n  separate(type, into = c(\"prefix\", \"supertype\", \"subtype\"), sep = \"\\\\.\", extra = \"merge\", fill = \"right\") %&gt;%\n  select(id, supertype, subtype)\n\nkable(head(mc3_nodes_clean))\n\n\n\n\n\nid\nsupertype\nsubtype\n\n\n\n\nAbbott, Mcbride and Edwards\nOrganization\nCompany\n\n\nAbbott-Gomez\nOrganization\nCompany\n\n\nAbbott-Harrison\nOrganization\nCompany\n\n\nAbbott-Ibarra\nOrganization\nCompany\n\n\nAbbott-Sullivan\nOrganization\nCompany\n\n\nAcevedo and Sons\nOrganization\nCompany\n\n\n\n\n\n\n\nThe code chunk below will be used to extract the links data.frame of mc3_data and save it as a tibble data.frame called mc3_edges.\n\n\nClick to view code\nmc3_edges_clean &lt;- as_tibble(mc3_edges_filt) %&gt;% \n  mutate(\n    start_date = as_datetime(start_date),\n    end_date = as_datetime(end_date)\n    ) %&gt;%\n  group_by(source, target, type, start_date, end_date) %&gt;%\n    summarise(weights = n(), .groups = 'drop') %&gt;%\n  filter(source != target) %&gt;%\n  ungroup()\nkable(head(mc3_edges_clean))\n\n\n\n\n\n\n\n\n\n\n\n\n\nsource\ntarget\ntype\nstart_date\nend_date\nweights\n\n\n\n\n4. SeaCargo Ges.m.b.H.\nDry CreekRybachit Marine A/S\nEvent.Owns.Shareholdership\n2034-12-31\n2035-12-12\n1\n\n\n4. SeaCargo Ges.m.b.H.\nKambalaSea Freight Inc\nEvent.Owns.Shareholdership\n2033-04-12\n2035-12-12\n1\n\n\n9. RiverLine CJSC\nSumacAmerica Transport GmbH & Co. KG\nEvent.Owns.Shareholdership\n2028-12-02\n2035-12-12\n1\n\n\nAaron Acosta\nManning-Pratt\nEvent.Owns.Shareholdership\n2008-09-14\n2035-12-12\n1\n\n\nAaron Acosta\nManning-Pratt\nEvent.WorksFor\n2008-07-30\n2035-12-12\n1\n\n\nAaron Allen\nHicks-Calderon\nEvent.Owns.BeneficialOwnership\n2025-03-06\n2035-12-12\n1\n\n\n\n\n\n\n\n\nLet’s focuse on the SouthSeafood Express Corp\n\nneighbourSub-directOwnership\n\n\n\n\nClick to view code\n# Define the target node\ntarget_node &lt;- \"SouthSeafood Express Corp\"\n\n# Filter edges related to the target node\nrelated_edges &lt;- mc3_edges_clean %&gt;%\n  filter(source == target_node | target == target_node) %&gt;%\n  rename(from = source, to = target)\n\n# Extract the related nodes\nrelated_nodes &lt;- mc3_nodes_clean %&gt;%\n  filter(id %in% c(related_edges$from, related_edges$to))\n\n\n# Create the visNetwork plot\nvisNetwork(related_nodes, related_edges) %&gt;%\n  visPhysics(solver = \"forceAtlas2Based\",\n             forceAtlas2Based = list(gravitationalConstant = -100)) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visGroups(groupname = \"Organization\", color = \"pink\") %&gt;%\n  visGroups(groupname = \"Person\", color = \"lightgreen\") %&gt;%\n  visLegend() %&gt;%\n  visEdges(arrows = \"to\") %&gt;%\n  visOptions(\n    highlightNearest = list(enabled = TRUE, degree = 2, hover = TRUE),\n    nodesIdSelection = TRUE,\n    selectedBy = \"subtype\",\n    collapse = TRUE\n  ) %&gt;%\n  visInteraction(dragNodes = TRUE, dragView = TRUE, zoomView = TRUE) %&gt;%\n  visEvents(selectNode = \"function(properties) {\n    var selectedNodeId = properties.nodes[0];\n    this.body.data.nodes.update({id: selectedNodeId, color: {background: 'red', border: 'black'}});\n  }\")\n\n\n\n\n\n\n\n\n\n\nClick to view code\n# Define the target node\ntarget_node &lt;- \"SouthSeafood Express Corp\"\n\n# Filter edges related to the target node\ninitial_edges &lt;- mc3_edges_clean %&gt;%\n  filter(source == target_node | target == target_node) %&gt;%\n  rename(from = source, to = target)\n\nconnected_nodes &lt;- mc3_nodes_clean %&gt;%\n  filter(id %in% c(initial_edges$from, initial_edges$to))\n\nexpanded_edges &lt;- mc3_edges_clean %&gt;%\n  filter(source %in% connected_nodes$id | target %in% connected_nodes$id) %&gt;%\n  rename(from = source, to = target)\n\n# Extract source and target nodes from expanded edges\nexpanded_nodes_source &lt;- expanded_edges %&gt;%\n  distinct(from) %&gt;%\n  rename(id = from)\n\nexpanded_nodes_target &lt;- expanded_edges %&gt;%\n  distinct(to) %&gt;%\n  rename(id = to)\n\n# Combine and deduplicate nodes\nexpanded_nodes_combined &lt;- bind_rows(expanded_nodes_source, expanded_nodes_target) %&gt;%\n  distinct(id) %&gt;%\n  left_join(mc3_nodes_clean, by = \"id\")\n\n# Assign group based on supertype\nexpanded_nodes_combined$group &lt;- ifelse(expanded_nodes_combined$supertype == \"Organization\", \"Organization\", \"Person\")\n\n\n# Create the visNetwork plot\nvisNetwork(expanded_nodes_combined, expanded_edges) %&gt;%\n  visPhysics(solver = \"forceAtlas2Based\",\n             forceAtlas2Based = list(gravitationalConstant = -100)) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visGroups(groupname = \"Organization\", color = \"pink\") %&gt;%\n  visGroups(groupname = \"Person\", color = \"lightgreen\") %&gt;%\n  visLegend() %&gt;%\n  visEdges(arrows = \"to\") %&gt;%\n  visOptions(\n    highlightNearest = list(enabled = TRUE, degree = 2, hover = TRUE),\n    nodesIdSelection = TRUE,\n    selectedBy = \"subtype\",\n    collapse = TRUE\n  ) %&gt;%\n  visInteraction(dragNodes = TRUE, dragView = TRUE, zoomView = TRUE) %&gt;%\n  visEvents(selectNode = \"function(properties) {\n    var selectedNodeId = properties.nodes[0];\n    this.body.data.nodes.update({id: selectedNodeId, color: {background: 'red', border: 'black'}});\n  }\")\n\n\n\n\n\n\n\n\n\n\nClick to view code\n# Identify nodes directly connected to the target node\nconnected_nodes &lt;- mc3_nodes_clean %&gt;%\n  filter(id %in% c(initial_edges$from, initial_edges$to))\n\nexpanded_edges &lt;- initial_edges\nexpanded_nodes &lt;- connected_nodes\n\nrepeat {\n  # Identify all nodes connected to the current set of nodes\n  new_edges &lt;- mc3_edges_clean %&gt;%\n    filter(source %in% expanded_nodes$id | target %in% expanded_nodes$id) %&gt;%\n    rename(from = source, to = target)\n  \n  # Identify new nodes from the newly found edges\n  new_nodes &lt;- mc3_nodes_clean %&gt;%\n    filter(id %in% c(new_edges$from, new_edges$to)) %&gt;%\n    filter(!id %in% expanded_nodes$id)\n  \n  # Add new edges and nodes to the expanded set\n  expanded_edges &lt;- bind_rows(expanded_edges, new_edges) %&gt;%\n    distinct()\n  expanded_nodes &lt;- bind_rows(expanded_nodes, new_nodes) %&gt;%\n    distinct()\n  \n  # Break the loop if there are no new nodes to add or all new nodes are of type \"Person\"\n  if (nrow(new_nodes) == 0 || all(new_nodes$supertype == \"Person\")) {\n    break\n  }\n}\n\n\n\n\nClick to view code\n# Extract source and target nodes from expanded edges\nexpanded_nodes_source &lt;- expanded_edges %&gt;%\n  distinct(from) %&gt;%\n  rename(id = from)\n\nexpanded_nodes_target &lt;- expanded_edges %&gt;%\n  distinct(to) %&gt;%\n  rename(id = to)\n\n# Combine and deduplicate nodes\nexpanded_nodes_combined &lt;- bind_rows(expanded_nodes_source, expanded_nodes_target) %&gt;%\n  distinct(id) %&gt;%\n  left_join(mc3_nodes_clean, by = \"id\")\n\n# Assign group based on supertype\nexpanded_nodes_combined$group &lt;- ifelse(expanded_nodes_combined$supertype == \"Organization\", \"Organization\", \"Person\")\n\n\n\n\nClick to view code\n# Create the visNetwork plot\nvisNetwork(expanded_nodes_combined, expanded_edges) %&gt;%\n  visPhysics(solver = \"forceAtlas2Based\",\n             forceAtlas2Based = list(gravitationalConstant = -100)) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visGroups(groupname = \"Organization\", color = \"pink\") %&gt;%\n  visGroups(groupname = \"Person\", color = \"lightgreen\") %&gt;%\n  visLegend() %&gt;%\n  visEdges(arrows = \"to\") %&gt;%\n  visOptions(\n    highlightNearest = list(enabled = TRUE, degree = 2, hover = TRUE),\n    nodesIdSelection = TRUE,\n    selectedBy = \"subtype\",\n    collapse = TRUE\n  ) %&gt;%\n  visInteraction(dragNodes = TRUE, dragView = TRUE, zoomView = TRUE) %&gt;%\n  visEvents(selectNode = \"function(properties) {\n    var selectedNodeId = properties.nodes[0];\n    this.body.data.nodes.update({id: selectedNodeId, color: {background: 'red', border: 'black'}});\n  }\")\n\n\n\n\n\n\n\n\n\n\n\n\nFirst, create a graph object using tbl_graph() function. Then calculate betweenness and closeness centrality scores.\n\n\nClick to view code\nmc3_graph &lt;- tbl_graph(nodes = mc3_nodes_clean,\n                       edges = mc3_edges_clean,\n                       directed = FALSE) %&gt;%\n  mutate(betweenness_centrality = centrality_betweenness(),\n         closeness_centrality = centrality_closeness())\n\n\nWe will filter nodes with high betweeness centrality scores (&gt;8,000,000) and visualise them to see the relationships that they have.\n\n\nClick to view code\nset.seed(1234)\nmc3_graph %&gt;%\n  filter(betweenness_centrality &gt; 8000000) %&gt;%\nggraph(layout = \"fr\") +\n  geom_edge_link(aes(alpha=0.5)) +\n  geom_node_point(aes(\n    size = betweenness_centrality,\n    color = supertype,\n    alpha = 0.3)) +\n  geom_node_label(aes(label = id),repel=TRUE, size=2.5, alpha = 0.8) +\n  scale_size_continuous(range=c(1,10)) +\n  theme_graph() +\n  labs(title = 'Initial network visualisation',\n       subtitle = 'Entities with betweenness scores &gt; 8,000,000')\n\n\n\n\n\n\n\n\n\nBelow is a dataframe showing us the top 10 entities with the highest betweenness scores.\n\n\nClick to view code\nmc3_graph %&gt;%  activate(nodes) %&gt;%  as_tibble() %&gt;% arrange(desc(betweenness_centrality)) %&gt;% slice(1:10) %&gt;% kable() \n\n\n\n\n\n\n\n\n\n\n\n\nid\nsupertype\nsubtype\nbetweenness_centrality\ncloseness_centrality\n\n\n\n\nSharon Moon\nPerson\nNA\n31170638\n3.6e-06\n\n\nSteven Robertson\nPerson\nNA\n28158072\n3.2e-06\n\n\nJohnson, Morales and Castro\nOrganization\nCompany\n26218503\n3.7e-06\n\n\nHart Ltd\nOrganization\nFinancialCompany\n26129255\n3.2e-06\n\n\nAbbott-Harrison\nOrganization\nCompany\n24206713\n3.0e-06\n\n\nPhelps, Montoya and Barnett\nOrganization\nCompany\n21073981\n3.0e-06\n\n\nMorrison-Zamora\nOrganization\nCompany\n20813895\n3.7e-06\n\n\nBlankenship-Strickland\nOrganization\nCompany\n20157207\n3.4e-06\n\n\nHolloway-Salas\nOrganization\nCompany\n19957178\n3.7e-06\n\n\nMichael Howard DDS\nPerson\nNA\n19922437\n3.5e-06\n\n\n\n\n\nThe top 10 betweenness entities above include 3 persons and 7 companies. In the next section, we will filter entities into only organization entities. We may revisit the person entities later when we have specific targets/companies to investigate.\n\n\n\n\nbefore 2033-10-29\nbetween 2033-10-29 and 2035-05-25\nafter 2035-05-25\n\n\n\nClick to view code\n# Time bins\nbin1 &lt;- mc3_edges_clean %&gt;%\n  filter(as.Date(start_date) &lt; as.Date(\"2033-10-29\"))\n\nbin2 &lt;- mc3_edges_clean %&gt;%\n  filter(as.Date(start_date) &gt;= as.Date(\"2033-10-29\") & as.Date(start_date) &lt;= as.Date(\"2035-05-25\"))\n\nbin3 &lt;- mc3_edges_clean %&gt;%\n  filter(as.Date(start_date) &gt; as.Date(\"2035-05-25\"))\n\n# Filter edges to include any that contain \"SouthSeafood\"\nsouthseafood_edges_bin1 &lt;- bin1 %&gt;%\n  filter(str_detect(source, \"SouthSeafood\") | str_detect(target, \"SouthSeafood\"))\n\nsouthseafood_edges_bin2 &lt;- bin2 %&gt;%\n  filter(str_detect(source, \"SouthSeafood\") | str_detect(target, \"SouthSeafood\"))\n\nsouthseafood_edges_bin3 &lt;- bin3 %&gt;%\n  filter(str_detect(source, \"SouthSeafood\") | str_detect(target, \"SouthSeafood\"))\n\nglimpse(southseafood_edges_bin1)\n\n\nRows: 0\nColumns: 6\n$ source     &lt;chr&gt; \n$ target     &lt;chr&gt; \n$ type       &lt;chr&gt; \n$ start_date &lt;dttm&gt; \n$ end_date   &lt;dttm&gt; \n$ weights    &lt;int&gt; \n\n\nClick to view code\nglimpse(southseafood_edges_bin2)\n\n\nRows: 2\nColumns: 6\n$ source     &lt;chr&gt; \"AguaLeska Transit N.V.\", \"Tainamarine Fishing Co\"\n$ target     &lt;chr&gt; \"SouthSeafood Express Corp\", \"SouthSeafood Express Corp\"\n$ type       &lt;chr&gt; \"Event.Owns.Shareholdership\", \"Event.Owns.Shareholdership\"\n$ start_date &lt;dttm&gt; 2033-10-29, 2035-05-25\n$ end_date   &lt;dttm&gt; 2035-05-25, 2035-12-12\n$ weights    &lt;int&gt; 1, 1\n\n\nClick to view code\nglimpse(southseafood_edges_bin3)\n\n\nRows: 0\nColumns: 6\n$ source     &lt;chr&gt; \n$ target     &lt;chr&gt; \n$ type       &lt;chr&gt; \n$ start_date &lt;dttm&gt; \n$ end_date   &lt;dttm&gt; \n$ weights    &lt;int&gt; \n\n\n\n\n\n\n\n\n\nClick to view code\n# Filter nodes to include only Organizations or Persons\nmc3_nodes_select &lt;- mc3_nodes_clean %&gt;%\n  filter(grepl(\"Organization|Person\", supertype, ignore.case = TRUE))\n\n\n\n\n\n\n\nClick to view code\nmc3_edges_select &lt;- mc3_edges_clean %&gt;%\n  filter(source %in% mc3_nodes_select$id | target %in% mc3_nodes_select$id) %&gt;%\n  distinct() %&gt;%\n  rename(from = source,\n         to = target)\n\n\n\n\n\n\n\nClick to view code\nmc3_edges_select_high &lt;- mc3_edges_select %&gt;%\n  group_by(from) %&gt;%\n  mutate(count = n()) %&gt;%\n  filter(count &gt;= 5) %&gt;%\n  ungroup()\n\n\n\n\n\n\n\nClick to view code\nmc3_nodes_source &lt;- mc3_edges_select_high %&gt;%\n  distinct(from) %&gt;%\n  rename(id = from)\n\nmc3_nodes_target &lt;- mc3_edges_select_high %&gt;%\n  distinct(to) %&gt;%\n  rename(id = to)\n\n\n\n\n\n\n\nClick to view code\n# Combine and deduplicate nodes\nmc3_nodes_combined &lt;- bind_rows(mc3_nodes_source, mc3_nodes_target) %&gt;%\n  distinct(id) %&gt;%\n  left_join(mc3_nodes_clean, by = \"id\")\n\n# Assign group based on supertype\nmc3_nodes_combined$group &lt;- ifelse(mc3_nodes_combined$supertype == \"Organization\", \"Organization\", \"Person\")\n\n# Visualize with visNetwork\nvisNetwork(mc3_nodes_combined, mc3_edges_select_high) %&gt;%\n  visPhysics(solver = \"forceAtlas2Based\",\n             forceAtlas2Based = list(gravitationalConstant = -100)) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visGroups(groupname = \"Organization\", color = \"yellow\") %&gt;%\n  visGroups(groupname = \"Person\", color = \"grey\") %&gt;%\n  visLegend() %&gt;%\n  visEdges(arrows = \"to\") %&gt;%\n  visOptions(\n    highlightNearest = list(enabled = TRUE, degree = 2, hover = TRUE),\n    nodesIdSelection = TRUE,\n    selectedBy = \"subtype\",\n    collapse = TRUE\n  ) %&gt;%\n  visInteraction(dragNodes = TRUE, dragView = TRUE, zoomView = TRUE) %&gt;%\n  visEvents(selectNode = \"function(properties) {\n    var selectedNodeId = properties.nodes[0];\n    this.body.data.nodes.update({id: selectedNodeId, color: {background: 'red', border: 'black'}});\n  }\")\n\n\n\n\n\n\n\n\n\nSince the SouthSeafood Express Corp connect first event from AguaLeska Transit N.V. in 2033-10-29, and turn to connect Tainamarine Fishing Co in 2035-05-25\n\nbefore 2033-10-29after 2035-05-25\n\n\n\n\nClick to view code\n# Filter edges based on date criteria\nmc3_edges_filtered_dates &lt;- mc3_edges_clean %&gt;%\n  filter(start_date &lt; as_datetime(\"2033-10-29\") & end_date &gt; as_datetime(\"2033-10-29\"))\n\n# Visualize with visNetwork\nvisNetwork(mc3_nodes_combined, mc3_edges_select_high) %&gt;%\n  visPhysics(solver = \"forceAtlas2Based\",\n             forceAtlas2Based = list(gravitationalConstant = -100)) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visGroups(groupname = \"Organization\", color = \"lightblue\") %&gt;%\n  visGroups(groupname = \"Person\", color = \"lightgreen\") %&gt;%\n  visLegend() %&gt;%\n  visEdges(arrows = \"to\") %&gt;%\n  visOptions(\n    highlightNearest = list(enabled = TRUE, degree = 2, hover = TRUE),\n    nodesIdSelection = TRUE,\n    selectedBy = \"subtype\",\n    collapse = TRUE\n  ) %&gt;%\n  visInteraction(dragNodes = TRUE, dragView = TRUE, zoomView = TRUE) %&gt;%\n  visEvents(selectNode = \"function(properties) {\n    var selectedNodeId = properties.nodes[0];\n    this.body.data.nodes.update({id: selectedNodeId, color: {background: 'red', border: 'black'}});\n  }\")\n\n\n\n\n\n\n\n\n\n\nClick to view code\nmc3_edges_filtered_dates &lt;- mc3_edges_clean %&gt;%\n  filter(end_date &gt; as_datetime(\"2035-05-25\"))\n\n\n# Visualize with visNetwork\nvisNetwork(mc3_nodes_combined, mc3_edges_select_high) %&gt;%\n  visPhysics(solver = \"forceAtlas2Based\",\n             forceAtlas2Based = list(gravitationalConstant = -100)) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visGroups(groupname = \"Organization\", color = \"lightblue\") %&gt;%\n  visGroups(groupname = \"Person\", color = \"lightgreen\") %&gt;%\n  visLegend() %&gt;%\n  visEdges(arrows = \"to\") %&gt;%\n  visOptions(\n    highlightNearest = list(enabled = TRUE, degree = 2, hover = TRUE),\n    nodesIdSelection = TRUE,\n    selectedBy = \"subtype\",\n    collapse = TRUE\n  ) %&gt;%\n  visInteraction(dragNodes = TRUE, dragView = TRUE, zoomView = TRUE) %&gt;%\n  visEvents(selectNode = \"function(properties) {\n    var selectedNodeId = properties.nodes[0];\n    this.body.data.nodes.update({id: selectedNodeId, color: {background: 'red', border: 'black'}});\n  }\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTo ensure the network associated with SouthSeafood Express Corp and visualize how this network and competing businesses change as a result of their illegal fishing behavior, an expand in timeline of visNetwork of the SouthSeafood is required.\n\n\n\n\nExploring the networks between the various type of nodes or players in the space has been useful to visualising the relationships between the different parties. It has yielded interesting insights on how certain companies may influence the around companies.\nFor future work, the additional column of timeline and financial situation can be used to provide an additional layer of to the overall visualisation of networks and information in this project."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#getting-start",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#getting-start",
    "title": "Take-home_Ex03",
    "section": "",
    "text": "Click to view code\npacman::p_load(tidyverse, readtext, skimr, knitr,\n               quanteda, tidytext, jsonlite, dplyr,\n               tidyr, tidygraph, ggraph, igraph, lubridate,\n               visNetwork, ggplot2, gganimate, gridExtra)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#data-wangling",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#data-wangling",
    "title": "Take-home_Ex03",
    "section": "",
    "text": "Click to view code\nmc3_data &lt;- fromJSON(\"data/MC3/mc3 1.json\")\nclass(mc3_data)\n\n\n[1] \"list\"\n\n\n\n\n\n\nEdgesNodes\n\n\n\n\nClick to view code\nmc3_edges &lt;- as_tibble(mc3_data$link)\nglimpse(mc3_edges)\n\n\nRows: 75,817\nColumns: 11\n$ start_date          &lt;chr&gt; \"2016-10-29T00:00:00\", \"2035-06-03T00:00:00\", \"202…\n$ type                &lt;chr&gt; \"Event.Owns.Shareholdership\", \"Event.Owns.Sharehol…\n$ `_last_edited_by`   &lt;chr&gt; \"Pelagia Alethea Mordoch\", \"Niklaus Oberon\", \"Pela…\n$ `_last_edited_date` &lt;chr&gt; \"2035-01-01T00:00:00\", \"2035-07-15T00:00:00\", \"203…\n$ `_date_added`       &lt;chr&gt; \"2035-01-01T00:00:00\", \"2035-07-15T00:00:00\", \"203…\n$ `_raw_source`       &lt;chr&gt; \"Existing Corporate Structure Data\", \"Oceanus Corp…\n$ `_algorithm`        &lt;chr&gt; \"Automatic Import\", \"Manual Entry\", \"Automatic Imp…\n$ source              &lt;chr&gt; \"Avery Inc\", \"Berger-Hayes\", \"Bowers Group\", \"Bowm…\n$ target              &lt;chr&gt; \"Allen, Nichols and Thompson\", \"Jensen, Morris and…\n$ key                 &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ end_date            &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n\n\n\n\n\n\nClick to view code\nmc3_nodes &lt;- as_tibble(mc3_data$nodes)\nglimpse(mc3_nodes)\n\n\nRows: 60,520\nColumns: 15\n$ type                &lt;chr&gt; \"Entity.Organization.Company\", \"Entity.Organizatio…\n$ country             &lt;chr&gt; \"Uziland\", \"Mawalara\", \"Uzifrica\", \"Islavaragon\", …\n$ ProductServices     &lt;chr&gt; \"Unknown\", \"Furniture and home accessories\", \"Food…\n$ PointOfContact      &lt;chr&gt; \"Rebecca Lewis\", \"Michael Lopez\", \"Steven Robertso…\n$ HeadOfOrg           &lt;chr&gt; \"Émilie-Susan Benoit\", \"Honoré Lemoine\", \"Jules La…\n$ founding_date       &lt;chr&gt; \"1954-04-24T00:00:00\", \"2009-06-12T00:00:00\", \"202…\n$ revenue             &lt;dbl&gt; 5994.73, 71766.67, 0.00, 0.00, 4746.67, 46566.67, …\n$ TradeDescription    &lt;chr&gt; \"Unknown\", \"Abbott-Gomez is a leading manufacturer…\n$ `_last_edited_by`   &lt;chr&gt; \"Pelagia Alethea Mordoch\", \"Pelagia Alethea Mordoc…\n$ `_last_edited_date` &lt;chr&gt; \"2035-01-01T00:00:00\", \"2035-01-01T00:00:00\", \"203…\n$ `_date_added`       &lt;chr&gt; \"2035-01-01T00:00:00\", \"2035-01-01T00:00:00\", \"203…\n$ `_raw_source`       &lt;chr&gt; \"Existing Corporate Structure Data\", \"Existing Cor…\n$ `_algorithm`        &lt;chr&gt; \"Automatic Import\", \"Automatic Import\", \"Automatic…\n$ id                  &lt;chr&gt; \"Abbott, Mcbride and Edwards\", \"Abbott-Gomez\", \"Ab…\n$ dob                 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n\n\n\n\n\n\n\n\n\nEdgesNodes\n\n\n\n\nClick to view code\n# Assume the end_data which is NA be filled by 2035-12-12\nmc3_edges_add &lt;- mc3_edges %&gt;%\n  mutate(\n    start_date = as.Date(start_date, format = \"%Y-%m-%d\"),\n    end_date = as.Date(ifelse(is.na(end_date), \"2035-12-12\", as.character(end_date)), format = \"%Y-%m-%d\")\n  ) %&gt;%\n  filter(!is.na(start_date))\n\n# Display the modified dataset\nglimpse(mc3_edges_add)\n\n\nRows: 75,727\nColumns: 11\n$ start_date          &lt;date&gt; 2016-10-29, 2035-06-03, 2028-11-20, 2024-09-04, 2…\n$ type                &lt;chr&gt; \"Event.Owns.Shareholdership\", \"Event.Owns.Sharehol…\n$ `_last_edited_by`   &lt;chr&gt; \"Pelagia Alethea Mordoch\", \"Niklaus Oberon\", \"Pela…\n$ `_last_edited_date` &lt;chr&gt; \"2035-01-01T00:00:00\", \"2035-07-15T00:00:00\", \"203…\n$ `_date_added`       &lt;chr&gt; \"2035-01-01T00:00:00\", \"2035-07-15T00:00:00\", \"203…\n$ `_raw_source`       &lt;chr&gt; \"Existing Corporate Structure Data\", \"Oceanus Corp…\n$ `_algorithm`        &lt;chr&gt; \"Automatic Import\", \"Manual Entry\", \"Automatic Imp…\n$ source              &lt;chr&gt; \"Avery Inc\", \"Berger-Hayes\", \"Bowers Group\", \"Bowm…\n$ target              &lt;chr&gt; \"Allen, Nichols and Thompson\", \"Jensen, Morris and…\n$ key                 &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ end_date            &lt;date&gt; 2035-12-12, 2035-12-12, 2035-12-12, 2035-12-12, 2…\n\n\n\n\nClick to view code\nmc3_edges_filt &lt;- mc3_edges_add %&gt;% select(type, source, target, start_date, end_date)\nglimpse(mc3_edges_filt)\n\n\nRows: 75,727\nColumns: 5\n$ type       &lt;chr&gt; \"Event.Owns.Shareholdership\", \"Event.Owns.Shareholdership\",…\n$ source     &lt;chr&gt; \"Avery Inc\", \"Berger-Hayes\", \"Bowers Group\", \"Bowman-Howe\",…\n$ target     &lt;chr&gt; \"Allen, Nichols and Thompson\", \"Jensen, Morris and Downs\", …\n$ start_date &lt;date&gt; 2016-10-29, 2035-06-03, 2028-11-20, 2024-09-04, 2034-11-12…\n$ end_date   &lt;date&gt; 2035-12-12, 2035-12-12, 2035-12-12, 2035-12-12, 2035-12-12…\n\n\n\n\n\n\nClick to view code\nmc3_nodes_filt &lt;- mc3_nodes %&gt;% select(type, id, country)\nglimpse(mc3_nodes_filt)\n\n\nRows: 60,520\nColumns: 3\n$ type    &lt;chr&gt; \"Entity.Organization.Company\", \"Entity.Organization.Company\", …\n$ id      &lt;chr&gt; \"Abbott, Mcbride and Edwards\", \"Abbott-Gomez\", \"Abbott-Harriso…\n$ country &lt;chr&gt; \"Uziland\", \"Mawalara\", \"Uzifrica\", \"Islavaragon\", \"Oceanus\", \"…\n\n\n\n\n\n\n\n\n\nEdgesNodes\n\n\n\n\nClick to view code\nskim(mc3_edges_filt)\n\n\n\nData summary\n\n\nName\nmc3_edges_filt\n\n\nNumber of rows\n75727\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n3\n\n\nDate\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\ntype\n0\n1\n14\n31\n0\n4\n0\n\n\nsource\n0\n1\n6\n42\n0\n51995\n0\n\n\ntarget\n0\n1\n6\n48\n0\n8872\n0\n\n\n\nVariable type: Date\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\nstart_date\n0\n1\n1952-05-31\n2035-12-29\n2023-12-12\n11468\n\n\nend_date\n0\n1\n2035-01-01\n2035-12-29\n2035-12-12\n73\n\n\n\n\n\n\n\nClick to view code\np1 &lt;- ggplot(data = mc3_edges_filt, aes(x = type, fill = type)) +\n  geom_bar() + theme(axis.text.x = element_text(angle = 60, hjust = 1))\np1\n\n\n\n\n\n\n\n\n\n\n\n\n\nClick to view code\nskim(mc3_nodes_filt)\n\n\n\nData summary\n\n\nName\nmc3_nodes_filt\n\n\nNumber of rows\n60520\n\n\nNumber of columns\n3\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\ntype\n0\n1\n13\n36\n0\n8\n0\n\n\nid\n0\n1\n6\n48\n0\n60520\n0\n\n\ncountry\n0\n1\n4\n15\n0\n86\n0\n\n\n\n\n\n\n\nClick to view code\np2 &lt;- ggplot(data = mc3_nodes_filt, aes(x = type, fill = type)) +\n  geom_bar() + theme(axis.text.x = element_text(angle = 60, hjust = 1))\np2 \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nAccording to the VAST2024 - MC3 Data Description, the person node include Entity.Person and Entity.Person.CEO, the other were included in the Company."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#mc3-task3",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#mc3-task3",
    "title": "Take_home_Ex03",
    "section": "",
    "text": "Develop a visual approach to examine inferences. Infer how the influence of a company changes through time. Can you infer ownership and influence that a network may have?\n\n\n\n\n\n\nTip\n\n\n\nBased on this plot, the edge types like {Shareholdership, BeneficialOwnership, WorksFor, FamilyRelationship} will be used, and the company name to define company; Meanwhile, the type in node like (Entity.Organization, Entity.Organization.Company, Entity.Organization.FishingCompany, Entity.Organization.LogisticsCompany, Entity.Organization.NewsCompany, Entity.Organization.FinancialCompany, Entity.Organization.NGO) will be used, source and target will be choosed to decide the “from” and “to”.\n\n\n\n\n\n3.1.1 Nodes3.1.2 Edges\n\n\nThe code chunk below will be used to extract the nodes data.frame of mc3_data and save it as a tibble data.frame called mc3_nodes.\n\n\nClick to view code\n# Clean and select columns from mc3_data$nodes\nmc3_nodes_clean &lt;- as_tibble(mc3_nodes_filt) %&gt;%\n  mutate(type = type,\n         id = id) %&gt;%\n  select(id, type) %&gt;%\n  separate(type, into = c(\"prefix\", \"supertype\", \"subtype\"), sep = \"\\\\.\", extra = \"merge\", fill = \"right\") %&gt;%\n  select(id, supertype, subtype)\n\n# Display the first few rows using kable\nkable(head(mc3_nodes_clean))\n\n\n\n\n\nid\nsupertype\nsubtype\n\n\n\n\nAbbott, Mcbride and Edwards\nOrganization\nCompany\n\n\nAbbott-Gomez\nOrganization\nCompany\n\n\nAbbott-Harrison\nOrganization\nCompany\n\n\nAbbott-Ibarra\nOrganization\nCompany\n\n\nAbbott-Sullivan\nOrganization\nCompany\n\n\nAcevedo and Sons\nOrganization\nCompany\n\n\n\n\n\n\n\nThe code chunk below will be used to extract the links data.frame of mc3_data and save it as a tibble data.frame called mc3_edges.\n\n\nClick to view code\nmc3_edges_clean &lt;- as_tibble(mc3_edges_filt) %&gt;% \n  mutate(\n    start_date = as_datetime(start_date),\n    end_date = as_datetime(end_date)\n    ) %&gt;%\n  group_by(source, target, type, start_date, end_date) %&gt;%\n    summarise(weights = n(), .groups = 'drop') %&gt;%\n  filter(source != target) %&gt;%\n  ungroup()\nkable(head(mc3_edges_clean))\n\n\n\n\n\n\n\n\n\n\n\n\n\nsource\ntarget\ntype\nstart_date\nend_date\nweights\n\n\n\n\n4. SeaCargo Ges.m.b.H.\nDry CreekRybachit Marine A/S\nEvent.Owns.Shareholdership\n2034-12-31\n2035-12-12\n1\n\n\n4. SeaCargo Ges.m.b.H.\nKambalaSea Freight Inc\nEvent.Owns.Shareholdership\n2033-04-12\n2035-12-12\n1\n\n\n9. RiverLine CJSC\nSumacAmerica Transport GmbH & Co. KG\nEvent.Owns.Shareholdership\n2028-12-02\n2035-12-12\n1\n\n\nAaron Acosta\nManning-Pratt\nEvent.Owns.Shareholdership\n2008-09-14\n2035-12-12\n1\n\n\nAaron Acosta\nManning-Pratt\nEvent.WorksFor\n2008-07-30\n2035-12-12\n1\n\n\nAaron Allen\nHicks-Calderon\nEvent.Owns.BeneficialOwnership\n2025-03-06\n2035-12-12\n1\n\n\n\n\n\n\n\n\n\n\n\nFirst, create a graph object using tbl_graph() function. Then calculate betweenness and closeness centrality scores.\n\n\nClick to view code\nmc3_graph &lt;- tbl_graph(nodes = mc3_nodes_clean,\n                       edges = mc3_edges_clean,\n                       directed = FALSE) %&gt;%\n  mutate(betweenness_centrality = centrality_betweenness(),\n         closeness_centrality = centrality_closeness())\n\n\nWe will filter nodes with high betweenness centrality scores (&gt;8,000,000) and visualise them to see the relationships that they have.\n\n\nClick to view code\nset.seed(1234)\nmc3_graph %&gt;%\n  filter(betweenness_centrality &gt;= 8000000) %&gt;%\nggraph(layout = \"fr\") +\n  geom_edge_link(aes(#width= weights,\n                     alpha=0.5)) +\n  geom_node_point(aes(\n    size = betweenness_centrality,\n    color = supertype,\n    alpha = 0.3)) +\n  geom_node_label(aes(label = id),repel=TRUE, size=2.5, alpha = 0.8) +\n  scale_size_continuous(range=c(1,10)) +\n  theme_graph() +\n  labs(title = 'Initial network visualisation',\n       subtitle = 'Entities with betweenness scores &gt; 8,000,000')\n\n\n\n\n\n\n\n\n\nBelow is a dataframe showing us the top 10 entities with the highest betweenness scores.\n\n\nClick to view code\nmc3_graph %&gt;%  activate(nodes) %&gt;%  as_tibble() %&gt;% arrange(desc(betweenness_centrality)) %&gt;% slice(1:10) %&gt;% kable() \n\n\n\n\n\n\n\n\n\n\n\n\nid\nsupertype\nsubtype\nbetweenness_centrality\ncloseness_centrality\n\n\n\n\nSharon Moon\nPerson\nNA\n31170638\n3.6e-06\n\n\nSteven Robertson\nPerson\nNA\n28158072\n3.2e-06\n\n\nJohnson, Morales and Castro\nOrganization\nCompany\n26218503\n3.7e-06\n\n\nHart Ltd\nOrganization\nFinancialCompany\n26129255\n3.2e-06\n\n\nAbbott-Harrison\nOrganization\nCompany\n24206713\n3.0e-06\n\n\nPhelps, Montoya and Barnett\nOrganization\nCompany\n21073981\n3.0e-06\n\n\nMorrison-Zamora\nOrganization\nCompany\n20813895\n3.7e-06\n\n\nBlankenship-Strickland\nOrganization\nCompany\n20157207\n3.4e-06\n\n\nHolloway-Salas\nOrganization\nCompany\n19957178\n3.7e-06\n\n\nMichael Howard DDS\nPerson\nNA\n19922437\n3.5e-06\n\n\n\n\n\nThe top 10 betweenness entities above include 3 persons and 7 companies. In the next section, we will filter entities into only organization entities. We may revisit the person entities later when we have specific targets/companies to investigate.\n\n\n\n\nbefore 2033-10-29\nbetween 2033-10-29 and 2035-05-25\nafter 2035-05-25\n\n\n\nClick to view code\n# Time bins\nbin1 &lt;- mc3_edges_clean %&gt;%\n  filter(as.Date(start_date) &lt; as.Date(\"2033-10-29\"))\n\nbin2 &lt;- mc3_edges_clean %&gt;%\n  filter(as.Date(start_date) &gt;= as.Date(\"2033-10-29\") & as.Date(start_date) &lt;= as.Date(\"2035-05-25\"))\n\nbin3 &lt;- mc3_edges_clean %&gt;%\n  filter(as.Date(start_date) &gt; as.Date(\"2035-05-25\"))\n\n# Filter edges to include any that contain \"SouthSeafood\"\nsouthseafood_edges_bin1 &lt;- bin1 %&gt;%\n  filter(str_detect(source, \"SouthSeafood\") | str_detect(target, \"SouthSeafood\"))\n\nsouthseafood_edges_bin2 &lt;- bin2 %&gt;%\n  filter(str_detect(source, \"SouthSeafood\") | str_detect(target, \"SouthSeafood\"))\n\nsouthseafood_edges_bin3 &lt;- bin3 %&gt;%\n  filter(str_detect(source, \"SouthSeafood\") | str_detect(target, \"SouthSeafood\"))\n\n# Glimpse the results\nglimpse(southseafood_edges_bin1)\n\n\nRows: 0\nColumns: 6\n$ source     &lt;chr&gt; \n$ target     &lt;chr&gt; \n$ type       &lt;chr&gt; \n$ start_date &lt;dttm&gt; \n$ end_date   &lt;dttm&gt; \n$ weights    &lt;int&gt; \n\n\nClick to view code\nglimpse(southseafood_edges_bin2)\n\n\nRows: 2\nColumns: 6\n$ source     &lt;chr&gt; \"AguaLeska Transit N.V.\", \"Tainamarine Fishing Co\"\n$ target     &lt;chr&gt; \"SouthSeafood Express Corp\", \"SouthSeafood Express Corp\"\n$ type       &lt;chr&gt; \"Event.Owns.Shareholdership\", \"Event.Owns.Shareholdership\"\n$ start_date &lt;dttm&gt; 2033-10-29, 2035-05-25\n$ end_date   &lt;dttm&gt; 2035-05-25, 2035-12-12\n$ weights    &lt;int&gt; 1, 1\n\n\nClick to view code\nglimpse(southseafood_edges_bin3)\n\n\nRows: 0\nColumns: 6\n$ source     &lt;chr&gt; \n$ target     &lt;chr&gt; \n$ type       &lt;chr&gt; \n$ start_date &lt;dttm&gt; \n$ end_date   &lt;dttm&gt; \n$ weights    &lt;int&gt; \n\n\n\n\n\n\n\n\n\nClick to view code\n# Filter nodes to include only Organizations or Persons\nmc3_nodes_select &lt;- mc3_nodes_clean %&gt;%\n  filter(grepl(\"Organization|Person\", supertype, ignore.case = TRUE))\n\n\n\n\n\n\n\nClick to view code\nmc3_edges_select &lt;- mc3_edges_clean %&gt;%\n  filter(source %in% mc3_nodes_select$id | target %in% mc3_nodes_select$id) %&gt;%\n  distinct() %&gt;%\n  rename(from = source,\n         to = target)\n\n\n\n\n\n\n\nClick to view code\nmc3_edges_select_high &lt;- mc3_edges_select %&gt;%\n  group_by(from) %&gt;%\n  mutate(count = n()) %&gt;%\n  filter(count &gt;= 5) %&gt;%\n  ungroup()\n\n\n\n\n\n\n\nClick to view code\nmc3_nodes_source &lt;- mc3_edges_select_high %&gt;%\n  distinct(from) %&gt;%\n  rename(id = from)\n\nmc3_nodes_target &lt;- mc3_edges_select_high %&gt;%\n  distinct(to) %&gt;%\n  rename(id = to)\n\n\n\n\n\n\n\nClick to view code\n# Combine and deduplicate nodes\nmc3_nodes_combined &lt;- bind_rows(mc3_nodes_source, mc3_nodes_target) %&gt;%\n  distinct(id) %&gt;%\n  left_join(mc3_nodes_clean, by = \"id\")\n\n# Assign group based on supertype\nmc3_nodes_combined$group &lt;- ifelse(mc3_nodes_combined$supertype == \"Organization\", \"Organization\", \"Person\")\n\n# Visualize with visNetwork\nvisNetwork(mc3_nodes_combined, mc3_edges_select_high) %&gt;%\n  visPhysics(solver = \"forceAtlas2Based\",\n             forceAtlas2Based = list(gravitationalConstant = -100)) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visGroups(groupname = \"Organization\", color = \"yellow\") %&gt;%\n  visGroups(groupname = \"Person\", color = \"grey\") %&gt;%\n  visLegend() %&gt;%\n  visEdges(arrows = \"to\") %&gt;%\n  visOptions(\n    highlightNearest = list(enabled = TRUE, degree = 2, hover = TRUE),\n    nodesIdSelection = TRUE,\n    selectedBy = \"group\",\n    collapse = TRUE\n  ) %&gt;%\n  visInteraction(dragNodes = TRUE, dragView = TRUE, zoomView = TRUE) %&gt;%\n  visEvents(selectNode = \"function(properties) {\n    var selectedNodeId = properties.nodes[0];\n    this.body.data.nodes.update({id: selectedNodeId, color: {background: 'red', border: 'black'}});\n  }\")\n\n\n\n\n\n\n\n\n\nSince the SouthSeafood Express Corp connect first event from AguaLeska Transit N.V. in 2033-10-29, and turn to connect Tainamarine Fishing Co in 2035-05-25\n\nbefore 2033-10-29after 2035-05-25\n\n\n\n\nClick to view code\n# Filter edges based on date criteria\nmc3_edges_filtered_dates &lt;- mc3_edges_clean %&gt;%\n  filter(start_date &lt; as_datetime(\"2033-10-29\") & end_date &gt; as_datetime(\"2033-10-29\"))\n\n# Visualize with visNetwork\nvisNetwork(mc3_nodes_combined, mc3_edges_select_high) %&gt;%\n  visPhysics(solver = \"forceAtlas2Based\",\n             forceAtlas2Based = list(gravitationalConstant = -100)) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visGroups(groupname = \"Organization\", color = \"lightblue\") %&gt;%\n  visGroups(groupname = \"Person\", color = \"lightgreen\") %&gt;%\n  visLegend() %&gt;%\n  visEdges(arrows = \"to\") %&gt;%\n  visOptions(\n    highlightNearest = list(enabled = TRUE, degree = 2, hover = TRUE),\n    nodesIdSelection = TRUE,\n    selectedBy = \"group\",\n    collapse = TRUE\n  ) %&gt;%\n  visInteraction(dragNodes = TRUE, dragView = TRUE, zoomView = TRUE) %&gt;%\n  visEvents(selectNode = \"function(properties) {\n    var selectedNodeId = properties.nodes[0];\n    this.body.data.nodes.update({id: selectedNodeId, color: {background: 'red', border: 'black'}});\n  }\")\n\n\n\n\n\n\n\n\n\n\nClick to view code\n# Filter edges based on date criteria\nmc3_edges_filtered_dates &lt;- mc3_edges_clean %&gt;%\n  filter(end_date &gt; as_datetime(\"2035-05-25\"))\n\n\n# Visualize with visNetwork\nvisNetwork(mc3_nodes_combined, mc3_edges_select_high) %&gt;%\n  visPhysics(solver = \"forceAtlas2Based\",\n             forceAtlas2Based = list(gravitationalConstant = -100)) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visGroups(groupname = \"Organization\", color = \"pink\") %&gt;%\n  visGroups(groupname = \"Person\", color = \"lightgreen\") %&gt;%\n  visLegend() %&gt;%\n  visEdges(arrows = \"to\") %&gt;%\n  visOptions(\n    highlightNearest = list(enabled = TRUE, degree = 2, hover = TRUE),\n    nodesIdSelection = TRUE,\n    selectedBy = \"group\",\n    collapse = TRUE\n  ) %&gt;%\n  visInteraction(dragNodes = TRUE, dragView = TRUE, zoomView = TRUE) %&gt;%\n  visEvents(selectNode = \"function(properties) {\n    var selectedNodeId = properties.nodes[0];\n    this.body.data.nodes.update({id: selectedNodeId, color: {background: 'red', border: 'black'}});\n  }\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#expand-for-southseafood-express-corp",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#expand-for-southseafood-express-corp",
    "title": "Take-home_Ex03",
    "section": "",
    "text": "To ensure the network associated with SouthSeafood Express Corp and visualize how this network and competing businesses change as a result of their illegal fishing behavior, an expand in timeline of visNetwork of the SouthSeafood is required."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "title": "In-class_Ex05",
    "section": "",
    "text": "Put all data into one tibular dataframe.\n\npacman::p_load(tidyverse, readtext,\n               quanteda, tidytext)\n\n\ndata_folder &lt;- \"data/MC1/articles\"\n\nText sensing to extract text\n\ntext_data &lt;- readtext(paste0(\"data/MC1/articles\",\n                \"/*\"))\n\nOR\n\ntext_data &lt;- readtext(\"data/MC1/articles\")\n\nBasic tokenisation\n\nusenet_words &lt;- text_data %&gt;%\n  unnest_tokens(word, text) %&gt;%  #reading the text data\n  filter(str_detect(word, \"[a-z']$\"),\n         !word %in% stop_words$word) #remove stop words\n\n\nusenet_words %&gt;%\n  count(word, sort = TRUE)\n\nreadtext object consisting of 3261 documents and 0 docvars.\n# A data frame: 3,261 × 3\n  word             n text     \n  &lt;chr&gt;        &lt;int&gt; &lt;chr&gt;    \n1 fishing       2177 \"\\\"\\\"...\"\n2 sustainable   1525 \"\\\"\\\"...\"\n3 company       1036 \"\\\"\\\"...\"\n4 practices      838 \"\\\"\\\"...\"\n5 industry       715 \"\\\"\\\"...\"\n6 transactions   696 \"\\\"\\\"...\"\n# ℹ 3,255 more rows\n\n\nObservations- Most common words are: fishing, sustainable, company\n\ntemp_table &lt;- usenet_words %&gt;%\n  count(word, sort = TRUE)\n\nCreating a table to observe word counts\n\ncorpus_text &lt;- corpus(text_data)\nsummary(corpus_text, 5)\n\nCorpus consisting of 338 documents, showing 5 documents:\n\n                                   Text Types Tokens Sentences\n Alvarez PLC__0__0__Haacklee Herald.txt   206    433        18\n    Alvarez PLC__0__0__Lomark Daily.txt   102    170        12\n   Alvarez PLC__0__0__The News Buoy.txt    90    200         9\n Alvarez PLC__0__1__Haacklee Herald.txt    96    187         8\n    Alvarez PLC__0__1__Lomark Daily.txt   241    504        21\n\n\nTo separate the data; with 2 columns X & Y. Some text are “1” hence the split does not occur\n\ntext_data_splitted &lt;- text_data %&gt;%\n  separate_wider_delim(\"doc_id\",\n                       delim = \"__0__\",\n                       names = c(\"X\", \"Y\"),\n                       too_few = \"align_end\")\n\n\npacman::p_load(jsonlite, tidyverse)\n\n\n##pacman::p_load(jsonlite, tidygraph,\n##ggraph, tidyverse, readtext,\n               ##quanteda, tidytext)\n\nIn the code chunk below, fromJSON() of jsonlite package is used to import MC3.json into R environment.\n\nmc1_data &lt;- fromJSON(\"data/MC1/mc1.json\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html",
    "title": "In-class_Ex09",
    "section": "",
    "text": "pacman::p_load(scatterPlotMatrix, parallelPlot, cluster, factoextra, tidyverse)\n\n\nwine &lt;- read_csv(\"data/wine_quality.csv\")\n\n\nggplot(data = wine,\n       aes(x = type)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\nwhitewine &lt;- wine %&gt;%\n  filter(type == \"white\") %&gt;%\n  select(c(1:11))\n\n\nscatterPlotMatrix(whitewine,\n                  corrPlotType = \"Text\",\n                  distribType = 1,\n                  width = 500,\n                  height = 500)\n\n\n\n\n\n\nset.seed(123)\nkmeans4 &lt;- kmeans(whitewine, 4, nstart= 25)\nprint(kmeans4)\n\nK-means clustering with 4 clusters of sizes 1719, 1444, 757, 978\n\nCluster means:\n  fixed acidity volatile acidity citric acid residual sugar  chlorides\n1      6.782403        0.2719372   0.3247469       5.348342 0.04324549\n2      6.908172        0.2776939   0.3455402       7.780852 0.04919668\n3      6.981506        0.2965786   0.3563540       9.705878 0.05227081\n4      6.805112        0.2759356   0.3168814       3.607822 0.04012781\n  free sulfur dioxide total sulfur dioxide   density       pH sulphates\n1            30.11635             121.1963 0.9931958 3.195829 0.4847935\n2            42.31129             160.3061 0.9951215 3.193996 0.4940651\n3            52.83421             206.8164 0.9965522 3.176975 0.5179392\n4            20.52761              83.1411 0.9919192 3.175256 0.4707566\n    alcohol\n1 10.833256\n2 10.120392\n3  9.611471\n4 11.233930\n\nClustering vector:\n   [1] 2 1 4 3 3 4 1 2 1 1 4 1 4 2 2 1 4 4 2 1 4 4 1 2 1 3 2 1 1 1 1 4 4 1 2 1 2\n  [38] 1 2 2 2 2 2 2 2 2 3 3 2 2 2 1 4 1 1 3 3 2 4 1 1 2 2 4 1 1 1 2 4 1 3 3 3 4\n  [75] 4 1 4 4 1 1 1 2 2 3 2 2 2 3 2 2 2 3 1 1 2 3 2 4 4 2 3 2 2 2 3 1 2 2 2 3 2\n [112] 3 3 2 2 4 1 4 3 3 4 1 1 1 2 2 1 3 2 2 4 3 3 3 3 2 1 2 4 4 4 2 1 4 4 1 2 4\n [149] 4 1 2 2 1 4 4 3 3 1 1 1 1 2 4 3 3 2 3 4 2 1 1 4 4 1 2 2 4 2 1 2 2 3 2 3 3\n [186] 3 2 1 1 3 3 2 1 1 3 3 3 3 3 3 3 3 3 1 1 2 1 1 4 2 4 1 1 1 1 2 2 2 2 2 2 2\n [223] 1 2 1 2 3 3 3 2 1 3 3 3 3 3 3 3 1 2 3 4 4 3 2 3 1 4 4 1 3 3 2 1 2 2 4 4 1\n [260] 4 1 2 4 3 2 2 2 2 2 2 2 2 2 1 3 2 2 4 4 1 1 1 3 3 3 2 3 3 3 3 3 2 3 2 2 2\n [297] 2 3 2 1 4 4 4 2 2 2 2 2 1 2 4 2 2 2 2 1 1 1 1 4 4 1 1 1 3 3 3 2 3 4 1 1 4\n [334] 1 4 4 1 2 1 2 2 1 1 2 2 1 4 2 1 2 2 1 1 1 3 3 3 2 2 2 2 4 1 3 4 1 2 2 2 4\n [371] 2 2 3 2 4 4 1 4 2 1 4 2 2 2 1 4 1 3 1 3 3 4 1 4 2 2 4 1 2 4 1 2 1 3 2 2 1\n [408] 1 1 4 2 2 4 4 2 2 4 3 4 1 1 3 3 3 2 3 3 3 4 3 3 4 3 2 1 4 3 3 3 1 4 1 1 3\n [445] 2 4 2 1 1 1 2 1 2 1 1 1 4 1 3 3 1 2 2 4 2 1 2 4 2 3 2 3 4 1 1 3 1 1 2 2 2\n [482] 1 1 2 3 1 1 4 2 2 4 4 2 2 1 2 3 2 2 3 3 2 3 3 2 2 1 2 2 2 2 2 1 4 1 2 2 2\n [519] 4 4 1 1 4 4 4 1 4 1 1 1 1 2 2 2 2 2 2 2 4 3 2 3 2 2 2 2 2 4 1 3 2 4 1 2 1\n [556] 4 2 1 2 2 2 1 2 1 2 4 4 2 2 2 3 1 2 2 1 3 3 2 1 1 3 1 2 4 1 4 2 1 1 1 1 1\n [593] 2 1 1 1 2 1 1 4 2 1 1 1 1 1 2 2 2 4 1 4 1 1 1 1 4 3 3 1 3 2 1 4 1 1 2 3 3\n [630] 4 2 2 1 3 2 1 1 2 3 3 1 3 3 2 2 2 2 2 3 3 3 3 3 1 2 1 4 1 3 3 4 1 2 4 2 1\n [667] 3 2 2 3 3 4 2 1 3 3 3 4 4 4 2 2 2 2 2 3 1 3 3 1 1 3 3 2 3 3 4 3 3 3 3 1 4\n [704] 1 1 4 3 2 1 4 2 1 1 3 3 2 3 2 2 1 2 2 1 4 1 1 1 4 2 2 1 3 4 2 3 1 2 3 2 1\n [741] 4 4 1 2 2 1 3 2 2 2 2 2 2 3 1 1 2 2 2 1 2 2 3 1 2 1 3 4 1 1 1 2 2 2 1 1 4\n [778] 3 2 2 4 3 2 2 3 1 1 1 1 1 1 4 2 4 2 2 3 2 1 4 2 3 3 2 1 2 3 3 3 3 3 1 2 2\n [815] 3 1 4 1 1 1 4 3 1 1 4 2 2 1 4 4 1 2 1 4 1 1 2 2 2 1 1 2 2 1 1 1 2 4 2 1 1\n [852] 2 1 2 1 1 2 2 2 2 1 3 2 1 2 1 1 2 2 4 2 2 1 4 4 1 1 1 1 1 1 1 1 1 3 1 2 4\n [889] 2 4 2 1 1 1 1 4 3 4 4 3 2 1 3 3 2 4 4 1 2 3 1 1 1 4 4 4 1 1 1 1 2 2 2 3 2\n [926] 4 4 2 2 1 4 3 3 3 3 3 4 1 3 3 3 3 4 1 1 1 3 2 4 4 1 1 4 1 1 1 1 4 4 2 2 1\n [963] 2 1 2 4 3 2 4 4 4 1 2 4 1 1 1 3 2 4 4 2 4 4 2 1 2 2 2 1 2 4 3 4 2 2 4 2 2\n[1000] 2 4 3 3 1 2 4 2 4 3 2 1 2 4 3 2 1 1 1 2 3 1 1 3 2 2 1 2 4 1 3 2 3 3 3 3 2\n[1037] 4 4 1 4 1 4 1 3 4 4 1 4 4 1 2 1 4 1 4 1 1 3 1 2 1 3 3 3 2 1 2 1 4 2 2 1 1\n[1074] 3 2 1 2 1 3 3 1 2 2 3 1 2 1 1 3 1 3 2 2 1 3 4 2 1 1 1 2 1 2 1 2 3 1 4 4 2\n[1111] 4 4 2 4 4 4 4 3 4 1 1 1 4 1 1 2 2 4 4 1 2 1 2 1 1 2 2 2 1 4 4 2 1 1 1 3 2\n[1148] 2 1 3 3 3 4 4 2 2 1 1 3 1 2 1 2 3 4 1 4 1 4 2 1 1 1 1 3 2 3 2 2 1 1 1 1 1\n[1185] 1 3 2 1 2 4 1 1 1 1 3 2 1 1 1 4 4 4 3 4 4 3 2 3 1 1 4 2 2 4 4 2 4 3 1 4 3\n[1222] 1 1 2 1 4 1 1 1 4 3 1 4 1 2 3 4 1 1 2 2 2 2 1 1 3 2 4 4 3 2 2 2 2 2 1 2 3\n[1259] 3 3 3 2 2 3 4 2 1 2 1 3 2 1 2 1 3 1 2 1 1 2 1 2 2 2 2 1 2 1 1 4 4 3 4 4 4\n[1296] 3 1 1 2 2 2 2 3 2 3 1 1 1 1 4 2 1 2 2 2 2 3 2 4 3 1 1 2 2 2 1 2 2 4 1 1 1\n[1333] 3 2 1 3 2 3 3 1 1 2 1 2 2 1 2 2 2 4 1 1 3 3 2 2 3 2 1 1 2 3 1 4 2 1 4 1 3\n[1370] 3 1 2 2 2 1 1 1 1 1 1 2 4 4 4 1 1 1 4 1 3 1 4 4 4 1 4 1 3 3 4 3 3 1 1 4 1\n[1407] 4 4 3 1 4 4 2 1 1 4 1 3 1 1 1 4 1 3 1 1 1 2 4 4 1 4 4 4 2 4 3 4 3 3 2 1 1\n[1444] 1 2 1 4 2 2 2 2 1 2 2 3 2 4 1 2 1 1 2 2 1 2 2 2 4 4 1 2 2 4 1 4 2 2 4 2 1\n[1481] 2 1 3 4 1 1 4 2 3 3 1 4 3 2 3 3 4 1 4 2 1 2 1 1 1 1 3 2 2 1 1 1 1 2 1 1 2\n[1518] 2 4 2 2 1 2 2 2 2 2 3 2 2 2 2 3 1 2 1 4 2 1 1 2 4 1 4 4 2 2 2 1 1 2 1 2 2\n[1555] 2 2 2 2 1 4 2 1 1 2 1 1 2 1 3 2 2 3 2 1 1 3 4 1 2 3 1 4 1 2 3 2 2 3 2 1 2\n[1592] 2 1 4 1 3 1 3 1 4 1 3 4 4 1 1 1 1 3 3 1 4 4 1 1 2 3 1 3 1 4 1 2 1 1 2 3 1\n[1629] 1 4 1 1 1 1 3 1 2 2 3 1 2 2 1 2 1 2 2 4 4 2 1 3 1 2 2 1 4 2 3 3 3 3 1 2 2\n[1666] 1 4 1 4 1 2 4 2 2 3 3 4 2 2 1 3 3 3 3 3 3 2 3 3 1 2 3 3 3 2 1 3 3 3 2 1 3\n[1703] 1 2 2 1 2 2 2 2 4 1 2 1 1 2 1 1 2 4 2 3 2 2 1 2 4 3 1 1 1 3 1 1 3 2 4 3 4\n[1740] 4 2 2 2 2 1 3 4 2 4 1 2 2 3 2 4 2 3 3 4 3 3 1 4 1 3 3 3 2 2 1 2 2 2 2 4 1\n[1777] 2 2 2 2 2 3 2 4 1 2 1 2 1 3 2 1 2 3 1 2 1 1 2 2 3 4 2 2 3 1 1 3 1 3 2 1 4\n[1814] 1 4 2 1 1 4 1 2 1 4 3 2 4 2 3 3 2 2 2 2 2 2 3 1 1 3 1 2 1 3 1 4 2 2 2 3 3\n[1851] 2 4 1 1 2 3 2 2 2 3 2 3 1 3 1 1 3 1 2 2 2 2 2 2 2 2 2 4 3 4 3 4 3 3 1 4 1\n[1888] 2 3 1 3 3 2 2 2 3 2 2 4 1 2 1 2 1 3 2 1 2 4 1 2 4 1 2 1 4 2 4 2 3 2 1 1 4\n[1925] 4 4 4 2 3 2 3 3 4 2 4 2 3 2 4 2 3 2 3 3 3 2 2 3 1 2 3 2 1 2 3 2 4 4 3 4 4\n[1962] 1 4 3 2 2 1 3 2 2 1 2 1 1 1 3 3 2 1 3 3 3 3 3 3 2 2 2 3 1 1 3 4 2 2 2 2 2\n[1999] 2 3 2 2 2 2 2 2 2 4 2 4 4 2 2 1 4 4 1 4 1 1 2 2 3 2 3 2 4 2 2 3 1 2 4 3 1\n[2036] 4 2 2 1 4 3 1 1 1 1 4 1 2 2 2 1 2 2 4 4 2 2 2 3 2 3 4 1 1 2 1 1 2 1 1 2 1\n[2073] 2 3 2 1 1 3 1 1 1 4 1 1 2 2 4 2 1 2 2 2 4 1 1 2 1 2 2 2 2 4 3 1 2 1 3 2 2\n[2110] 3 2 2 2 4 3 2 4 1 1 1 2 1 2 2 1 2 2 3 2 1 1 2 2 2 1 3 1 3 4 4 1 1 2 4 2 2\n[2147] 1 1 4 4 1 1 4 4 3 2 4 4 1 4 1 4 1 4 1 2 2 3 3 3 3 3 1 2 3 3 1 1 2 1 2 1 2\n[2184] 2 1 4 4 1 4 1 1 2 2 1 4 1 4 4 3 3 2 2 3 2 2 2 1 1 1 1 2 1 1 1 1 2 4 1 2 1\n[2221] 1 2 2 2 2 2 2 2 1 2 1 2 4 2 4 1 3 2 2 1 2 3 2 2 3 1 2 2 4 3 3 1 2 3 2 1 1\n[2258] 1 3 1 3 1 4 2 2 2 2 2 2 2 1 2 1 4 1 2 3 4 3 2 4 4 3 3 3 3 2 2 3 4 1 2 3 4\n[2295] 1 2 2 3 1 1 1 1 3 1 2 2 1 2 1 1 2 1 1 4 1 2 1 2 2 4 1 2 1 2 3 1 1 1 1 2 3\n[2332] 2 3 1 3 1 3 2 2 4 2 2 4 2 4 3 2 4 1 2 3 3 1 4 4 1 1 4 3 1 1 4 2 2 3 1 3 3\n[2369] 2 2 1 3 4 4 3 2 3 4 3 3 3 2 1 4 1 2 2 2 4 4 1 2 1 1 3 3 3 4 4 4 4 1 3 1 1\n[2406] 3 4 1 3 1 3 3 3 1 3 1 3 3 4 3 1 3 3 1 3 1 2 3 2 3 3 2 3 3 3 1 2 2 2 1 2 2\n[2443] 3 3 3 3 3 1 1 3 2 2 1 1 3 3 2 2 3 2 2 4 4 2 1 2 2 1 4 1 2 2 4 1 4 1 2 4 3\n[2480] 1 1 3 3 3 3 3 1 1 1 2 1 3 2 1 1 2 4 1 1 2 1 3 1 1 2 3 3 1 2 1 3 3 4 1 2 4\n[2517] 2 3 4 3 2 1 2 2 2 2 1 1 1 2 2 2 2 2 4 2 1 1 1 1 2 2 2 1 1 2 2 1 3 3 1 3 1\n[2554] 2 2 2 2 2 2 1 4 1 4 1 2 3 4 1 3 1 1 4 4 2 2 3 3 3 1 1 2 2 2 2 2 2 2 4 2 2\n[2591] 1 2 2 2 1 2 3 1 3 3 1 3 1 1 1 4 2 3 3 4 2 3 1 1 4 1 1 1 1 2 2 1 1 1 4 2 1\n[2628] 1 3 3 1 1 3 2 3 4 2 3 1 4 4 2 4 2 2 1 4 1 2 2 2 2 4 2 3 3 3 1 2 4 2 2 1 4\n[2665] 4 1 2 1 1 2 2 2 1 4 1 1 4 2 1 1 1 2 1 1 1 4 1 3 2 1 1 1 2 1 1 1 2 4 2 1 4\n[2702] 1 1 1 3 3 3 1 3 3 3 2 2 3 3 2 3 2 4 2 4 2 1 1 2 2 4 1 3 4 3 2 1 4 2 3 1 4\n[2739] 1 4 2 1 2 4 4 4 2 1 2 1 2 1 1 4 4 3 3 4 4 1 2 2 2 1 2 1 4 2 1 2 3 1 1 4 1\n[2776] 1 1 1 4 1 1 2 3 3 3 2 4 2 2 2 3 3 3 1 2 4 1 2 1 1 3 3 4 4 4 1 2 2 3 2 4 1\n[2813] 1 2 4 4 1 4 2 1 1 3 2 4 2 2 3 2 2 2 2 2 4 1 1 2 3 2 4 4 4 4 4 4 4 4 4 4 2\n[2850] 3 2 4 2 1 4 2 1 4 2 1 2 4 4 4 1 1 1 1 1 1 1 4 2 4 1 4 2 2 1 4 4 4 1 4 1 4\n[2887] 4 4 4 1 2 2 3 2 4 2 3 3 4 2 4 4 2 4 1 2 3 4 4 4 2 2 4 3 4 4 1 1 4 1 4 3 1\n[2924] 1 1 3 4 2 2 1 2 4 3 1 4 4 4 3 1 1 1 1 2 1 1 2 1 1 3 1 1 4 1 1 4 1 4 4 4 4\n[2961] 1 1 4 1 1 1 1 1 2 4 2 1 1 1 1 2 1 1 1 1 1 4 3 2 4 1 1 1 4 3 2 2 1 1 1 1 1\n[2998] 2 1 1 1 1 2 4 1 2 3 2 2 3 3 1 4 1 4 4 1 2 1 4 4 4 1 4 1 2 1 2 1 1 1 1 4 3\n[3035] 2 4 3 2 1 3 1 2 2 1 1 4 1 2 1 3 3 3 2 1 4 1 4 1 3 4 2 2 1 2 3 1 3 1 1 4 1\n[3072] 4 2 1 1 4 1 3 4 1 4 2 4 4 4 4 4 3 4 4 4 3 2 1 4 4 4 1 1 1 1 4 1 1 1 2 2 2\n[3109] 2 3 1 4 1 1 1 1 4 4 2 4 3 1 1 4 1 2 1 4 4 1 2 3 1 1 1 3 1 1 1 1 3 4 1 1 1\n[3146] 1 1 2 1 2 4 1 3 4 1 1 1 1 1 1 4 1 1 1 3 1 1 1 4 1 2 4 1 1 1 2 4 2 4 1 4 1\n[3183] 1 4 4 1 4 1 1 2 1 2 1 1 4 1 1 1 1 1 2 1 4 1 2 2 4 1 2 2 1 2 1 2 4 4 1 1 1\n[3220] 4 4 4 1 2 2 4 1 3 3 1 2 1 4 4 1 2 2 2 1 4 1 1 1 4 4 1 1 2 2 2 1 2 1 1 3 3\n[3257] 3 3 3 3 3 4 3 4 3 2 1 2 1 3 1 4 4 1 1 4 2 1 3 1 1 1 1 2 1 1 1 1 2 3 4 4 3\n[3294] 4 1 3 3 3 1 1 4 4 4 4 2 4 2 3 1 4 1 2 4 4 3 4 4 1 1 2 1 4 1 4 1 1 2 4 1 1\n[3331] 2 2 2 2 4 3 3 3 4 4 1 4 1 3 3 3 3 2 4 4 1 4 4 4 1 1 2 4 4 4 4 4 1 4 4 4 1\n[3368] 1 2 1 1 1 2 1 2 1 2 3 2 3 1 1 1 2 2 1 2 3 4 4 1 1 4 1 3 3 1 3 3 4 1 1 1 1\n[3405] 4 1 4 3 3 1 2 1 2 3 2 2 3 4 3 2 2 4 1 2 1 2 2 2 1 2 2 2 1 4 4 4 4 1 3 1 1\n[3442] 1 4 1 3 1 2 4 1 1 1 1 1 4 1 4 2 2 1 2 1 3 1 1 2 1 1 3 4 2 3 1 1 4 3 2 4 2\n[3479] 2 4 4 1 4 4 4 1 4 3 4 4 2 1 1 1 1 1 2 2 1 1 1 1 2 4 1 1 2 1 2 2 2 4 1 4 4\n[3516] 4 2 1 1 1 3 2 2 3 1 1 1 2 4 1 2 2 4 2 2 2 4 1 1 4 4 1 2 2 2 3 2 3 1 2 1 1\n[3553] 1 1 4 1 1 4 1 4 4 4 2 4 4 4 1 4 4 4 4 4 1 4 1 1 2 1 1 4 2 1 4 4 4 1 2 1 1\n[3590] 1 1 2 2 2 1 1 1 2 2 3 4 1 1 1 4 2 2 4 2 2 2 4 1 2 2 4 3 1 1 1 2 1 4 1 4 3\n[3627] 1 3 2 2 1 1 1 1 2 4 4 1 4 4 1 2 2 1 1 2 4 4 1 1 1 3 1 3 1 1 3 1 2 1 1 2 4\n[3664] 2 2 1 2 1 4 1 2 4 4 4 1 2 4 2 1 1 3 1 1 3 1 3 2 4 3 1 2 1 1 1 1 2 1 3 4 2\n[3701] 2 1 2 2 2 2 4 1 3 2 4 2 2 3 4 3 2 1 1 3 2 1 1 2 1 1 1 2 4 1 3 2 1 1 1 4 4\n[3738] 1 1 2 2 2 2 2 2 2 1 3 1 2 2 1 2 2 1 1 1 2 2 1 1 4 4 4 1 3 3 3 1 3 1 1 1 1\n[3775] 3 1 1 1 1 4 3 1 4 3 1 4 3 3 3 3 3 3 1 2 1 1 4 4 1 2 4 4 1 1 4 4 4 1 1 1 2\n[3812] 2 1 2 2 1 1 1 1 1 1 2 3 3 1 4 1 4 1 4 1 1 1 1 2 1 1 1 2 1 4 3 1 1 4 2 1 2\n[3849] 4 4 1 1 4 1 1 2 4 1 1 3 3 2 3 3 4 1 1 3 3 2 2 3 3 2 3 1 2 4 2 4 1 1 1 2 1\n[3886] 4 2 4 1 1 4 1 1 4 1 4 2 2 1 1 4 4 4 4 1 4 4 4 1 1 2 1 4 1 1 1 2 3 1 1 1 2\n[3923] 4 1 1 4 4 1 2 2 4 1 1 4 4 3 1 2 4 2 2 2 1 1 2 2 1 2 1 2 2 2 4 1 2 4 1 4 1\n[3960] 1 2 2 1 1 2 4 1 3 3 1 2 1 4 3 3 2 1 1 3 3 2 2 2 1 1 1 1 3 1 1 3 1 4 1 1 1\n[3997] 1 2 1 1 1 1 4 1 1 1 4 1 4 2 1 2 1 2 3 4 2 1 3 4 4 1 2 2 2 4 2 2 4 1 1 1 1\n[4034] 1 1 2 2 2 1 1 3 2 1 1 1 1 2 1 1 4 1 4 2 1 2 4 1 1 1 4 4 4 1 1 4 1 2 2 2 1\n[4071] 2 4 2 1 4 1 1 1 1 4 1 1 2 2 4 4 4 1 4 1 2 4 1 4 4 4 1 4 1 1 4 2 2 4 4 1 2\n[4108] 2 1 2 3 4 4 4 1 4 2 2 1 2 1 2 2 4 4 2 2 3 3 4 1 3 3 1 4 1 1 3 4 2 2 2 1 1\n[4145] 2 2 1 2 1 4 3 3 1 3 3 3 3 2 2 2 2 2 2 1 1 4 2 1 1 1 2 1 2 4 2 2 2 1 1 3 1\n[4182] 4 2 4 4 3 4 1 1 1 4 1 4 4 4 4 4 2 2 4 4 4 1 2 1 4 2 1 4 4 1 3 2 4 3 3 3 1\n[4219] 2 3 4 1 1 4 4 3 2 4 3 1 1 4 4 1 1 1 1 4 1 4 1 2 2 4 1 1 4 1 1 2 4 4 4 4 1\n[4256] 1 1 1 1 1 2 1 2 2 1 2 1 1 2 3 2 3 1 1 1 1 1 2 4 1 1 1 1 4 4 4 4 1 4 1 1 3\n[4293] 1 3 1 3 1 1 1 2 2 2 3 1 1 1 1 1 4 1 2 1 1 4 1 1 4 2 1 1 3 2 1 1 1 2 2 2 2\n[4330] 2 2 2 2 2 2 2 2 2 2 4 2 1 2 1 1 1 1 2 2 3 4 1 2 2 2 1 2 3 2 3 2 1 1 1 1 2\n[4367] 1 1 1 1 1 4 1 4 2 3 1 4 1 1 2 2 1 4 2 2 2 4 4 1 2 3 2 2 2 2 2 2 2 2 2 1 2\n[4404] 3 3 3 1 4 3 1 2 4 1 4 1 1 2 1 1 1 1 1 1 1 1 1 1 3 2 2 2 4 4 3 2 2 4 2 1 1\n[4441] 2 1 2 1 1 1 1 4 1 2 1 3 2 4 2 2 2 2 1 1 2 2 1 1 1 1 2 2 4 1 4 4 4 1 1 1 1\n[4478] 2 2 1 1 2 2 1 1 4 4 4 1 1 1 4 4 2 4 3 4 2 1 4 2 2 2 1 1 2 1 4 2 4 2 1 1 4\n[4515] 3 1 4 4 4 2 3 3 4 2 2 2 3 4 4 2 2 2 1 1 1 2 2 4 1 4 1 1 4 4 1 1 4 4 3 4 4\n[4552] 1 1 1 1 4 1 3 1 1 1 4 1 1 1 2 2 2 1 1 4 4 4 4 1 1 4 4 4 1 1 1 2 2 1 2 1 1\n[4589] 1 1 2 3 2 1 1 1 1 4 1 4 1 1 2 1 2 4 1 2 4 4 4 4 2 2 2 1 4 1 1 3 1 4 1 1 4\n[4626] 2 3 4 4 4 1 1 3 3 1 1 2 1 2 3 1 1 4 3 1 2 4 1 3 4 4 1 3 4 2 2 2 2 1 4 4 2\n[4663] 1 1 1 1 3 1 1 1 2 2 2 1 2 2 1 1 2 2 1 4 4 1 3 1 1 2 2 2 2 2 2 2 2 1 4 1 1\n[4700] 2 2 2 2 4 3 1 1 1 1 2 1 1 1 4 1 4 4 1 1 4 4 4 1 2 4 1 4 1 1 4 1 2 2 1 4 4\n[4737] 4 1 1 4 3 1 1 2 4 3 1 4 2 2 2 3 4 1 1 4 1 1 1 1 1 1 4 1 1 4 1 2 2 2 2 2 3\n[4774] 4 1 1 1 1 1 4 1 2 1 1 2 4 1 1 2 1 1 1 1 2 2 2 2 4 1 1 1 2 1 1 4 4 1 1 4 2\n[4811] 2 4 1 2 1 1 2 1 4 1 2 1 2 1 2 1 1 4 2 4 1 1 1 4 4 1 4 3 1 4 1 3 4 2 2 4 2\n[4848] 1 2 2 2 2 1 4 4 2 2 1 2 1 1 4 4 4 2 4 1 4 1 4 1 4 2 1 1 4 1 4 4 2 2 1 2 2\n[4885] 2 2 1 4 1 1 4 1 1 4 2 1 1 4\n\nWithin cluster sum of squares by cluster:\n[1] 462118.7 579703.3 681403.3 357903.9\n (between_SS / total_SS =  80.0 %)\n\nAvailable components:\n\n[1] \"cluster\"      \"centers\"      \"totss\"        \"withinss\"     \"tot.withinss\"\n[6] \"betweenss\"    \"size\"         \"iter\"         \"ifault\"      \n\n\n\nfviz_cluster(kmeans4, data = whitewine)\n\n\n\n\n\n\n\n\n\nwhitewine &lt;- whitewine %&gt;%\n  mutate(Cluster = kmeans4$cluster)\n\n\nwhitewine$Cluster &lt;- \n  as_factor(whitewine$Cluster)\n\n\nwhitewine %&gt;%\n  parallelPlot(refColumnDim = \"Cluster\",\n               width = 300,\n               height = 250,\n               rotateTitle = TRUE)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html",
    "title": "In-class_Ex06",
    "section": "",
    "text": "pacman::p_load(tidyverse, readtext, corporaexplorer, quanteda, stringi, rvest, tidytext, textnets)\n\n\nbible &lt;- readr::read_lines(\"http://www.gutenberg.org/cache/epub/10/pg10.txt\")\n\n\n# coll in to string\nbible &lt;- paste(bible, collapse = \"\\n\")\n\n\n# Identifying the beginning and end of the Bible / stripping PJ metadata\n # (technique borrowed from https://quanteda.io/articles/pkgdown/replication/digital-humanities.html).\nstart_v &lt;- stri_locate_first_fixed(bible, \"The First Book of Moses: Called Genesis\")[1]\nend_v &lt;- stri_locate_last_fixed(bible, \"Amen.\")[2]\nbible &lt;- stri_sub(bible, start_v, end_v)\n\n\n# In the file, every book in the bible is preceded by five newlines,\n  # which we use to split our string into a vector where each element is a book.\nbooks &lt;- stri_split_regex(bible, \"\\n{5}\") %&gt;%\n    unlist %&gt;%\n    .[-40]  # Removing the heading \"The New Testament of the King James Bible\",\n              # which also was preceded by five newlines.\n\n\n# Because of the structure of the text in the file:\n  # Replacing double or more newlines with two newlines, and a single newline with space.\nbooks &lt;- str_replace_all(books, \"\\n{2,}\", \"NEW_PARAGRAPH\") %&gt;%\n    str_replace_all(\"\\n\", \" \") %&gt;%\n    str_replace_all(\"NEW_PARAGRAPH\", \"\\n\\n\")\nbooks &lt;- books[3:68]  # The two first elements are not books\n\n\n# Identifying new chapters within each book and split the text into chapters.\n# (The first characters in chapter 2 will e.g. be 2:1)\nchapters &lt;- str_replace_all(books, \"(\\\\d+:1 )\", \"NEW_CHAPTER\\\\1\") %&gt;%\n    stri_split_regex(\"NEW_CHAPTER\")\n\n\n# Removing the chapter headings from the text (we want them as metadata).\nchapters &lt;- lapply(chapters, function(x) x[-1])\n\n\n# We are not quite happy with the long book titles in the King James Bible,\n  # so we retrieve shorter versions from esv.org which will take up less\n  # space in the corpus map plot.\nbook_titles &lt;- read_html(\"https://www.esv.org/resources/esv-global-study-bible/list-of-abbreviations\") %&gt;%\n  html_nodes(\"td:nth-child(1)\") %&gt;%\n  html_text() %&gt;%\n  .[13:78]  # Removing irrelevant elements after manual inspection.\n\n# We add a column indicating whether a book belongs to the Old or New Testament,\n#   knowing that they contain respectively 39 and 27 books.\ntestament &lt;- c(rep(\"Old\", 39), rep(\"New\", 27))\n\n\n# Data frame with one book as one row.\nbible_df &lt;- tibble::tibble(Text = chapters,\n                           Book = book_titles,\n                           Testament = testament)\n\n# We want each chapter to be one row, but keep the metadata (book and which testament).\nbible_df &lt;- tidyr::unnest(bible_df, Text)\n\n\n# As this is a corpus which is not organised by date,\n  # we set `date_based_corpus` to `FALSE`.\n# Because we want to organise our exploration around the books in the Bible,\n  # we pass `\"Book\"` to the `grouping_variable` argument.\n# We specify which metadata columns we want to be displayed in the\n  # \"Document information\" tab, using the `columns_doc_info` argument.\nKJB &lt;- prepare_data(dataset = bible_df,\n                    date_based_corpus = FALSE,\n                    grouping_variable = \"Book\",\n                    columns_doc_info = c(\"Testament\", \"Book\"))\n\n\nclass(KJB)\n\n[1] \"corporaexplorerobject\"\n\n\n\nexplore(KJB)\n\nShiny applications not supported in static R Markdown documents"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#conclusion",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#conclusion",
    "title": "Take-home_Ex03",
    "section": "",
    "text": "Exploring the networks between the various type of nodes or players in the space has been useful to visualising the relationships between the different parties. It has yielded interesting insights on how certain companies may influence the around companies.\nFor future work, the additional column of timeline and financial situation can be used to provide an additional layer of to the overall visualisation of networks and information in this project."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#mc3-task4---focuse-on-the-southseafood-express-corp",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#mc3-task4---focuse-on-the-southseafood-express-corp",
    "title": "Take_home_Ex03",
    "section": "",
    "text": "neighbourSub-directOwnership\n\n\n\n\nClick to view code\n# Define the target node\ntarget_node &lt;- \"SouthSeafood Express Corp\"\n\n# Filter edges related to the target node\nrelated_edges &lt;- mc3_edges_clean %&gt;%\n  filter(source == target_node | target == target_node) %&gt;%\n  rename(from = source, to = target)\n\n# Extract the related nodes\nrelated_nodes &lt;- mc3_nodes_clean %&gt;%\n  filter(id %in% c(related_edges$from, related_edges$to))\n\n\n# Create the visNetwork plot\nvisNetwork(related_nodes, related_edges) %&gt;%\n  visPhysics(solver = \"forceAtlas2Based\",\n             forceAtlas2Based = list(gravitationalConstant = -100)) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visGroups(groupname = \"Organization\", color = \"pink\") %&gt;%\n  visGroups(groupname = \"Person\", color = \"lightgreen\") %&gt;%\n  visLegend() %&gt;%\n  visEdges(arrows = \"to\") %&gt;%\n  visOptions(\n    highlightNearest = list(enabled = TRUE, degree = 2, hover = TRUE),\n    nodesIdSelection = TRUE,\n    selectedBy = \"subtype\",\n    collapse = TRUE\n  ) %&gt;%\n  visInteraction(dragNodes = TRUE, dragView = TRUE, zoomView = TRUE) %&gt;%\n  visEvents(selectNode = \"function(properties) {\n    var selectedNodeId = properties.nodes[0];\n    this.body.data.nodes.update({id: selectedNodeId, color: {background: 'red', border: 'black'}});\n  }\")\n\n\n\n\n\n\n\n\n\n\nClick to view code\n# Define the target node\ntarget_node &lt;- \"SouthSeafood Express Corp\"\n\n# Filter edges related to the target node\ninitial_edges &lt;- mc3_edges_clean %&gt;%\n  filter(source == target_node | target == target_node) %&gt;%\n  rename(from = source, to = target)\n\nconnected_nodes &lt;- mc3_nodes_clean %&gt;%\n  filter(id %in% c(initial_edges$from, initial_edges$to))\n\nexpanded_edges &lt;- mc3_edges_clean %&gt;%\n  filter(source %in% connected_nodes$id | target %in% connected_nodes$id) %&gt;%\n  rename(from = source, to = target)\n\n# Extract source and target nodes from expanded edges\nexpanded_nodes_source &lt;- expanded_edges %&gt;%\n  distinct(from) %&gt;%\n  rename(id = from)\n\nexpanded_nodes_target &lt;- expanded_edges %&gt;%\n  distinct(to) %&gt;%\n  rename(id = to)\n\n# Combine and deduplicate nodes\nexpanded_nodes_combined &lt;- bind_rows(expanded_nodes_source, expanded_nodes_target) %&gt;%\n  distinct(id) %&gt;%\n  left_join(mc3_nodes_clean, by = \"id\")\n\n# Assign group based on supertype\nexpanded_nodes_combined$group &lt;- ifelse(expanded_nodes_combined$supertype == \"Organization\", \"Organization\", \"Person\")\n\n\n# Create the visNetwork plot\nvisNetwork(expanded_nodes_combined, expanded_edges) %&gt;%\n  visPhysics(solver = \"forceAtlas2Based\",\n             forceAtlas2Based = list(gravitationalConstant = -100)) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visGroups(groupname = \"Organization\", color = \"pink\") %&gt;%\n  visGroups(groupname = \"Person\", color = \"lightgreen\") %&gt;%\n  visLegend() %&gt;%\n  visEdges(arrows = \"to\") %&gt;%\n  visOptions(\n    highlightNearest = list(enabled = TRUE, degree = 2, hover = TRUE),\n    nodesIdSelection = TRUE,\n    selectedBy = \"group\",\n    collapse = TRUE\n  ) %&gt;%\n  visInteraction(dragNodes = TRUE, dragView = TRUE, zoomView = TRUE) %&gt;%\n  visEvents(selectNode = \"function(properties) {\n    var selectedNodeId = properties.nodes[0];\n    this.body.data.nodes.update({id: selectedNodeId, color: {background: 'red', border: 'black'}});\n  }\")\n\n\n\n\n\n\n\n\n\n\nClick to view code\n# Define the target node\ntarget_node &lt;- \"SouthSeafood Express Corp\"\n\n# Filter edges related to the target node\ninitial_edges &lt;- mc3_edges_clean %&gt;%\n  filter(source == target_node | target == target_node) %&gt;%\n  rename(from = source, to = target)\n\n# Identify nodes directly connected to the target node\nconnected_nodes &lt;- mc3_nodes_clean %&gt;%\n  filter(id %in% c(initial_edges$from, initial_edges$to))\n\nexpanded_edges &lt;- initial_edges\nexpanded_nodes &lt;- connected_nodes\n\nrepeat {\n  # Identify all nodes connected to the current set of nodes\n  new_edges &lt;- mc3_edges_clean %&gt;%\n    filter(source %in% expanded_nodes$id | target %in% expanded_nodes$id) %&gt;%\n    rename(from = source, to = target)\n  \n  # Identify new nodes from the newly found edges\n  new_nodes &lt;- mc3_nodes_clean %&gt;%\n    filter(id %in% c(new_edges$from, new_edges$to)) %&gt;%\n    filter(!id %in% expanded_nodes$id)\n  \n  # Add new edges and nodes to the expanded set\n  expanded_edges &lt;- bind_rows(expanded_edges, new_edges) %&gt;%\n    distinct()\n  expanded_nodes &lt;- bind_rows(expanded_nodes, new_nodes) %&gt;%\n    distinct()\n  \n  # Break the loop if there are no new nodes to add or all new nodes are of type \"Person\"\n  if (nrow(new_nodes) == 0 || all(new_nodes$supertype == \"Person\")) {\n    break\n  }\n}\n\n\n\n\nClick to view code\n# Extract source and target nodes from expanded edges\nexpanded_nodes_source &lt;- expanded_edges %&gt;%\n  distinct(from) %&gt;%\n  rename(id = from)\n\nexpanded_nodes_target &lt;- expanded_edges %&gt;%\n  distinct(to) %&gt;%\n  rename(id = to)\n\n# Combine and deduplicate nodes\nexpanded_nodes_combined &lt;- bind_rows(expanded_nodes_source, expanded_nodes_target) %&gt;%\n  distinct(id) %&gt;%\n  left_join(mc3_nodes_clean, by = \"id\")\n\n# Assign group based on supertype\nexpanded_nodes_combined$group &lt;- ifelse(expanded_nodes_combined$supertype == \"Organization\", \"Organization\", \"Person\")\n\n\n\n\nClick to view code\n# Create the visNetwork plot\nvisNetwork(expanded_nodes_combined, expanded_edges) %&gt;%\n  visPhysics(solver = \"forceAtlas2Based\",\n             forceAtlas2Based = list(gravitationalConstant = -100)) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visGroups(groupname = \"Organization\", color = \"pink\") %&gt;%\n  visGroups(groupname = \"Person\", color = \"lightgreen\") %&gt;%\n  visLegend() %&gt;%\n  visEdges(arrows = \"to\") %&gt;%\n  visOptions(\n    highlightNearest = list(enabled = TRUE, degree = 2, hover = TRUE),\n    nodesIdSelection = TRUE,\n    selectedBy = \"group\",\n    collapse = TRUE\n  ) %&gt;%\n  visInteraction(dragNodes = TRUE, dragView = TRUE, zoomView = TRUE) %&gt;%\n  visEvents(selectNode = \"function(properties) {\n    var selectedNodeId = properties.nodes[0];\n    this.body.data.nodes.update({id: selectedNodeId, color: {background: 'red', border: 'black'}});\n  }\")\n\n\n\n\n\n\n\n\n\nIt is interesting to find that there is one complicated center which connected entities like “Hart Ltd”, “Johnson, Morales and Castro”, which showed a high cooperation and organiztion between current fish companies. And it might be interested to dig the development based on timeline or the financial situation to define its influence. What’s more, even if some points are on the very outside, they still have a sound connection with certain company maybe the supplier or retailer."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#mc3-task",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#mc3-task",
    "title": "Take-home_Ex03",
    "section": "",
    "text": "Tip\n\n\n\nBased on this plot, the edge date will be used, and the company name to define company; Meanwhile, the type in node will be used, source and target will be choosed to decide the “from” and “to”.\n\n\n\n\n\n3.1.1 Nodes3.1.2 Edges\n\n\nThe code chunk below will be used to extract the nodes data.frame of mc3_data and save it as a tibble data.frame called mc3_nodes.\n\n\nClick to view code\n# Clean and select columns from mc3_data$nodes\nmc3_nodes_clean &lt;- as_tibble(mc3_nodes_filt) %&gt;%\n  mutate(type = type,\n         id = id) %&gt;%\n  select(id, type) %&gt;%\n  separate(type, into = c(\"prefix\", \"supertype\", \"subtype\"), sep = \"\\\\.\", extra = \"merge\", fill = \"right\") %&gt;%\n  select(id, supertype, subtype)\n\nkable(head(mc3_nodes_clean))\n\n\n\n\n\nid\nsupertype\nsubtype\n\n\n\n\nAbbott, Mcbride and Edwards\nOrganization\nCompany\n\n\nAbbott-Gomez\nOrganization\nCompany\n\n\nAbbott-Harrison\nOrganization\nCompany\n\n\nAbbott-Ibarra\nOrganization\nCompany\n\n\nAbbott-Sullivan\nOrganization\nCompany\n\n\nAcevedo and Sons\nOrganization\nCompany\n\n\n\n\n\n\n\nThe code chunk below will be used to extract the links data.frame of mc3_data and save it as a tibble data.frame called mc3_edges.\n\n\nClick to view code\nmc3_edges_clean &lt;- as_tibble(mc3_edges_filt) %&gt;% \n  mutate(\n    start_date = as_datetime(start_date),\n    end_date = as_datetime(end_date)\n    ) %&gt;%\n  group_by(source, target, type, start_date, end_date) %&gt;%\n    summarise(weights = n(), .groups = 'drop') %&gt;%\n  filter(source != target) %&gt;%\n  ungroup()\nkable(head(mc3_edges_clean))\n\n\n\n\n\n\n\n\n\n\n\n\n\nsource\ntarget\ntype\nstart_date\nend_date\nweights\n\n\n\n\n4. SeaCargo Ges.m.b.H.\nDry CreekRybachit Marine A/S\nEvent.Owns.Shareholdership\n2034-12-31\n2035-12-12\n1\n\n\n4. SeaCargo Ges.m.b.H.\nKambalaSea Freight Inc\nEvent.Owns.Shareholdership\n2033-04-12\n2035-12-12\n1\n\n\n9. RiverLine CJSC\nSumacAmerica Transport GmbH & Co. KG\nEvent.Owns.Shareholdership\n2028-12-02\n2035-12-12\n1\n\n\nAaron Acosta\nManning-Pratt\nEvent.Owns.Shareholdership\n2008-09-14\n2035-12-12\n1\n\n\nAaron Acosta\nManning-Pratt\nEvent.WorksFor\n2008-07-30\n2035-12-12\n1\n\n\nAaron Allen\nHicks-Calderon\nEvent.Owns.BeneficialOwnership\n2025-03-06\n2035-12-12\n1\n\n\n\n\n\n\n\n\nLet’s focuse on the SouthSeafood Express Corp\n\nneighbourSub-directOwnership\n\n\n\n\nClick to view code\n# Define the target node\ntarget_node &lt;- \"SouthSeafood Express Corp\"\n\n# Filter edges related to the target node\nrelated_edges &lt;- mc3_edges_clean %&gt;%\n  filter(source == target_node | target == target_node) %&gt;%\n  rename(from = source, to = target)\n\n# Extract the related nodes\nrelated_nodes &lt;- mc3_nodes_clean %&gt;%\n  filter(id %in% c(related_edges$from, related_edges$to))\n\n\n# Create the visNetwork plot\nvisNetwork(related_nodes, related_edges) %&gt;%\n  visPhysics(solver = \"forceAtlas2Based\",\n             forceAtlas2Based = list(gravitationalConstant = -100)) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visGroups(groupname = \"Organization\", color = \"pink\") %&gt;%\n  visGroups(groupname = \"Person\", color = \"lightgreen\") %&gt;%\n  visLegend() %&gt;%\n  visEdges(arrows = \"to\") %&gt;%\n  visOptions(\n    highlightNearest = list(enabled = TRUE, degree = 2, hover = TRUE),\n    nodesIdSelection = TRUE,\n    selectedBy = \"subtype\",\n    collapse = TRUE\n  ) %&gt;%\n  visInteraction(dragNodes = TRUE, dragView = TRUE, zoomView = TRUE) %&gt;%\n  visEvents(selectNode = \"function(properties) {\n    var selectedNodeId = properties.nodes[0];\n    this.body.data.nodes.update({id: selectedNodeId, color: {background: 'red', border: 'black'}});\n  }\")\n\n\n\n\n\n\n\n\n\n\nClick to view code\n# Define the target node\ntarget_node &lt;- \"SouthSeafood Express Corp\"\n\n# Filter edges related to the target node\ninitial_edges &lt;- mc3_edges_clean %&gt;%\n  filter(source == target_node | target == target_node) %&gt;%\n  rename(from = source, to = target)\n\nconnected_nodes &lt;- mc3_nodes_clean %&gt;%\n  filter(id %in% c(initial_edges$from, initial_edges$to))\n\nexpanded_edges &lt;- mc3_edges_clean %&gt;%\n  filter(source %in% connected_nodes$id | target %in% connected_nodes$id) %&gt;%\n  rename(from = source, to = target)\n\n# Extract source and target nodes from expanded edges\nexpanded_nodes_source &lt;- expanded_edges %&gt;%\n  distinct(from) %&gt;%\n  rename(id = from)\n\nexpanded_nodes_target &lt;- expanded_edges %&gt;%\n  distinct(to) %&gt;%\n  rename(id = to)\n\n# Combine and deduplicate nodes\nexpanded_nodes_combined &lt;- bind_rows(expanded_nodes_source, expanded_nodes_target) %&gt;%\n  distinct(id) %&gt;%\n  left_join(mc3_nodes_clean, by = \"id\")\n\n# Assign group based on supertype\nexpanded_nodes_combined$group &lt;- ifelse(expanded_nodes_combined$supertype == \"Organization\", \"Organization\", \"Person\")\n\n\n# Create the visNetwork plot\nvisNetwork(expanded_nodes_combined, expanded_edges) %&gt;%\n  visPhysics(solver = \"forceAtlas2Based\",\n             forceAtlas2Based = list(gravitationalConstant = -100)) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visGroups(groupname = \"Organization\", color = \"pink\") %&gt;%\n  visGroups(groupname = \"Person\", color = \"lightgreen\") %&gt;%\n  visLegend() %&gt;%\n  visEdges(arrows = \"to\") %&gt;%\n  visOptions(\n    highlightNearest = list(enabled = TRUE, degree = 2, hover = TRUE),\n    nodesIdSelection = TRUE,\n    selectedBy = \"subtype\",\n    collapse = TRUE\n  ) %&gt;%\n  visInteraction(dragNodes = TRUE, dragView = TRUE, zoomView = TRUE) %&gt;%\n  visEvents(selectNode = \"function(properties) {\n    var selectedNodeId = properties.nodes[0];\n    this.body.data.nodes.update({id: selectedNodeId, color: {background: 'red', border: 'black'}});\n  }\")\n\n\n\n\n\n\n\n\n\n\nClick to view code\n# Identify nodes directly connected to the target node\nconnected_nodes &lt;- mc3_nodes_clean %&gt;%\n  filter(id %in% c(initial_edges$from, initial_edges$to))\n\nexpanded_edges &lt;- initial_edges\nexpanded_nodes &lt;- connected_nodes\n\nrepeat {\n  # Identify all nodes connected to the current set of nodes\n  new_edges &lt;- mc3_edges_clean %&gt;%\n    filter(source %in% expanded_nodes$id | target %in% expanded_nodes$id) %&gt;%\n    rename(from = source, to = target)\n  \n  # Identify new nodes from the newly found edges\n  new_nodes &lt;- mc3_nodes_clean %&gt;%\n    filter(id %in% c(new_edges$from, new_edges$to)) %&gt;%\n    filter(!id %in% expanded_nodes$id)\n  \n  # Add new edges and nodes to the expanded set\n  expanded_edges &lt;- bind_rows(expanded_edges, new_edges) %&gt;%\n    distinct()\n  expanded_nodes &lt;- bind_rows(expanded_nodes, new_nodes) %&gt;%\n    distinct()\n  \n  # Break the loop if there are no new nodes to add or all new nodes are of type \"Person\"\n  if (nrow(new_nodes) == 0 || all(new_nodes$supertype == \"Person\")) {\n    break\n  }\n}\n\n\n\n\nClick to view code\n# Extract source and target nodes from expanded edges\nexpanded_nodes_source &lt;- expanded_edges %&gt;%\n  distinct(from) %&gt;%\n  rename(id = from)\n\nexpanded_nodes_target &lt;- expanded_edges %&gt;%\n  distinct(to) %&gt;%\n  rename(id = to)\n\n# Combine and deduplicate nodes\nexpanded_nodes_combined &lt;- bind_rows(expanded_nodes_source, expanded_nodes_target) %&gt;%\n  distinct(id) %&gt;%\n  left_join(mc3_nodes_clean, by = \"id\")\n\n# Assign group based on supertype\nexpanded_nodes_combined$group &lt;- ifelse(expanded_nodes_combined$supertype == \"Organization\", \"Organization\", \"Person\")\n\n\n\n\nClick to view code\n# Create the visNetwork plot\nvisNetwork(expanded_nodes_combined, expanded_edges) %&gt;%\n  visPhysics(solver = \"forceAtlas2Based\",\n             forceAtlas2Based = list(gravitationalConstant = -100)) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visGroups(groupname = \"Organization\", color = \"pink\") %&gt;%\n  visGroups(groupname = \"Person\", color = \"lightgreen\") %&gt;%\n  visLegend() %&gt;%\n  visEdges(arrows = \"to\") %&gt;%\n  visOptions(\n    highlightNearest = list(enabled = TRUE, degree = 2, hover = TRUE),\n    nodesIdSelection = TRUE,\n    selectedBy = \"subtype\",\n    collapse = TRUE\n  ) %&gt;%\n  visInteraction(dragNodes = TRUE, dragView = TRUE, zoomView = TRUE) %&gt;%\n  visEvents(selectNode = \"function(properties) {\n    var selectedNodeId = properties.nodes[0];\n    this.body.data.nodes.update({id: selectedNodeId, color: {background: 'red', border: 'black'}});\n  }\")\n\n\n\n\n\n\n\n\n\n\n\n\nFirst, create a graph object using tbl_graph() function. Then calculate betweenness and closeness centrality scores.\n\n\nClick to view code\nmc3_graph &lt;- tbl_graph(nodes = mc3_nodes_clean,\n                       edges = mc3_edges_clean,\n                       directed = FALSE) %&gt;%\n  mutate(betweenness_centrality = centrality_betweenness(),\n         closeness_centrality = centrality_closeness())\n\n\nWe will filter nodes with high betweeness centrality scores (&gt;8,000,000) and visualise them to see the relationships that they have.\n\n\nClick to view code\nset.seed(1234)\nmc3_graph %&gt;%\n  filter(betweenness_centrality &gt; 8000000) %&gt;%\nggraph(layout = \"fr\") +\n  geom_edge_link(aes(alpha=0.5)) +\n  geom_node_point(aes(\n    size = betweenness_centrality,\n    color = supertype,\n    alpha = 0.3)) +\n  geom_node_label(aes(label = id),repel=TRUE, size=2.5, alpha = 0.8) +\n  scale_size_continuous(range=c(1,10)) +\n  theme_graph() +\n  labs(title = 'Initial network visualisation',\n       subtitle = 'Entities with betweenness scores &gt; 8,000,000')\n\n\n\n\n\n\n\n\n\nBelow is a dataframe showing us the top 10 entities with the highest betweenness scores.\n\n\nClick to view code\nmc3_graph %&gt;%  activate(nodes) %&gt;%  as_tibble() %&gt;% arrange(desc(betweenness_centrality)) %&gt;% slice(1:10) %&gt;% kable() \n\n\n\n\n\n\n\n\n\n\n\n\nid\nsupertype\nsubtype\nbetweenness_centrality\ncloseness_centrality\n\n\n\n\nSharon Moon\nPerson\nNA\n31170638\n3.6e-06\n\n\nSteven Robertson\nPerson\nNA\n28158072\n3.2e-06\n\n\nJohnson, Morales and Castro\nOrganization\nCompany\n26218503\n3.7e-06\n\n\nHart Ltd\nOrganization\nFinancialCompany\n26129255\n3.2e-06\n\n\nAbbott-Harrison\nOrganization\nCompany\n24206713\n3.0e-06\n\n\nPhelps, Montoya and Barnett\nOrganization\nCompany\n21073981\n3.0e-06\n\n\nMorrison-Zamora\nOrganization\nCompany\n20813895\n3.7e-06\n\n\nBlankenship-Strickland\nOrganization\nCompany\n20157207\n3.4e-06\n\n\nHolloway-Salas\nOrganization\nCompany\n19957178\n3.7e-06\n\n\nMichael Howard DDS\nPerson\nNA\n19922437\n3.5e-06\n\n\n\n\n\nThe top 10 betweenness entities above include 3 persons and 7 companies. In the next section, we will filter entities into only organization entities. We may revisit the person entities later when we have specific targets/companies to investigate.\n\n\n\n\nbefore 2033-10-29\nbetween 2033-10-29 and 2035-05-25\nafter 2035-05-25\n\n\n\nClick to view code\n# Time bins\nbin1 &lt;- mc3_edges_clean %&gt;%\n  filter(as.Date(start_date) &lt; as.Date(\"2033-10-29\"))\n\nbin2 &lt;- mc3_edges_clean %&gt;%\n  filter(as.Date(start_date) &gt;= as.Date(\"2033-10-29\") & as.Date(start_date) &lt;= as.Date(\"2035-05-25\"))\n\nbin3 &lt;- mc3_edges_clean %&gt;%\n  filter(as.Date(start_date) &gt; as.Date(\"2035-05-25\"))\n\n# Filter edges to include any that contain \"SouthSeafood\"\nsouthseafood_edges_bin1 &lt;- bin1 %&gt;%\n  filter(str_detect(source, \"SouthSeafood\") | str_detect(target, \"SouthSeafood\"))\n\nsouthseafood_edges_bin2 &lt;- bin2 %&gt;%\n  filter(str_detect(source, \"SouthSeafood\") | str_detect(target, \"SouthSeafood\"))\n\nsouthseafood_edges_bin3 &lt;- bin3 %&gt;%\n  filter(str_detect(source, \"SouthSeafood\") | str_detect(target, \"SouthSeafood\"))\n\nglimpse(southseafood_edges_bin1)\n\n\nRows: 0\nColumns: 6\n$ source     &lt;chr&gt; \n$ target     &lt;chr&gt; \n$ type       &lt;chr&gt; \n$ start_date &lt;dttm&gt; \n$ end_date   &lt;dttm&gt; \n$ weights    &lt;int&gt; \n\n\nClick to view code\nglimpse(southseafood_edges_bin2)\n\n\nRows: 2\nColumns: 6\n$ source     &lt;chr&gt; \"AguaLeska Transit N.V.\", \"Tainamarine Fishing Co\"\n$ target     &lt;chr&gt; \"SouthSeafood Express Corp\", \"SouthSeafood Express Corp\"\n$ type       &lt;chr&gt; \"Event.Owns.Shareholdership\", \"Event.Owns.Shareholdership\"\n$ start_date &lt;dttm&gt; 2033-10-29, 2035-05-25\n$ end_date   &lt;dttm&gt; 2035-05-25, 2035-12-12\n$ weights    &lt;int&gt; 1, 1\n\n\nClick to view code\nglimpse(southseafood_edges_bin3)\n\n\nRows: 0\nColumns: 6\n$ source     &lt;chr&gt; \n$ target     &lt;chr&gt; \n$ type       &lt;chr&gt; \n$ start_date &lt;dttm&gt; \n$ end_date   &lt;dttm&gt; \n$ weights    &lt;int&gt; \n\n\n\n\n\n\n\n\n\nClick to view code\n# Filter nodes to include only Organizations or Persons\nmc3_nodes_select &lt;- mc3_nodes_clean %&gt;%\n  filter(grepl(\"Organization|Person\", supertype, ignore.case = TRUE))\n\n\n\n\n\n\n\nClick to view code\nmc3_edges_select &lt;- mc3_edges_clean %&gt;%\n  filter(source %in% mc3_nodes_select$id | target %in% mc3_nodes_select$id) %&gt;%\n  distinct() %&gt;%\n  rename(from = source,\n         to = target)\n\n\n\n\n\n\n\nClick to view code\nmc3_edges_select_high &lt;- mc3_edges_select %&gt;%\n  group_by(from) %&gt;%\n  mutate(count = n()) %&gt;%\n  filter(count &gt;= 5) %&gt;%\n  ungroup()\n\n\n\n\n\n\n\nClick to view code\nmc3_nodes_source &lt;- mc3_edges_select_high %&gt;%\n  distinct(from) %&gt;%\n  rename(id = from)\n\nmc3_nodes_target &lt;- mc3_edges_select_high %&gt;%\n  distinct(to) %&gt;%\n  rename(id = to)\n\n\n\n\n\n\n\nClick to view code\n# Combine and deduplicate nodes\nmc3_nodes_combined &lt;- bind_rows(mc3_nodes_source, mc3_nodes_target) %&gt;%\n  distinct(id) %&gt;%\n  left_join(mc3_nodes_clean, by = \"id\")\n\n# Assign group based on supertype\nmc3_nodes_combined$group &lt;- ifelse(mc3_nodes_combined$supertype == \"Organization\", \"Organization\", \"Person\")\n\n# Visualize with visNetwork\nvisNetwork(mc3_nodes_combined, mc3_edges_select_high) %&gt;%\n  visPhysics(solver = \"forceAtlas2Based\",\n             forceAtlas2Based = list(gravitationalConstant = -100)) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visGroups(groupname = \"Organization\", color = \"yellow\") %&gt;%\n  visGroups(groupname = \"Person\", color = \"grey\") %&gt;%\n  visLegend() %&gt;%\n  visEdges(arrows = \"to\") %&gt;%\n  visOptions(\n    highlightNearest = list(enabled = TRUE, degree = 2, hover = TRUE),\n    nodesIdSelection = TRUE,\n    selectedBy = \"subtype\",\n    collapse = TRUE\n  ) %&gt;%\n  visInteraction(dragNodes = TRUE, dragView = TRUE, zoomView = TRUE) %&gt;%\n  visEvents(selectNode = \"function(properties) {\n    var selectedNodeId = properties.nodes[0];\n    this.body.data.nodes.update({id: selectedNodeId, color: {background: 'red', border: 'black'}});\n  }\")\n\n\n\n\n\n\n\n\n\nSince the SouthSeafood Express Corp connect first event from AguaLeska Transit N.V. in 2033-10-29, and turn to connect Tainamarine Fishing Co in 2035-05-25\n\nbefore 2033-10-29after 2035-05-25\n\n\n\n\nClick to view code\n# Filter edges based on date criteria\nmc3_edges_filtered_dates &lt;- mc3_edges_clean %&gt;%\n  filter(start_date &lt; as_datetime(\"2033-10-29\") & end_date &gt; as_datetime(\"2033-10-29\"))\n\n# Visualize with visNetwork\nvisNetwork(mc3_nodes_combined, mc3_edges_select_high) %&gt;%\n  visPhysics(solver = \"forceAtlas2Based\",\n             forceAtlas2Based = list(gravitationalConstant = -100)) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visGroups(groupname = \"Organization\", color = \"lightblue\") %&gt;%\n  visGroups(groupname = \"Person\", color = \"lightgreen\") %&gt;%\n  visLegend() %&gt;%\n  visEdges(arrows = \"to\") %&gt;%\n  visOptions(\n    highlightNearest = list(enabled = TRUE, degree = 2, hover = TRUE),\n    nodesIdSelection = TRUE,\n    selectedBy = \"subtype\",\n    collapse = TRUE\n  ) %&gt;%\n  visInteraction(dragNodes = TRUE, dragView = TRUE, zoomView = TRUE) %&gt;%\n  visEvents(selectNode = \"function(properties) {\n    var selectedNodeId = properties.nodes[0];\n    this.body.data.nodes.update({id: selectedNodeId, color: {background: 'red', border: 'black'}});\n  }\")\n\n\n\n\n\n\n\n\n\n\nClick to view code\nmc3_edges_filtered_dates &lt;- mc3_edges_clean %&gt;%\n  filter(end_date &gt; as_datetime(\"2035-05-25\"))\n\n\n# Visualize with visNetwork\nvisNetwork(mc3_nodes_combined, mc3_edges_select_high) %&gt;%\n  visPhysics(solver = \"forceAtlas2Based\",\n             forceAtlas2Based = list(gravitationalConstant = -100)) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visGroups(groupname = \"Organization\", color = \"lightblue\") %&gt;%\n  visGroups(groupname = \"Person\", color = \"lightgreen\") %&gt;%\n  visLegend() %&gt;%\n  visEdges(arrows = \"to\") %&gt;%\n  visOptions(\n    highlightNearest = list(enabled = TRUE, degree = 2, hover = TRUE),\n    nodesIdSelection = TRUE,\n    selectedBy = \"subtype\",\n    collapse = TRUE\n  ) %&gt;%\n  visInteraction(dragNodes = TRUE, dragView = TRUE, zoomView = TRUE) %&gt;%\n  visEvents(selectNode = \"function(properties) {\n    var selectedNodeId = properties.nodes[0];\n    this.body.data.nodes.update({id: selectedNodeId, color: {background: 'red', border: 'black'}});\n  }\")"
  }
]